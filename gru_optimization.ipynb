{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sommaire: <a class=\"anchor\" id=\"sommaire\"></a>\n",
    "* [Sommaire](#sommaire)\n",
    "* [Preambule](#prem)\n",
    "     * [Package Loading](#package)\n",
    "     * [Functions](#function)\n",
    "* [GRU](#lstm)\n",
    "    * [1.FD001](#fd001)\n",
    "        * [1.1 Data loading](#fd001dataload)\n",
    "        * [1.2 Model selection](#fd001modelselect)\n",
    "    * [2.FD002](#fd002)\n",
    "         * [2.1 Data loading](#fd002dataload)\n",
    "         * [2.2 Model selection](#fd002modelselect)\n",
    "    * [3.FD003](#fd003)\n",
    "         * [3.1 Data loading](#fd003dataload)\n",
    "         * [3.2 Model selection](#fd003modelselect)\n",
    "    * [4.FD004](#fd004)\n",
    "         * [4.1 Data loading](#fd004dataload)\n",
    "         * [4.2 Model selection](#fd004modelselect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package loading <a class = \"anchor\" id=\"package\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "okay\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from lime.lime_tabular import RecurrentTabularExplainer\n",
    "from tqdm import tqdm\n",
    "import keras\n",
    "from sp_modif.model_function import *\n",
    "from sp_modif.methods import *\n",
    "from sp_modif.data_prep import *\n",
    "from sp_modif.evaluator import *\n",
    "from sp_modif.SHAP import *\n",
    "from sp_modif.L2X import *\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import random\n",
    "# import keras\n",
    "import math\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score \n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn import preprocessing\n",
    "from keras import backend as K\n",
    "from sklearn.preprocessing import MinMaxScaler , StandardScaler\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, Activation, GRU\n",
    "from scipy import optimize\n",
    "from methods import *\n",
    "import warnings\n",
    "from tensorflow.keras import optimizers\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "print(\"okay\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions <a class = \"anchor\" id=\"function\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixer le seed pour la reproductibilit√©\n",
    "SEED = 0\n",
    "def set_seed(seed=SEED):\n",
    "    os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "    random.seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    tf.random.set_seed(SEED)\n",
    "\n",
    "# Appeler la fonction pour fixer le seed\n",
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rul_piecewise_fct(X_train, rul):\n",
    "    \n",
    "    X_train['RUL'].clip(upper=rul, inplace=True)\n",
    "    \n",
    "    return X_train\n",
    "\n",
    "def prep_data(train, test, drop_sensors, remaining_sensors, alpha):\n",
    "    X_train_interim = add_operating_condition(train.drop(drop_sensors, axis=1))\n",
    "    X_test_interim = add_operating_condition(test.drop(drop_sensors, axis=1))\n",
    "\n",
    "    X_train_interim, X_test_interim = condition_scaler(X_train_interim, X_test_interim, remaining_sensors)\n",
    "\n",
    "    X_train_interim = exponential_smoothing(X_train_interim, remaining_sensors, 0, alpha)\n",
    "    X_test_interim = exponential_smoothing(X_test_interim, remaining_sensors, 0, alpha)\n",
    "    \n",
    "    return X_train_interim, X_test_interim\n",
    "\n",
    "# Models functions\n",
    "\n",
    "# 1layers\n",
    "def model_gru_1layer(input_shape, nodes_per_layer, dropout, activation, weights_file):\n",
    "    \n",
    "    cb = keras.callbacks.EarlyStopping(monitor='loss', patience=4)\n",
    "    model = Sequential()\n",
    "    model.add(GRU(units = nodes_per_layer, activation=activation, \n",
    "                  input_shape=input_shape))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error',\n",
    "                  optimizer=Adam(learning_rate=0.001))\n",
    "    model.save_weights(weights_file)\n",
    "\n",
    "    return model\n",
    "# 2layers\n",
    "def model_gru_2layer(input_shape, nodes_per_layer, dropout, activation, weights_file):\n",
    "    \n",
    "    cb = keras.callbacks.EarlyStopping(monitor='loss', patience=10)\n",
    "    model = Sequential()\n",
    "    model.add(GRU(units = nodes_per_layer, activation=activation, \n",
    "                  input_shape=input_shape, return_sequences=True))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(GRU(units = nodes_per_layer, activation=activation, \n",
    "                  input_shape=input_shape))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error',\n",
    "                  optimizer=Adam(learning_rate=0.001))\n",
    "    model.save_weights(weights_file)\n",
    "\n",
    "    return model\n",
    "\n",
    "# 3layers\n",
    "def model_gru_3layer(input_shape, nodes_per_layer, dropout, activation, weights_file):\n",
    "    \n",
    "    cb = keras.callbacks.EarlyStopping(monitor='loss', patience=4)\n",
    "    model = Sequential()\n",
    "    model.add(GRU(units = nodes_per_layer, activation=activation, \n",
    "                  input_shape=input_shape, return_sequences=True))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(GRU(units = nodes_per_layer, activation=activation, \n",
    "                  input_shape=input_shape, return_sequences=True))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(GRU(units = nodes_per_layer, activation=activation, \n",
    "                  input_shape=input_shape))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error',\n",
    "                  optimizer=Adam(learning_rate=0.001))\n",
    "    model.save_weights(weights_file)\n",
    "\n",
    "    return model\n",
    "\n",
    "def model_gru_4layer(input_shape, nodes_per_layer, dropout, activation, weights_file):\n",
    "    \n",
    "    cb = keras.callbacks.EarlyStopping(monitor='loss', patience=4)\n",
    "    model = Sequential()\n",
    "    model.add(GRU(units = nodes_per_layer, activation=activation, \n",
    "                  input_shape=input_shape, return_sequences=True))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(GRU(units = nodes_per_layer, activation=activation, \n",
    "                  input_shape=input_shape, return_sequences=True))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(GRU(units = nodes_per_layer, activation=activation, \n",
    "                  input_shape=input_shape, return_sequences=True))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(GRU(units = nodes_per_layer, activation=activation, \n",
    "                  input_shape=input_shape))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error',\n",
    "                  optimizer=Adam(learning_rate=0.001))\n",
    "    model.save_weights(weights_file)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. FD001 <a class = \"anchor\" id=\"fd001\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20631, 27) (13096, 26) (100, 1)\n"
     ]
    }
   ],
   "source": [
    "# Data preparation\n",
    "# Data loading\n",
    "\n",
    "train, test, y_test = prepare_data('FD001.txt')\n",
    "print(train.shape, test.shape, y_test.shape)\n",
    "sensor_names = ['T20','T24','T30','T50','P20','P15','P30','Nf','Nc','epr','Ps30','phi',\n",
    "                'NRf','NRc','BPR','farB','htBleed','Nf_dmd','PCNfR_dmd','W31','W32']\n",
    "\n",
    "remaining_sensors = ['T24','T30','T50','P30','Nf','Nc','Ps30','phi',\n",
    "                'NRf','NRc','BPR','htBleed','W31','W32'] # selection based on main_notebook\n",
    "\n",
    "drop_sensors = [element for element in sensor_names if element not in remaining_sensors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rul_piecewise = 130\n",
    "train['RUL'].clip(upper=rul_piecewise, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10752"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lower alpha's perform better, so we can ditch a few high ones to reduce the search space\n",
    "alpha_list = [0.01, 0.05] + list(np.arange(10,60+1,10)/100)\n",
    "\n",
    "sequence_list = list(np.arange(10,40+1,5))\n",
    "epoch_list = list(np.arange(5,20+1,5))\n",
    "nodes_list = [[32], [64], [128], [256]]\n",
    "\n",
    "# lowest dropout=0.1, because I know zero dropout will yield better training results but worse generalization\n",
    "dropouts = list(np.arange(1,4)/10)  \n",
    "\n",
    "# again, earlier testing revealed relu performed significantly worse, so I removed it from the options\n",
    "activation_functions = ['tanh']\n",
    "batch_size_list = [32, 64, 128, 256]\n",
    "sensor_list = [sensor_names]\n",
    "\n",
    "tuning_options = np.prod([len(alpha_list),\n",
    "                          len(sequence_list),\n",
    "                          len(epoch_list),\n",
    "                          len(nodes_list),\n",
    "                          len(dropouts),\n",
    "                          len(activation_functions),\n",
    "                          len(batch_size_list),\n",
    "                          len(sensor_list)])\n",
    "tuning_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ITERATIONS = 25\n",
    "SEED = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17731, 30, 14) (17731, 1) (100, 30, 14)\n",
      "Epoch 1/25\n",
      "139/139 [==============================] - 8s 51ms/step - loss: 4484.9697 - val_loss: 2283.7559\n",
      "Epoch 2/25\n",
      "139/139 [==============================] - 6s 47ms/step - loss: 2357.8901 - val_loss: 1675.9274\n",
      "Epoch 3/25\n",
      "139/139 [==============================] - 7s 50ms/step - loss: 1918.4822 - val_loss: 1566.9929\n",
      "Epoch 4/25\n",
      "139/139 [==============================] - 7s 48ms/step - loss: 1413.2267 - val_loss: 854.2256\n",
      "Epoch 5/25\n",
      "139/139 [==============================] - 7s 47ms/step - loss: 879.9505 - val_loss: 737.9779\n",
      "Epoch 6/25\n",
      "139/139 [==============================] - 7s 48ms/step - loss: 639.4908 - val_loss: 383.0013\n",
      "Epoch 7/25\n",
      "139/139 [==============================] - 7s 48ms/step - loss: 417.1738 - val_loss: 237.7495\n",
      "Epoch 8/25\n",
      "139/139 [==============================] - 7s 48ms/step - loss: 294.6344 - val_loss: 261.5718\n",
      "Epoch 9/25\n",
      "139/139 [==============================] - 7s 48ms/step - loss: 272.3218 - val_loss: 283.1718\n",
      "Epoch 10/25\n",
      "139/139 [==============================] - 7s 48ms/step - loss: 240.8410 - val_loss: 244.5215\n",
      "Epoch 11/25\n",
      "139/139 [==============================] - 6s 46ms/step - loss: 237.8919 - val_loss: 250.9338\n",
      "Epoch 12/25\n",
      "139/139 [==============================] - 7s 49ms/step - loss: 236.0237 - val_loss: 263.5081\n",
      "Epoch 13/25\n",
      "139/139 [==============================] - 7s 48ms/step - loss: 259.8078 - val_loss: 270.8480\n",
      "Epoch 14/25\n",
      "139/139 [==============================] - 7s 49ms/step - loss: 231.5586 - val_loss: 239.7760\n",
      "Epoch 15/25\n",
      "139/139 [==============================] - 7s 49ms/step - loss: 220.7224 - val_loss: 216.3718\n",
      "Epoch 16/25\n",
      "139/139 [==============================] - 7s 49ms/step - loss: 226.6138 - val_loss: 209.7791\n",
      "Epoch 17/25\n",
      "139/139 [==============================] - 7s 49ms/step - loss: 226.1328 - val_loss: 235.6252\n",
      "Epoch 18/25\n",
      "139/139 [==============================] - 7s 47ms/step - loss: 220.8153 - val_loss: 197.2982\n",
      "Epoch 19/25\n",
      "139/139 [==============================] - 7s 47ms/step - loss: 214.4673 - val_loss: 226.4941\n",
      "Epoch 20/25\n",
      "139/139 [==============================] - 7s 49ms/step - loss: 217.4461 - val_loss: 196.1257\n",
      "Epoch 21/25\n",
      "139/139 [==============================] - 7s 48ms/step - loss: 208.8302 - val_loss: 198.5038\n",
      "Epoch 22/25\n",
      "139/139 [==============================] - 7s 49ms/step - loss: 209.9509 - val_loss: 232.9578\n",
      "Epoch 23/25\n",
      "139/139 [==============================] - 7s 47ms/step - loss: 210.1224 - val_loss: 206.1753\n",
      "Epoch 24/25\n",
      "139/139 [==============================] - 7s 48ms/step - loss: 212.9557 - val_loss: 230.6471\n",
      "Epoch 25/25\n",
      "139/139 [==============================] - 7s 48ms/step - loss: 212.6371 - val_loss: 217.5804\n",
      "4/4 [==============================] - 0s 6ms/step\n",
      "(17731, 30, 14) (17731, 1) (100, 30, 14)\n",
      "Epoch 1/25\n",
      "278/278 [==============================] - 5s 15ms/step - loss: 4791.2563 - val_loss: 2482.9697\n",
      "Epoch 2/25\n",
      "278/278 [==============================] - 4s 13ms/step - loss: 2526.6162 - val_loss: 1720.6929\n",
      "Epoch 3/25\n",
      "278/278 [==============================] - 4s 13ms/step - loss: 1987.4493 - val_loss: 1659.4957\n",
      "Epoch 4/25\n",
      "278/278 [==============================] - 4s 13ms/step - loss: 1743.1564 - val_loss: 999.0058\n",
      "Epoch 5/25\n",
      "278/278 [==============================] - 4s 13ms/step - loss: 897.0549 - val_loss: 404.4308\n",
      "Epoch 6/25\n",
      "278/278 [==============================] - 4s 13ms/step - loss: 482.5660 - val_loss: 283.8534\n",
      "Epoch 7/25\n",
      "278/278 [==============================] - 4s 13ms/step - loss: 332.8272 - val_loss: 314.2548\n",
      "Epoch 8/25\n",
      "278/278 [==============================] - 4s 13ms/step - loss: 283.9523 - val_loss: 212.8382\n",
      "Epoch 9/25\n",
      "278/278 [==============================] - 4s 13ms/step - loss: 269.2342 - val_loss: 215.5987\n",
      "Epoch 10/25\n",
      "278/278 [==============================] - 4s 14ms/step - loss: 244.7224 - val_loss: 330.5759\n",
      "Epoch 11/25\n",
      "278/278 [==============================] - 4s 14ms/step - loss: 238.5557 - val_loss: 231.8622\n",
      "Epoch 12/25\n",
      "278/278 [==============================] - 4s 14ms/step - loss: 238.1204 - val_loss: 296.5210\n",
      "Epoch 13/25\n",
      "278/278 [==============================] - 4s 14ms/step - loss: 227.0833 - val_loss: 262.0619\n",
      "Epoch 14/25\n",
      "278/278 [==============================] - 4s 13ms/step - loss: 222.2014 - val_loss: 297.0371\n",
      "Epoch 15/25\n",
      "278/278 [==============================] - 4s 13ms/step - loss: 234.3723 - val_loss: 214.2708\n",
      "Epoch 16/25\n",
      "278/278 [==============================] - 4s 13ms/step - loss: 224.0984 - val_loss: 230.3587\n",
      "Epoch 17/25\n",
      "278/278 [==============================] - 4s 14ms/step - loss: 221.4544 - val_loss: 223.6700\n",
      "Epoch 18/25\n",
      "278/278 [==============================] - 4s 14ms/step - loss: 221.5219 - val_loss: 236.5724\n",
      "Epoch 19/25\n",
      "278/278 [==============================] - 4s 13ms/step - loss: 218.0076 - val_loss: 219.1748\n",
      "Epoch 20/25\n",
      "278/278 [==============================] - 4s 13ms/step - loss: 213.1937 - val_loss: 220.1331\n",
      "Epoch 21/25\n",
      "278/278 [==============================] - 4s 13ms/step - loss: 213.5222 - val_loss: 243.3353\n",
      "Epoch 22/25\n",
      "278/278 [==============================] - 4s 13ms/step - loss: 211.7248 - val_loss: 214.7794\n",
      "Epoch 23/25\n",
      "278/278 [==============================] - 4s 13ms/step - loss: 216.4496 - val_loss: 201.4646\n",
      "Epoch 24/25\n",
      "278/278 [==============================] - 4s 13ms/step - loss: 207.3363 - val_loss: 196.6371\n",
      "Epoch 25/25\n",
      "278/278 [==============================] - 4s 13ms/step - loss: 210.0222 - val_loss: 239.4077\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "(17731, 30, 14) (17731, 1) (100, 30, 14)\n",
      "Epoch 1/25\n",
      "278/278 [==============================] - 3s 7ms/step - loss: 6155.2192 - val_loss: 3934.7102\n",
      "Epoch 2/25\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 4122.7988 - val_loss: 2719.5281\n",
      "Epoch 3/25\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 3016.1096 - val_loss: 2069.9495\n",
      "Epoch 4/25\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 2401.3853 - val_loss: 1770.4275\n",
      "Epoch 5/25\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 2093.7244 - val_loss: 1668.7021\n",
      "Epoch 6/25\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 1957.5846 - val_loss: 1656.8118\n",
      "Epoch 7/25\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 1907.2463 - val_loss: 1672.8949\n",
      "Epoch 8/25\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 1892.7131 - val_loss: 1688.3947\n",
      "Epoch 9/25\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 1891.3965 - val_loss: 1698.3182\n",
      "Epoch 10/25\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 1882.1429 - val_loss: 1648.7325\n",
      "Epoch 11/25\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 1663.7589 - val_loss: 722.3092\n",
      "Epoch 12/25\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 706.0582 - val_loss: 397.4070\n",
      "Epoch 13/25\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 483.9018 - val_loss: 267.3799\n",
      "Epoch 14/25\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 375.6046 - val_loss: 214.9977\n",
      "Epoch 15/25\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 302.5385 - val_loss: 190.5028\n",
      "Epoch 16/25\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 274.5753 - val_loss: 200.0749\n",
      "Epoch 17/25\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 246.1533 - val_loss: 219.6796\n",
      "Epoch 18/25\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 242.9347 - val_loss: 184.8107\n",
      "Epoch 19/25\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 233.2404 - val_loss: 200.1810\n",
      "Epoch 20/25\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 221.5069 - val_loss: 221.8950\n",
      "Epoch 21/25\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 220.8753 - val_loss: 188.8424\n",
      "Epoch 22/25\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 220.8538 - val_loss: 203.5754\n",
      "Epoch 23/25\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 214.9133 - val_loss: 195.8785\n",
      "Epoch 24/25\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 217.5863 - val_loss: 206.0898\n",
      "Epoch 25/25\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 210.2006 - val_loss: 273.2770\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "(17731, 30, 14) (17731, 1) (100, 30, 14)\n",
      "Epoch 1/25\n",
      "70/70 [==============================] - 2s 12ms/step - loss: 7914.6851 - val_loss: 5988.5693\n",
      "Epoch 2/25\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 6963.1895 - val_loss: 5582.4390\n",
      "Epoch 3/25\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 6578.7002 - val_loss: 5270.2158\n",
      "Epoch 4/25\n",
      "70/70 [==============================] - 1s 11ms/step - loss: 6248.8740 - val_loss: 4988.5903\n",
      "Epoch 5/25\n",
      "70/70 [==============================] - 1s 11ms/step - loss: 5948.6709 - val_loss: 4729.4863\n",
      "Epoch 6/25\n",
      "70/70 [==============================] - 1s 10ms/step - loss: 5664.2905 - val_loss: 4487.5664\n",
      "Epoch 7/25\n",
      "70/70 [==============================] - 1s 10ms/step - loss: 5405.9004 - val_loss: 4262.0273\n",
      "Epoch 8/25\n",
      "70/70 [==============================] - 1s 10ms/step - loss: 5151.1196 - val_loss: 4050.4153\n",
      "Epoch 9/25\n",
      "70/70 [==============================] - 1s 12ms/step - loss: 4923.8618 - val_loss: 3852.1484\n",
      "Epoch 10/25\n",
      "70/70 [==============================] - 1s 10ms/step - loss: 4702.2339 - val_loss: 3666.1960\n",
      "Epoch 11/25\n",
      "70/70 [==============================] - 1s 10ms/step - loss: 4494.9712 - val_loss: 3493.3557\n",
      "Epoch 12/25\n",
      "70/70 [==============================] - 1s 10ms/step - loss: 4302.2412 - val_loss: 3331.0728\n",
      "Epoch 13/25\n",
      "70/70 [==============================] - 1s 10ms/step - loss: 4123.0186 - val_loss: 3179.5403\n",
      "Epoch 14/25\n",
      "70/70 [==============================] - 1s 10ms/step - loss: 3948.0940 - val_loss: 3038.3638\n",
      "Epoch 15/25\n",
      "70/70 [==============================] - 1s 11ms/step - loss: 3789.6345 - val_loss: 2906.3660\n",
      "Epoch 16/25\n",
      "70/70 [==============================] - 1s 11ms/step - loss: 3634.1680 - val_loss: 2784.2881\n",
      "Epoch 17/25\n",
      "70/70 [==============================] - 1s 10ms/step - loss: 3495.7510 - val_loss: 2670.3157\n",
      "Epoch 18/25\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 3361.5806 - val_loss: 2564.9282\n",
      "Epoch 19/25\n",
      "70/70 [==============================] - 1s 10ms/step - loss: 3248.5095 - val_loss: 2467.4438\n",
      "Epoch 20/25\n",
      "70/70 [==============================] - 1s 10ms/step - loss: 3129.6855 - val_loss: 2377.7024\n",
      "Epoch 21/25\n",
      "70/70 [==============================] - 1s 11ms/step - loss: 3017.6479 - val_loss: 2295.1030\n",
      "Epoch 22/25\n",
      "70/70 [==============================] - 1s 10ms/step - loss: 2914.4204 - val_loss: 2219.4578\n",
      "Epoch 23/25\n",
      "70/70 [==============================] - 1s 10ms/step - loss: 2826.0342 - val_loss: 2149.8567\n",
      "Epoch 24/25\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 2734.9766 - val_loss: 2086.9946\n",
      "Epoch 25/25\n",
      "70/70 [==============================] - 1s 10ms/step - loss: 2662.8728 - val_loss: 2029.9135\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "(17731, 30, 14) (17731, 1) (100, 30, 14)\n",
      "Epoch 1/25\n",
      "70/70 [==============================] - 5s 59ms/step - loss: 5561.6064 - val_loss: 3318.2100\n",
      "Epoch 2/25\n",
      "70/70 [==============================] - 4s 55ms/step - loss: 3496.0657 - val_loss: 2271.6980\n",
      "Epoch 3/25\n",
      "70/70 [==============================] - 4s 56ms/step - loss: 2562.2783 - val_loss: 1824.2397\n",
      "Epoch 4/25\n",
      "70/70 [==============================] - 4s 55ms/step - loss: 2141.5173 - val_loss: 1677.1573\n",
      "Epoch 5/25\n",
      "70/70 [==============================] - 4s 56ms/step - loss: 1967.9788 - val_loss: 1651.6211\n",
      "Epoch 6/25\n",
      "70/70 [==============================] - 4s 55ms/step - loss: 1899.7737 - val_loss: 1634.8867\n",
      "Epoch 7/25\n",
      "70/70 [==============================] - 4s 56ms/step - loss: 1724.7148 - val_loss: 1297.9398\n",
      "Epoch 8/25\n",
      "70/70 [==============================] - 4s 55ms/step - loss: 1283.1499 - val_loss: 1125.8673\n",
      "Epoch 9/25\n",
      "70/70 [==============================] - 4s 56ms/step - loss: 979.1725 - val_loss: 821.8455\n",
      "Epoch 10/25\n",
      "70/70 [==============================] - 4s 56ms/step - loss: 784.4562 - val_loss: 542.2509\n",
      "Epoch 11/25\n",
      "70/70 [==============================] - 4s 56ms/step - loss: 672.8026 - val_loss: 956.4562\n",
      "Epoch 12/25\n",
      "70/70 [==============================] - 4s 54ms/step - loss: 575.4962 - val_loss: 322.1514\n",
      "Epoch 13/25\n",
      "70/70 [==============================] - 4s 56ms/step - loss: 481.0318 - val_loss: 295.7581\n",
      "Epoch 14/25\n",
      "70/70 [==============================] - 4s 54ms/step - loss: 356.3634 - val_loss: 264.7820\n",
      "Epoch 15/25\n",
      "70/70 [==============================] - 4s 56ms/step - loss: 318.0967 - val_loss: 240.4581\n",
      "Epoch 16/25\n",
      "70/70 [==============================] - 4s 55ms/step - loss: 295.6862 - val_loss: 233.5229\n",
      "Epoch 17/25\n",
      "70/70 [==============================] - 4s 55ms/step - loss: 286.4003 - val_loss: 227.7932\n",
      "Epoch 18/25\n",
      "70/70 [==============================] - 4s 55ms/step - loss: 274.6184 - val_loss: 287.2612\n",
      "Epoch 19/25\n",
      "70/70 [==============================] - 4s 56ms/step - loss: 263.0002 - val_loss: 354.1173\n",
      "Epoch 20/25\n",
      "70/70 [==============================] - 4s 56ms/step - loss: 266.2015 - val_loss: 217.0418\n",
      "Epoch 21/25\n",
      "70/70 [==============================] - 4s 56ms/step - loss: 255.9888 - val_loss: 314.4259\n",
      "Epoch 22/25\n",
      "70/70 [==============================] - 4s 55ms/step - loss: 257.0614 - val_loss: 314.5509\n",
      "Epoch 23/25\n",
      "70/70 [==============================] - 4s 55ms/step - loss: 234.4413 - val_loss: 211.8051\n",
      "Epoch 24/25\n",
      "70/70 [==============================] - 4s 56ms/step - loss: 239.4083 - val_loss: 214.6741\n",
      "Epoch 25/25\n",
      "70/70 [==============================] - 4s 56ms/step - loss: 224.1373 - val_loss: 322.9883\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "(17731, 30, 14) (17731, 1) (100, 30, 14)\n",
      "Epoch 1/25\n",
      "555/555 [==============================] - 5s 8ms/step - loss: 3726.3113 - val_loss: 1735.6603\n",
      "Epoch 2/25\n",
      "555/555 [==============================] - 4s 8ms/step - loss: 1946.7550 - val_loss: 1644.2504\n",
      "Epoch 3/25\n",
      "555/555 [==============================] - 4s 8ms/step - loss: 1549.0731 - val_loss: 1335.4801\n",
      "Epoch 4/25\n",
      "555/555 [==============================] - 4s 8ms/step - loss: 905.0875 - val_loss: 446.1452\n",
      "Epoch 5/25\n",
      "555/555 [==============================] - 4s 8ms/step - loss: 443.5997 - val_loss: 364.3291\n",
      "Epoch 6/25\n",
      "555/555 [==============================] - 4s 8ms/step - loss: 297.7220 - val_loss: 432.5484\n",
      "Epoch 7/25\n",
      "555/555 [==============================] - 4s 8ms/step - loss: 235.6122 - val_loss: 222.9128\n",
      "Epoch 8/25\n",
      "555/555 [==============================] - 5s 8ms/step - loss: 220.1111 - val_loss: 207.4355\n",
      "Epoch 9/25\n",
      "555/555 [==============================] - 4s 8ms/step - loss: 211.5959 - val_loss: 229.6997\n",
      "Epoch 10/25\n",
      "555/555 [==============================] - 4s 8ms/step - loss: 205.9075 - val_loss: 215.1607\n",
      "Epoch 11/25\n",
      "555/555 [==============================] - 4s 8ms/step - loss: 201.1477 - val_loss: 282.3297\n",
      "Epoch 12/25\n",
      "555/555 [==============================] - 4s 8ms/step - loss: 199.9292 - val_loss: 208.2321\n",
      "Epoch 13/25\n",
      "555/555 [==============================] - 4s 8ms/step - loss: 200.0790 - val_loss: 211.7304\n",
      "Epoch 14/25\n",
      "555/555 [==============================] - 4s 8ms/step - loss: 194.8276 - val_loss: 205.5965\n",
      "Epoch 15/25\n",
      "555/555 [==============================] - 4s 8ms/step - loss: 196.0801 - val_loss: 216.8124\n",
      "Epoch 16/25\n",
      "555/555 [==============================] - 4s 8ms/step - loss: 194.6656 - val_loss: 253.9650\n",
      "Epoch 17/25\n",
      "555/555 [==============================] - 4s 8ms/step - loss: 196.0572 - val_loss: 207.5939\n",
      "Epoch 18/25\n",
      "555/555 [==============================] - 4s 8ms/step - loss: 194.9750 - val_loss: 207.1251\n",
      "Epoch 19/25\n",
      "555/555 [==============================] - 5s 8ms/step - loss: 194.2982 - val_loss: 218.4211\n",
      "Epoch 20/25\n",
      "555/555 [==============================] - 4s 8ms/step - loss: 189.9349 - val_loss: 227.1254\n",
      "Epoch 21/25\n",
      "555/555 [==============================] - 4s 8ms/step - loss: 189.3650 - val_loss: 199.5320\n",
      "Epoch 22/25\n",
      "555/555 [==============================] - 4s 8ms/step - loss: 187.6357 - val_loss: 204.2082\n",
      "Epoch 23/25\n",
      "555/555 [==============================] - 4s 8ms/step - loss: 189.1447 - val_loss: 209.3471\n",
      "Epoch 24/25\n",
      "555/555 [==============================] - 5s 8ms/step - loss: 188.4583 - val_loss: 211.0223\n",
      "Epoch 25/25\n",
      "555/555 [==============================] - 4s 8ms/step - loss: 186.3139 - val_loss: 218.9315\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "(17731, 30, 14) (17731, 1) (100, 30, 14)\n",
      "Epoch 1/25\n",
      "139/139 [==============================] - 2s 8ms/step - loss: 7599.7563 - val_loss: 5719.2729\n",
      "Epoch 2/25\n",
      "139/139 [==============================] - 1s 7ms/step - loss: 6560.2246 - val_loss: 5113.7896\n",
      "Epoch 3/25\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 5941.1558 - val_loss: 4604.5254\n",
      "Epoch 4/25\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 5404.6113 - val_loss: 4159.4458\n",
      "Epoch 5/25\n",
      "139/139 [==============================] - 1s 7ms/step - loss: 4931.3955 - val_loss: 3769.1965\n",
      "Epoch 6/25\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 4508.5620 - val_loss: 3424.8396\n",
      "Epoch 7/25\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 4138.2773 - val_loss: 3124.2532\n",
      "Epoch 8/25\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 3802.6946 - val_loss: 2861.8391\n",
      "Epoch 9/25\n",
      "139/139 [==============================] - 1s 7ms/step - loss: 3516.4670 - val_loss: 2634.5271\n",
      "Epoch 10/25\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 3264.0510 - val_loss: 2439.3289\n",
      "Epoch 11/25\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 3038.9490 - val_loss: 2273.9160\n",
      "Epoch 12/25\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 2851.2739 - val_loss: 2134.3743\n",
      "Epoch 13/25\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 2687.9878 - val_loss: 2016.5637\n",
      "Epoch 14/25\n",
      "139/139 [==============================] - 1s 7ms/step - loss: 2507.6038 - val_loss: 1840.0713\n",
      "Epoch 15/25\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 2300.8103 - val_loss: 1663.8569\n",
      "Epoch 16/25\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 2052.0193 - val_loss: 1469.3280\n",
      "Epoch 17/25\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 1783.9816 - val_loss: 1170.7532\n",
      "Epoch 18/25\n",
      "139/139 [==============================] - 1s 7ms/step - loss: 1582.1110 - val_loss: 1028.3301\n",
      "Epoch 19/25\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 1399.8834 - val_loss: 851.0605\n",
      "Epoch 20/25\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 1256.1624 - val_loss: 738.6868\n",
      "Epoch 21/25\n",
      "139/139 [==============================] - 1s 7ms/step - loss: 1121.6666 - val_loss: 666.4414\n",
      "Epoch 22/25\n",
      "139/139 [==============================] - 1s 7ms/step - loss: 1020.0500 - val_loss: 574.7156\n",
      "Epoch 23/25\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 922.2891 - val_loss: 545.7850\n",
      "Epoch 24/25\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 839.6890 - val_loss: 452.0135\n",
      "Epoch 25/25\n",
      "139/139 [==============================] - 1s 7ms/step - loss: 766.9114 - val_loss: 400.4715\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "(17731, 30, 14) (17731, 1) (100, 30, 14)\n",
      "Epoch 1/25\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 7064.2969 - val_loss: 5126.7886\n",
      "Epoch 2/25\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 5686.6479 - val_loss: 4173.1235\n",
      "Epoch 3/25\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 4731.4160 - val_loss: 3437.9658\n",
      "Epoch 4/25\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 3974.3950 - val_loss: 2871.2231\n",
      "Epoch 5/25\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 3380.8416 - val_loss: 2446.1650\n",
      "Epoch 6/25\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 2921.5408 - val_loss: 2118.2188\n",
      "Epoch 7/25\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 2479.8396 - val_loss: 1759.1580\n",
      "Epoch 8/25\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 2071.7671 - val_loss: 1415.8319\n",
      "Epoch 9/25\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 1652.7935 - val_loss: 1071.3102\n",
      "Epoch 10/25\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 1303.5020 - val_loss: 760.0151\n",
      "Epoch 11/25\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 1034.6556 - val_loss: 611.0858\n",
      "Epoch 12/25\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 833.3351 - val_loss: 441.1103\n",
      "Epoch 13/25\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 687.3284 - val_loss: 353.9377\n",
      "Epoch 14/25\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 567.8552 - val_loss: 299.5890\n",
      "Epoch 15/25\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 466.1999 - val_loss: 297.8190\n",
      "Epoch 16/25\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 422.4496 - val_loss: 246.5384\n",
      "Epoch 17/25\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 357.1197 - val_loss: 242.9042\n",
      "Epoch 18/25\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 322.1982 - val_loss: 217.3142\n",
      "Epoch 19/25\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 294.1465 - val_loss: 216.1505\n",
      "Epoch 20/25\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 276.4422 - val_loss: 281.1192\n",
      "Epoch 21/25\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 265.5085 - val_loss: 198.8380\n",
      "Epoch 22/25\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 256.4160 - val_loss: 231.4412\n",
      "Epoch 23/25\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 246.9482 - val_loss: 226.6540\n",
      "Epoch 24/25\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 239.4473 - val_loss: 198.9776\n",
      "Epoch 25/25\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 241.7659 - val_loss: 227.5650\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "(17731, 30, 14) (17731, 1) (100, 30, 14)\n",
      "Epoch 1/25\n",
      "139/139 [==============================] - 8s 49ms/step - loss: 4622.4292 - val_loss: 2356.5312\n",
      "Epoch 2/25\n",
      "139/139 [==============================] - 6s 46ms/step - loss: 2417.5671 - val_loss: 1690.5084\n",
      "Epoch 3/25\n",
      "139/139 [==============================] - 6s 46ms/step - loss: 1947.7649 - val_loss: 1661.9270\n",
      "Epoch 4/25\n",
      "139/139 [==============================] - 7s 47ms/step - loss: 1870.8062 - val_loss: 1640.3070\n",
      "Epoch 5/25\n",
      "139/139 [==============================] - 7s 47ms/step - loss: 1473.5001 - val_loss: 950.3452\n",
      "Epoch 6/25\n",
      "139/139 [==============================] - 6s 46ms/step - loss: 793.4556 - val_loss: 458.7637\n",
      "Epoch 7/25\n",
      "139/139 [==============================] - 6s 46ms/step - loss: 538.1431 - val_loss: 353.8381\n",
      "Epoch 8/25\n",
      "139/139 [==============================] - 6s 46ms/step - loss: 383.2882 - val_loss: 303.8684\n",
      "Epoch 9/25\n",
      "139/139 [==============================] - 6s 47ms/step - loss: 313.7463 - val_loss: 315.9980\n",
      "Epoch 10/25\n",
      "139/139 [==============================] - 7s 48ms/step - loss: 270.8188 - val_loss: 277.1055\n",
      "Epoch 11/25\n",
      "139/139 [==============================] - 7s 48ms/step - loss: 247.6902 - val_loss: 210.3844\n",
      "Epoch 12/25\n",
      "139/139 [==============================] - 7s 48ms/step - loss: 240.5834 - val_loss: 255.9597\n",
      "Epoch 13/25\n",
      "139/139 [==============================] - 6s 46ms/step - loss: 227.0606 - val_loss: 240.8825\n",
      "Epoch 14/25\n",
      "139/139 [==============================] - 6s 46ms/step - loss: 222.2328 - val_loss: 218.7194\n",
      "Epoch 15/25\n",
      "139/139 [==============================] - 7s 48ms/step - loss: 213.1489 - val_loss: 221.3608\n",
      "Epoch 16/25\n",
      "139/139 [==============================] - 7s 47ms/step - loss: 212.0127 - val_loss: 256.7866\n",
      "Epoch 17/25\n",
      "139/139 [==============================] - 7s 49ms/step - loss: 215.0609 - val_loss: 223.9696\n",
      "Epoch 18/25\n",
      "139/139 [==============================] - 7s 49ms/step - loss: 204.5162 - val_loss: 251.6037\n",
      "Epoch 19/25\n",
      "139/139 [==============================] - 7s 48ms/step - loss: 206.6874 - val_loss: 233.6073\n",
      "Epoch 20/25\n",
      "139/139 [==============================] - 6s 46ms/step - loss: 202.1152 - val_loss: 215.6038\n",
      "Epoch 21/25\n",
      "139/139 [==============================] - 7s 49ms/step - loss: 200.2206 - val_loss: 209.8980\n",
      "Epoch 22/25\n",
      "139/139 [==============================] - 7s 48ms/step - loss: 203.1007 - val_loss: 210.7719\n",
      "Epoch 23/25\n",
      "139/139 [==============================] - 7s 48ms/step - loss: 196.4665 - val_loss: 211.1978\n",
      "Epoch 24/25\n",
      "139/139 [==============================] - 6s 46ms/step - loss: 197.7188 - val_loss: 222.4395\n",
      "Epoch 25/25\n",
      "139/139 [==============================] - 7s 47ms/step - loss: 191.9734 - val_loss: 239.4415\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "iteration  10\n",
      "(17731, 30, 14) (17731, 1) (100, 30, 14)\n",
      "Epoch 1/25\n",
      "555/555 [==============================] - 4s 5ms/step - loss: 6361.9688 - val_loss: 4141.9102\n",
      "Epoch 2/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 4330.6660 - val_loss: 2855.6487\n",
      "Epoch 3/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 3153.4541 - val_loss: 2134.8564\n",
      "Epoch 4/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 2450.4290 - val_loss: 1659.4012\n",
      "Epoch 5/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 1698.9438 - val_loss: 973.8318\n",
      "Epoch 6/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 1053.8287 - val_loss: 566.5382\n",
      "Epoch 7/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 697.5087 - val_loss: 322.8914\n",
      "Epoch 8/25\n",
      "555/555 [==============================] - 2s 5ms/step - loss: 513.4583 - val_loss: 282.1993\n",
      "Epoch 9/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 398.4968 - val_loss: 278.2389\n",
      "Epoch 10/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 353.0068 - val_loss: 213.7620\n",
      "Epoch 11/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 320.2456 - val_loss: 264.5556\n",
      "Epoch 12/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 306.0299 - val_loss: 200.1839\n",
      "Epoch 13/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 294.5084 - val_loss: 234.3820\n",
      "Epoch 14/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 285.3305 - val_loss: 299.7058\n",
      "Epoch 15/25\n",
      "555/555 [==============================] - 2s 4ms/step - loss: 295.4319 - val_loss: 220.1065\n",
      "Epoch 16/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 280.0389 - val_loss: 245.7937\n",
      "Epoch 17/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 284.9242 - val_loss: 213.0007\n",
      "Epoch 18/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 280.4441 - val_loss: 243.4910\n",
      "Epoch 19/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 280.5911 - val_loss: 212.1267\n",
      "Epoch 20/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 274.2198 - val_loss: 258.9994\n",
      "Epoch 21/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 271.4068 - val_loss: 219.5104\n",
      "Epoch 22/25\n",
      "555/555 [==============================] - 2s 4ms/step - loss: 267.6698 - val_loss: 203.5977\n",
      "Epoch 23/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 267.6749 - val_loss: 212.6198\n",
      "Epoch 24/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 267.8432 - val_loss: 199.5044\n",
      "Epoch 25/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 266.1716 - val_loss: 264.0201\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "(17731, 30, 14) (17731, 1) (100, 30, 14)\n",
      "Epoch 1/25\n",
      "70/70 [==============================] - 2s 16ms/step - loss: 7386.9717 - val_loss: 5398.7271\n",
      "Epoch 2/25\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 6199.3091 - val_loss: 4785.5981\n",
      "Epoch 3/25\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 5582.1152 - val_loss: 4290.6216\n",
      "Epoch 4/25\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 5063.2290 - val_loss: 3866.4229\n",
      "Epoch 5/25\n",
      "70/70 [==============================] - 1s 13ms/step - loss: 4613.1758 - val_loss: 3500.5134\n",
      "Epoch 6/25\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 4209.4751 - val_loss: 3182.0190\n",
      "Epoch 7/25\n",
      "70/70 [==============================] - 1s 13ms/step - loss: 3861.9827 - val_loss: 2907.7122\n",
      "Epoch 8/25\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 3556.8923 - val_loss: 2671.8223\n",
      "Epoch 9/25\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 3287.6440 - val_loss: 2469.8525\n",
      "Epoch 10/25\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 3056.7100 - val_loss: 2298.8213\n",
      "Epoch 11/25\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 2856.5747 - val_loss: 2157.2908\n",
      "Epoch 12/25\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 2696.8049 - val_loss: 2039.5826\n",
      "Epoch 13/25\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 2551.1350 - val_loss: 1943.4742\n",
      "Epoch 14/25\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 2423.3320 - val_loss: 1866.1250\n",
      "Epoch 15/25\n",
      "70/70 [==============================] - 1s 13ms/step - loss: 2319.6394 - val_loss: 1797.8983\n",
      "Epoch 16/25\n",
      "70/70 [==============================] - 1s 13ms/step - loss: 2209.0803 - val_loss: 1683.0922\n",
      "Epoch 17/25\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 2040.6244 - val_loss: 1540.0759\n",
      "Epoch 18/25\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 1873.4171 - val_loss: 1379.1101\n",
      "Epoch 19/25\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 1694.0781 - val_loss: 1156.3777\n",
      "Epoch 20/25\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 1483.1664 - val_loss: 1081.9320\n",
      "Epoch 21/25\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 1380.8121 - val_loss: 1001.4594\n",
      "Epoch 22/25\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 1303.1821 - val_loss: 934.5851\n",
      "Epoch 23/25\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 1171.4838 - val_loss: 803.5941\n",
      "Epoch 24/25\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 1075.6292 - val_loss: 740.4417\n",
      "Epoch 25/25\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 989.6699 - val_loss: 695.5038\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "(17731, 30, 14) (17731, 1) (100, 30, 14)\n",
      "Epoch 1/25\n",
      "139/139 [==============================] - 8s 49ms/step - loss: 4590.8149 - val_loss: 2344.4924\n",
      "Epoch 2/25\n",
      "139/139 [==============================] - 7s 48ms/step - loss: 2414.5195 - val_loss: 1689.6812\n",
      "Epoch 3/25\n",
      "139/139 [==============================] - 7s 48ms/step - loss: 1946.6683 - val_loss: 1651.4851\n",
      "Epoch 4/25\n",
      "139/139 [==============================] - 7s 47ms/step - loss: 1668.1870 - val_loss: 1100.4780\n",
      "Epoch 5/25\n",
      "139/139 [==============================] - 7s 48ms/step - loss: 1029.4104 - val_loss: 807.1519\n",
      "Epoch 6/25\n",
      "139/139 [==============================] - 7s 49ms/step - loss: 666.0904 - val_loss: 518.2744\n",
      "Epoch 7/25\n",
      "139/139 [==============================] - 7s 48ms/step - loss: 552.7140 - val_loss: 406.0194\n",
      "Epoch 8/25\n",
      "139/139 [==============================] - 7s 47ms/step - loss: 429.0963 - val_loss: 327.5572\n",
      "Epoch 9/25\n",
      "139/139 [==============================] - 7s 48ms/step - loss: 287.6912 - val_loss: 281.4670\n",
      "Epoch 10/25\n",
      "139/139 [==============================] - 7s 49ms/step - loss: 260.4631 - val_loss: 249.5186\n",
      "Epoch 11/25\n",
      "139/139 [==============================] - 7s 49ms/step - loss: 235.9638 - val_loss: 290.2265\n",
      "Epoch 12/25\n",
      "139/139 [==============================] - 7s 48ms/step - loss: 231.8604 - val_loss: 246.9328\n",
      "Epoch 13/25\n",
      "139/139 [==============================] - 7s 49ms/step - loss: 225.6105 - val_loss: 325.7874\n",
      "Epoch 14/25\n",
      "139/139 [==============================] - 7s 48ms/step - loss: 231.1258 - val_loss: 208.8865\n",
      "Epoch 15/25\n",
      "139/139 [==============================] - 6s 46ms/step - loss: 214.0700 - val_loss: 214.3873\n",
      "Epoch 16/25\n",
      "139/139 [==============================] - 7s 48ms/step - loss: 221.6094 - val_loss: 215.2826\n",
      "Epoch 17/25\n",
      "139/139 [==============================] - 7s 48ms/step - loss: 213.7281 - val_loss: 253.2187\n",
      "Epoch 18/25\n",
      "139/139 [==============================] - 7s 48ms/step - loss: 210.9421 - val_loss: 207.8925\n",
      "Epoch 19/25\n",
      "139/139 [==============================] - 7s 48ms/step - loss: 207.7796 - val_loss: 204.6594\n",
      "Epoch 20/25\n",
      "139/139 [==============================] - 7s 49ms/step - loss: 209.4812 - val_loss: 202.0801\n",
      "Epoch 21/25\n",
      "139/139 [==============================] - 7s 49ms/step - loss: 202.1469 - val_loss: 217.6680\n",
      "Epoch 22/25\n",
      "139/139 [==============================] - 6s 46ms/step - loss: 202.6079 - val_loss: 226.5616\n",
      "Epoch 23/25\n",
      "139/139 [==============================] - 7s 47ms/step - loss: 205.4834 - val_loss: 211.9887\n",
      "Epoch 24/25\n",
      "139/139 [==============================] - 6s 47ms/step - loss: 205.0312 - val_loss: 223.6411\n",
      "Epoch 25/25\n",
      "139/139 [==============================] - 7s 47ms/step - loss: 203.5231 - val_loss: 246.2288\n",
      "4/4 [==============================] - 0s 6ms/step\n",
      "(17731, 30, 14) (17731, 1) (100, 30, 14)\n",
      "Epoch 1/25\n",
      "70/70 [==============================] - 2s 17ms/step - loss: 7415.2417 - val_loss: 5420.0464\n",
      "Epoch 2/25\n",
      "70/70 [==============================] - 1s 13ms/step - loss: 6226.2642 - val_loss: 4814.4204\n",
      "Epoch 3/25\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 5613.0093 - val_loss: 4320.0771\n",
      "Epoch 4/25\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 5085.9478 - val_loss: 3880.4182\n",
      "Epoch 5/25\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 4617.4546 - val_loss: 3506.3367\n",
      "Epoch 6/25\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 4208.8784 - val_loss: 3183.8047\n",
      "Epoch 7/25\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 3856.4150 - val_loss: 2906.8843\n",
      "Epoch 8/25\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 3544.0168 - val_loss: 2669.1108\n",
      "Epoch 9/25\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 3277.9563 - val_loss: 2466.2676\n",
      "Epoch 10/25\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 3043.3660 - val_loss: 2294.7292\n",
      "Epoch 11/25\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 2839.3647 - val_loss: 2152.8167\n",
      "Epoch 12/25\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 2670.6782 - val_loss: 2034.8851\n",
      "Epoch 13/25\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 2527.5710 - val_loss: 1938.7473\n",
      "Epoch 14/25\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 2401.8757 - val_loss: 1861.5620\n",
      "Epoch 15/25\n",
      "70/70 [==============================] - 1s 13ms/step - loss: 2297.2102 - val_loss: 1800.1782\n",
      "Epoch 16/25\n",
      "70/70 [==============================] - 1s 13ms/step - loss: 2214.7334 - val_loss: 1753.4839\n",
      "Epoch 17/25\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 2143.9570 - val_loss: 1717.9263\n",
      "Epoch 18/25\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 2078.6589 - val_loss: 1666.5597\n",
      "Epoch 19/25\n",
      "70/70 [==============================] - 1s 13ms/step - loss: 1942.9702 - val_loss: 1505.8032\n",
      "Epoch 20/25\n",
      "70/70 [==============================] - 1s 13ms/step - loss: 1786.0188 - val_loss: 1384.1753\n",
      "Epoch 21/25\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 1543.8586 - val_loss: 990.9896\n",
      "Epoch 22/25\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 1291.9490 - val_loss: 938.1796\n",
      "Epoch 23/25\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 1147.4817 - val_loss: 747.1564\n",
      "Epoch 24/25\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 986.3613 - val_loss: 591.3840\n",
      "Epoch 25/25\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 863.1768 - val_loss: 547.2188\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "(17731, 30, 14) (17731, 1) (100, 30, 14)\n",
      "Epoch 1/25\n",
      "555/555 [==============================] - 4s 6ms/step - loss: 5094.1772 - val_loss: 2712.8225\n",
      "Epoch 2/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 2708.1189 - val_loss: 1772.7153\n",
      "Epoch 3/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 2019.6483 - val_loss: 1507.9570\n",
      "Epoch 4/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 1100.0988 - val_loss: 566.4003\n",
      "Epoch 5/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 535.8532 - val_loss: 268.5986\n",
      "Epoch 6/25\n",
      "555/555 [==============================] - 3s 6ms/step - loss: 339.2650 - val_loss: 256.7603\n",
      "Epoch 7/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 271.6646 - val_loss: 213.3564\n",
      "Epoch 8/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 250.5331 - val_loss: 191.8277\n",
      "Epoch 9/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 237.4729 - val_loss: 223.9113\n",
      "Epoch 10/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 237.0430 - val_loss: 224.7336\n",
      "Epoch 11/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 225.3279 - val_loss: 194.8722\n",
      "Epoch 12/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 221.0128 - val_loss: 202.6768\n",
      "Epoch 13/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 222.4599 - val_loss: 239.3414\n",
      "Epoch 14/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 215.2683 - val_loss: 307.7054\n",
      "Epoch 15/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 219.6995 - val_loss: 203.1548\n",
      "Epoch 16/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 209.9532 - val_loss: 200.5512\n",
      "Epoch 17/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 209.2155 - val_loss: 191.2538\n",
      "Epoch 18/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 205.6446 - val_loss: 366.4722\n",
      "Epoch 19/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 213.3770 - val_loss: 207.0739\n",
      "Epoch 20/25\n",
      "555/555 [==============================] - 3s 6ms/step - loss: 206.0889 - val_loss: 187.4516\n",
      "Epoch 21/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 209.7749 - val_loss: 232.3168\n",
      "Epoch 22/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 209.4680 - val_loss: 213.6536\n",
      "Epoch 23/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 204.2455 - val_loss: 194.9564\n",
      "Epoch 24/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 205.2278 - val_loss: 194.3798\n",
      "Epoch 25/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 199.5573 - val_loss: 230.4703\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "(17731, 30, 14) (17731, 1) (100, 30, 14)\n",
      "Epoch 1/25\n",
      "278/278 [==============================] - 9s 29ms/step - loss: 3403.2891 - val_loss: 1679.3540\n",
      "Epoch 2/25\n",
      "278/278 [==============================] - 8s 28ms/step - loss: 1906.6392 - val_loss: 1524.7991\n",
      "Epoch 3/25\n",
      "278/278 [==============================] - 8s 29ms/step - loss: 1185.7504 - val_loss: 1003.4642\n",
      "Epoch 4/25\n",
      "278/278 [==============================] - 8s 30ms/step - loss: 699.1370 - val_loss: 432.1667\n",
      "Epoch 5/25\n",
      "278/278 [==============================] - 8s 30ms/step - loss: 422.0059 - val_loss: 296.6501\n",
      "Epoch 6/25\n",
      "278/278 [==============================] - 8s 29ms/step - loss: 318.2255 - val_loss: 489.8214\n",
      "Epoch 7/25\n",
      "278/278 [==============================] - 8s 29ms/step - loss: 282.4977 - val_loss: 224.7119\n",
      "Epoch 8/25\n",
      "278/278 [==============================] - 8s 29ms/step - loss: 259.2817 - val_loss: 228.4612\n",
      "Epoch 9/25\n",
      "278/278 [==============================] - 8s 29ms/step - loss: 254.3551 - val_loss: 237.8799\n",
      "Epoch 10/25\n",
      "278/278 [==============================] - 8s 29ms/step - loss: 240.7124 - val_loss: 366.7810\n",
      "Epoch 11/25\n",
      "278/278 [==============================] - 8s 30ms/step - loss: 238.0349 - val_loss: 264.1410\n",
      "Epoch 12/25\n",
      "278/278 [==============================] - 10s 37ms/step - loss: 239.1246 - val_loss: 333.4411\n",
      "Epoch 13/25\n",
      "278/278 [==============================] - 9s 32ms/step - loss: 227.6095 - val_loss: 247.5136\n",
      "Epoch 14/25\n",
      "278/278 [==============================] - 8s 28ms/step - loss: 216.0195 - val_loss: 550.0647\n",
      "Epoch 15/25\n",
      "278/278 [==============================] - 8s 29ms/step - loss: 252.8741 - val_loss: 198.5271\n",
      "Epoch 16/25\n",
      "278/278 [==============================] - 8s 29ms/step - loss: 216.1367 - val_loss: 320.7354\n",
      "Epoch 17/25\n",
      "278/278 [==============================] - 8s 29ms/step - loss: 225.6310 - val_loss: 222.9040\n",
      "Epoch 18/25\n",
      "278/278 [==============================] - 8s 29ms/step - loss: 221.6061 - val_loss: 265.5307\n",
      "Epoch 19/25\n",
      "278/278 [==============================] - 8s 29ms/step - loss: 214.9282 - val_loss: 241.1892\n",
      "Epoch 20/25\n",
      "278/278 [==============================] - 8s 29ms/step - loss: 215.9507 - val_loss: 220.2006\n",
      "Epoch 21/25\n",
      "278/278 [==============================] - 8s 29ms/step - loss: 216.2590 - val_loss: 225.6033\n",
      "Epoch 22/25\n",
      "278/278 [==============================] - 8s 29ms/step - loss: 212.0428 - val_loss: 226.2557\n",
      "Epoch 23/25\n",
      "278/278 [==============================] - 8s 29ms/step - loss: 210.6883 - val_loss: 215.2021\n",
      "Epoch 24/25\n",
      "278/278 [==============================] - 8s 29ms/step - loss: 202.3891 - val_loss: 201.5022\n",
      "Epoch 25/25\n",
      "278/278 [==============================] - 8s 29ms/step - loss: 205.4915 - val_loss: 232.5218\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "(17731, 30, 14) (17731, 1) (100, 30, 14)\n",
      "Epoch 1/25\n",
      "70/70 [==============================] - 5s 58ms/step - loss: 5523.7271 - val_loss: 3268.5703\n",
      "Epoch 2/25\n",
      "70/70 [==============================] - 4s 56ms/step - loss: 3456.3645 - val_loss: 2264.4617\n",
      "Epoch 3/25\n",
      "70/70 [==============================] - 4s 56ms/step - loss: 2562.1316 - val_loss: 1825.0886\n",
      "Epoch 4/25\n",
      "70/70 [==============================] - 4s 56ms/step - loss: 2143.9758 - val_loss: 1675.5005\n",
      "Epoch 5/25\n",
      "70/70 [==============================] - 4s 55ms/step - loss: 1970.5013 - val_loss: 1648.3228\n",
      "Epoch 6/25\n",
      "70/70 [==============================] - 4s 55ms/step - loss: 1890.2592 - val_loss: 1588.4222\n",
      "Epoch 7/25\n",
      "70/70 [==============================] - 4s 56ms/step - loss: 1666.0521 - val_loss: 1339.2612\n",
      "Epoch 8/25\n",
      "70/70 [==============================] - 4s 55ms/step - loss: 1211.0486 - val_loss: 852.7277\n",
      "Epoch 9/25\n",
      "70/70 [==============================] - 4s 55ms/step - loss: 887.0055 - val_loss: 860.0070\n",
      "Epoch 10/25\n",
      "70/70 [==============================] - 4s 55ms/step - loss: 724.5353 - val_loss: 480.3594\n",
      "Epoch 11/25\n",
      "70/70 [==============================] - 4s 56ms/step - loss: 583.1975 - val_loss: 366.7698\n",
      "Epoch 12/25\n",
      "70/70 [==============================] - 4s 56ms/step - loss: 440.8648 - val_loss: 284.2975\n",
      "Epoch 13/25\n",
      "70/70 [==============================] - 4s 55ms/step - loss: 433.8904 - val_loss: 320.8735\n",
      "Epoch 14/25\n",
      "70/70 [==============================] - 4s 57ms/step - loss: 318.5047 - val_loss: 247.8480\n",
      "Epoch 15/25\n",
      "70/70 [==============================] - 4s 55ms/step - loss: 275.6437 - val_loss: 283.9590\n",
      "Epoch 16/25\n",
      "70/70 [==============================] - 4s 56ms/step - loss: 276.8068 - val_loss: 243.8335\n",
      "Epoch 17/25\n",
      "70/70 [==============================] - 4s 56ms/step - loss: 294.2203 - val_loss: 223.4542\n",
      "Epoch 18/25\n",
      "70/70 [==============================] - 4s 55ms/step - loss: 252.9133 - val_loss: 273.1831\n",
      "Epoch 19/25\n",
      "70/70 [==============================] - 4s 57ms/step - loss: 259.6694 - val_loss: 209.5853\n",
      "Epoch 20/25\n",
      "70/70 [==============================] - 4s 57ms/step - loss: 246.3482 - val_loss: 222.8024\n",
      "Epoch 21/25\n",
      "70/70 [==============================] - 4s 57ms/step - loss: 248.5211 - val_loss: 219.0323\n",
      "Epoch 22/25\n",
      "70/70 [==============================] - 4s 55ms/step - loss: 244.8611 - val_loss: 330.1161\n",
      "Epoch 23/25\n",
      "70/70 [==============================] - 4s 56ms/step - loss: 247.5885 - val_loss: 242.1104\n",
      "Epoch 24/25\n",
      "70/70 [==============================] - 4s 56ms/step - loss: 252.8489 - val_loss: 201.1596\n",
      "Epoch 25/25\n",
      "70/70 [==============================] - 4s 56ms/step - loss: 232.1712 - val_loss: 295.2489\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "(17731, 30, 14) (17731, 1) (100, 30, 14)\n",
      "Epoch 1/25\n",
      "555/555 [==============================] - 6s 8ms/step - loss: 3689.1646 - val_loss: 1725.5861\n",
      "Epoch 2/25\n",
      "555/555 [==============================] - 4s 8ms/step - loss: 1632.3035 - val_loss: 771.5289\n",
      "Epoch 3/25\n",
      "555/555 [==============================] - 4s 8ms/step - loss: 607.3324 - val_loss: 259.0701\n",
      "Epoch 4/25\n",
      "555/555 [==============================] - 4s 8ms/step - loss: 317.7441 - val_loss: 250.4668\n",
      "Epoch 5/25\n",
      "555/555 [==============================] - 5s 8ms/step - loss: 255.3012 - val_loss: 204.7790\n",
      "Epoch 6/25\n",
      "555/555 [==============================] - 5s 8ms/step - loss: 241.2934 - val_loss: 364.9646\n",
      "Epoch 7/25\n",
      "555/555 [==============================] - 4s 8ms/step - loss: 233.3026 - val_loss: 211.0732\n",
      "Epoch 8/25\n",
      "555/555 [==============================] - 4s 8ms/step - loss: 225.8367 - val_loss: 210.7957\n",
      "Epoch 9/25\n",
      "555/555 [==============================] - 4s 8ms/step - loss: 214.9785 - val_loss: 246.8260\n",
      "Epoch 10/25\n",
      "555/555 [==============================] - 4s 8ms/step - loss: 216.5598 - val_loss: 243.3417\n",
      "Epoch 11/25\n",
      "555/555 [==============================] - 4s 8ms/step - loss: 204.6523 - val_loss: 194.5764\n",
      "Epoch 12/25\n",
      "555/555 [==============================] - 4s 8ms/step - loss: 204.9576 - val_loss: 196.4929\n",
      "Epoch 13/25\n",
      "555/555 [==============================] - 5s 8ms/step - loss: 205.1803 - val_loss: 254.3494\n",
      "Epoch 14/25\n",
      "555/555 [==============================] - 4s 8ms/step - loss: 193.1801 - val_loss: 248.9628\n",
      "Epoch 15/25\n",
      "555/555 [==============================] - 4s 8ms/step - loss: 203.8797 - val_loss: 208.3826\n",
      "Epoch 16/25\n",
      "555/555 [==============================] - 4s 8ms/step - loss: 194.9041 - val_loss: 230.2508\n",
      "Epoch 17/25\n",
      "555/555 [==============================] - 4s 8ms/step - loss: 197.2573 - val_loss: 229.1492\n",
      "Epoch 18/25\n",
      "555/555 [==============================] - 4s 8ms/step - loss: 194.9945 - val_loss: 304.4415\n",
      "Epoch 19/25\n",
      "555/555 [==============================] - 5s 8ms/step - loss: 191.5911 - val_loss: 203.2614\n",
      "Epoch 20/25\n",
      "555/555 [==============================] - 5s 8ms/step - loss: 189.6496 - val_loss: 264.4165\n",
      "Epoch 21/25\n",
      "555/555 [==============================] - 4s 8ms/step - loss: 187.3821 - val_loss: 211.1185\n",
      "Epoch 22/25\n",
      "555/555 [==============================] - 5s 8ms/step - loss: 187.3107 - val_loss: 210.1055\n",
      "Epoch 23/25\n",
      "555/555 [==============================] - 4s 8ms/step - loss: 184.5204 - val_loss: 204.0324\n",
      "Epoch 24/25\n",
      "555/555 [==============================] - 4s 8ms/step - loss: 184.9953 - val_loss: 198.0435\n",
      "Epoch 25/25\n",
      "555/555 [==============================] - 4s 8ms/step - loss: 182.1208 - val_loss: 213.2263\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "(17731, 30, 14) (17731, 1) (100, 30, 14)\n",
      "Epoch 1/25\n",
      "555/555 [==============================] - 5s 8ms/step - loss: 3614.1396 - val_loss: 1718.4419\n",
      "Epoch 2/25\n",
      "555/555 [==============================] - 4s 8ms/step - loss: 1925.2205 - val_loss: 1512.1876\n",
      "Epoch 3/25\n",
      "555/555 [==============================] - 5s 8ms/step - loss: 934.2289 - val_loss: 453.0723\n",
      "Epoch 4/25\n",
      "555/555 [==============================] - 4s 8ms/step - loss: 365.7335 - val_loss: 300.9948\n",
      "Epoch 5/25\n",
      "555/555 [==============================] - 5s 8ms/step - loss: 255.9804 - val_loss: 240.1520\n",
      "Epoch 6/25\n",
      "555/555 [==============================] - 4s 8ms/step - loss: 232.8988 - val_loss: 324.5435\n",
      "Epoch 7/25\n",
      "555/555 [==============================] - 5s 8ms/step - loss: 215.5842 - val_loss: 235.8130\n",
      "Epoch 8/25\n",
      "555/555 [==============================] - 5s 8ms/step - loss: 212.4487 - val_loss: 211.7831\n",
      "Epoch 9/25\n",
      "555/555 [==============================] - 5s 8ms/step - loss: 205.7083 - val_loss: 233.6132\n",
      "Epoch 10/25\n",
      "555/555 [==============================] - 5s 8ms/step - loss: 203.1265 - val_loss: 201.9371\n",
      "Epoch 11/25\n",
      "555/555 [==============================] - 5s 8ms/step - loss: 198.3912 - val_loss: 263.1817\n",
      "Epoch 12/25\n",
      "555/555 [==============================] - 4s 8ms/step - loss: 198.6820 - val_loss: 202.3593\n",
      "Epoch 13/25\n",
      "555/555 [==============================] - 4s 8ms/step - loss: 195.8775 - val_loss: 225.0216\n",
      "Epoch 14/25\n",
      "555/555 [==============================] - 4s 8ms/step - loss: 193.2920 - val_loss: 201.8443\n",
      "Epoch 15/25\n",
      "555/555 [==============================] - 4s 8ms/step - loss: 194.9133 - val_loss: 218.9125\n",
      "Epoch 16/25\n",
      "555/555 [==============================] - 5s 8ms/step - loss: 191.5149 - val_loss: 247.0722\n",
      "Epoch 17/25\n",
      "555/555 [==============================] - 5s 9ms/step - loss: 192.6887 - val_loss: 222.5779\n",
      "Epoch 18/25\n",
      "555/555 [==============================] - 4s 8ms/step - loss: 192.9050 - val_loss: 215.5981\n",
      "Epoch 19/25\n",
      "555/555 [==============================] - 4s 8ms/step - loss: 189.8208 - val_loss: 209.9512\n",
      "Epoch 20/25\n",
      "555/555 [==============================] - 4s 8ms/step - loss: 187.8149 - val_loss: 241.6630\n",
      "Epoch 21/25\n",
      "555/555 [==============================] - 4s 8ms/step - loss: 187.4481 - val_loss: 213.2956\n",
      "Epoch 22/25\n",
      "555/555 [==============================] - 4s 8ms/step - loss: 184.4236 - val_loss: 218.2006\n",
      "Epoch 23/25\n",
      "555/555 [==============================] - 5s 8ms/step - loss: 185.8752 - val_loss: 219.4102\n",
      "Epoch 24/25\n",
      "555/555 [==============================] - 5s 8ms/step - loss: 185.4364 - val_loss: 210.7032\n",
      "Epoch 25/25\n",
      "555/555 [==============================] - 4s 8ms/step - loss: 183.2102 - val_loss: 234.8960\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "(17731, 30, 14) (17731, 1) (100, 30, 14)\n",
      "Epoch 1/25\n",
      "139/139 [==============================] - 3s 13ms/step - loss: 6930.4961 - val_loss: 4894.8643\n",
      "Epoch 2/25\n",
      "139/139 [==============================] - 1s 10ms/step - loss: 5425.0898 - val_loss: 3947.3721\n",
      "Epoch 3/25\n",
      "139/139 [==============================] - 1s 10ms/step - loss: 4487.0439 - val_loss: 3244.7976\n",
      "Epoch 4/25\n",
      "139/139 [==============================] - 2s 12ms/step - loss: 3770.5205 - val_loss: 2720.1909\n",
      "Epoch 5/25\n",
      "139/139 [==============================] - 1s 10ms/step - loss: 3226.8860 - val_loss: 2338.5010\n",
      "Epoch 6/25\n",
      "139/139 [==============================] - 2s 12ms/step - loss: 2809.1252 - val_loss: 2067.3994\n",
      "Epoch 7/25\n",
      "139/139 [==============================] - 1s 11ms/step - loss: 2514.5178 - val_loss: 1885.2081\n",
      "Epoch 8/25\n",
      "139/139 [==============================] - 1s 10ms/step - loss: 2293.9578 - val_loss: 1769.3068\n",
      "Epoch 9/25\n",
      "139/139 [==============================] - 2s 12ms/step - loss: 2138.4849 - val_loss: 1662.8129\n",
      "Epoch 10/25\n",
      "139/139 [==============================] - 1s 11ms/step - loss: 1853.5338 - val_loss: 1301.4132\n",
      "Epoch 11/25\n",
      "139/139 [==============================] - 2s 11ms/step - loss: 1478.9941 - val_loss: 1004.1407\n",
      "Epoch 12/25\n",
      "139/139 [==============================] - 2s 11ms/step - loss: 1154.7745 - val_loss: 747.9731\n",
      "Epoch 13/25\n",
      "139/139 [==============================] - 2s 11ms/step - loss: 954.1006 - val_loss: 568.3851\n",
      "Epoch 14/25\n",
      "139/139 [==============================] - 2s 11ms/step - loss: 749.7291 - val_loss: 400.1183\n",
      "Epoch 15/25\n",
      "139/139 [==============================] - 2s 11ms/step - loss: 600.3862 - val_loss: 317.3217\n",
      "Epoch 16/25\n",
      "139/139 [==============================] - 2s 11ms/step - loss: 509.3484 - val_loss: 276.4172\n",
      "Epoch 17/25\n",
      "139/139 [==============================] - 2s 11ms/step - loss: 461.7752 - val_loss: 282.5722\n",
      "Epoch 18/25\n",
      "139/139 [==============================] - 1s 11ms/step - loss: 393.1919 - val_loss: 234.1285\n",
      "Epoch 19/25\n",
      "139/139 [==============================] - 2s 12ms/step - loss: 357.1394 - val_loss: 232.6389\n",
      "Epoch 20/25\n",
      "139/139 [==============================] - 1s 11ms/step - loss: 340.7932 - val_loss: 239.8880\n",
      "Epoch 21/25\n",
      "139/139 [==============================] - 2s 11ms/step - loss: 306.9099 - val_loss: 217.6729\n",
      "Epoch 22/25\n",
      "139/139 [==============================] - 2s 11ms/step - loss: 295.1062 - val_loss: 236.5037\n",
      "Epoch 23/25\n",
      "139/139 [==============================] - 1s 11ms/step - loss: 273.1095 - val_loss: 189.5091\n",
      "Epoch 24/25\n",
      "139/139 [==============================] - 2s 12ms/step - loss: 289.5009 - val_loss: 227.2847\n",
      "Epoch 25/25\n",
      "139/139 [==============================] - 2s 11ms/step - loss: 254.2691 - val_loss: 267.8202\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "iteration  20\n",
      "(17731, 30, 14) (17731, 1) (100, 30, 14)\n",
      "Epoch 1/25\n",
      "555/555 [==============================] - 4s 5ms/step - loss: 6243.8677 - val_loss: 4085.0981\n",
      "Epoch 2/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 4271.3691 - val_loss: 2820.6226\n",
      "Epoch 3/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 3109.6775 - val_loss: 2113.7627\n",
      "Epoch 4/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 2378.5388 - val_loss: 1631.9705\n",
      "Epoch 5/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 1708.2719 - val_loss: 897.6163\n",
      "Epoch 6/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 987.3971 - val_loss: 512.1526\n",
      "Epoch 7/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 640.0212 - val_loss: 297.6344\n",
      "Epoch 8/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 453.7517 - val_loss: 243.8821\n",
      "Epoch 9/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 354.9994 - val_loss: 237.7763\n",
      "Epoch 10/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 294.7919 - val_loss: 200.5013\n",
      "Epoch 11/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 264.7593 - val_loss: 216.3324\n",
      "Epoch 12/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 257.3853 - val_loss: 193.5889\n",
      "Epoch 13/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 243.9169 - val_loss: 222.1783\n",
      "Epoch 14/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 236.1415 - val_loss: 199.3580\n",
      "Epoch 15/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 240.0739 - val_loss: 200.5492\n",
      "Epoch 16/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 234.3884 - val_loss: 210.6637\n",
      "Epoch 17/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 238.0304 - val_loss: 205.8286\n",
      "Epoch 18/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 233.8859 - val_loss: 242.1140\n",
      "Epoch 19/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 231.9911 - val_loss: 193.3094\n",
      "Epoch 20/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 230.1198 - val_loss: 242.7047\n",
      "Epoch 21/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 226.1737 - val_loss: 208.4575\n",
      "Epoch 22/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 226.2239 - val_loss: 196.3152\n",
      "Epoch 23/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 225.8329 - val_loss: 191.1848\n",
      "Epoch 24/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 223.6910 - val_loss: 188.7112\n",
      "Epoch 25/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 223.4736 - val_loss: 223.3922\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "(17731, 30, 14) (17731, 1) (100, 30, 14)\n",
      "Epoch 1/25\n",
      "278/278 [==============================] - 3s 6ms/step - loss: 7208.6851 - val_loss: 5217.8086\n",
      "Epoch 2/25\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 5773.8530 - val_loss: 4239.4062\n",
      "Epoch 3/25\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 4798.5894 - val_loss: 3488.8662\n",
      "Epoch 4/25\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 4027.9060 - val_loss: 2910.3005\n",
      "Epoch 5/25\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 3422.2920 - val_loss: 2475.5581\n",
      "Epoch 6/25\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 2956.6382 - val_loss: 2158.2109\n",
      "Epoch 7/25\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 2607.7852 - val_loss: 1937.9027\n",
      "Epoch 8/25\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 2293.3174 - val_loss: 1604.8690\n",
      "Epoch 9/25\n",
      "278/278 [==============================] - 2s 5ms/step - loss: 1858.9821 - val_loss: 1128.1603\n",
      "Epoch 10/25\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 1424.2963 - val_loss: 930.8431\n",
      "Epoch 11/25\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 1104.9288 - val_loss: 614.6732\n",
      "Epoch 12/25\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 864.8949 - val_loss: 508.1195\n",
      "Epoch 13/25\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 700.6207 - val_loss: 364.3159\n",
      "Epoch 14/25\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 578.4339 - val_loss: 334.5070\n",
      "Epoch 15/25\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 488.6364 - val_loss: 283.6866\n",
      "Epoch 16/25\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 415.0144 - val_loss: 251.5166\n",
      "Epoch 17/25\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 362.1434 - val_loss: 233.4757\n",
      "Epoch 18/25\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 327.5449 - val_loss: 228.5089\n",
      "Epoch 19/25\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 300.5171 - val_loss: 230.8995\n",
      "Epoch 20/25\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 276.5596 - val_loss: 258.9701\n",
      "Epoch 21/25\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 263.5960 - val_loss: 196.3680\n",
      "Epoch 22/25\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 260.9262 - val_loss: 229.5900\n",
      "Epoch 23/25\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 249.7019 - val_loss: 211.9592\n",
      "Epoch 24/25\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 244.0597 - val_loss: 206.3777\n",
      "Epoch 25/25\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 248.8215 - val_loss: 243.2814\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "(17731, 30, 14) (17731, 1) (100, 30, 14)\n",
      "Epoch 1/25\n",
      "139/139 [==============================] - 2s 8ms/step - loss: 7316.2769 - val_loss: 5505.8306\n",
      "Epoch 2/25\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 6336.3779 - val_loss: 4927.5430\n",
      "Epoch 3/25\n",
      "139/139 [==============================] - 1s 7ms/step - loss: 5742.5400 - val_loss: 4437.9941\n",
      "Epoch 4/25\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 5220.4180 - val_loss: 4009.2029\n",
      "Epoch 5/25\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 4763.6982 - val_loss: 3633.6335\n",
      "Epoch 6/25\n",
      "139/139 [==============================] - 1s 7ms/step - loss: 4352.8936 - val_loss: 3302.9988\n",
      "Epoch 7/25\n",
      "139/139 [==============================] - 1s 7ms/step - loss: 3994.4426 - val_loss: 3014.9028\n",
      "Epoch 8/25\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 3675.5278 - val_loss: 2764.6978\n",
      "Epoch 9/25\n",
      "139/139 [==============================] - 1s 7ms/step - loss: 3397.1863 - val_loss: 2548.7263\n",
      "Epoch 10/25\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 3150.1841 - val_loss: 2364.1497\n",
      "Epoch 11/25\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 2933.6160 - val_loss: 2208.5388\n",
      "Epoch 12/25\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 2753.3794 - val_loss: 2078.1968\n",
      "Epoch 13/25\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 2595.7229 - val_loss: 1970.9978\n",
      "Epoch 14/25\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 2466.0276 - val_loss: 1884.4728\n",
      "Epoch 15/25\n",
      "139/139 [==============================] - 1s 7ms/step - loss: 2355.9675 - val_loss: 1814.7150\n",
      "Epoch 16/25\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 2219.7473 - val_loss: 1665.7427\n",
      "Epoch 17/25\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 2039.2142 - val_loss: 1530.5955\n",
      "Epoch 18/25\n",
      "139/139 [==============================] - 1s 7ms/step - loss: 1871.5824 - val_loss: 1358.5085\n",
      "Epoch 19/25\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 1681.1664 - val_loss: 1152.8086\n",
      "Epoch 20/25\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 1403.8672 - val_loss: 901.4885\n",
      "Epoch 21/25\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 1217.2400 - val_loss: 726.4355\n",
      "Epoch 22/25\n",
      "139/139 [==============================] - 1s 7ms/step - loss: 1082.5118 - val_loss: 629.7018\n",
      "Epoch 23/25\n",
      "139/139 [==============================] - 1s 7ms/step - loss: 964.2249 - val_loss: 538.2543\n",
      "Epoch 24/25\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 850.3601 - val_loss: 464.0928\n",
      "Epoch 25/25\n",
      "139/139 [==============================] - 1s 7ms/step - loss: 767.6024 - val_loss: 413.5914\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "(17731, 30, 14) (17731, 1) (100, 30, 14)\n",
      "Epoch 1/25\n",
      "555/555 [==============================] - 4s 5ms/step - loss: 6216.8047 - val_loss: 4060.9014\n",
      "Epoch 2/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 4248.4126 - val_loss: 2804.7451\n",
      "Epoch 3/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 3074.1626 - val_loss: 2015.9237\n",
      "Epoch 4/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 2243.2656 - val_loss: 1449.5288\n",
      "Epoch 5/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 1492.1880 - val_loss: 902.5123\n",
      "Epoch 6/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 1001.3698 - val_loss: 510.0243\n",
      "Epoch 7/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 672.6681 - val_loss: 352.6879\n",
      "Epoch 8/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 480.9753 - val_loss: 248.6196\n",
      "Epoch 9/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 381.7720 - val_loss: 308.1570\n",
      "Epoch 10/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 325.1301 - val_loss: 232.6589\n",
      "Epoch 11/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 287.9756 - val_loss: 235.2531\n",
      "Epoch 12/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 280.1999 - val_loss: 196.8558\n",
      "Epoch 13/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 262.7235 - val_loss: 224.0606\n",
      "Epoch 14/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 250.8217 - val_loss: 187.1585\n",
      "Epoch 15/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 256.7044 - val_loss: 202.5939\n",
      "Epoch 16/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 246.4820 - val_loss: 193.2311\n",
      "Epoch 17/25\n",
      "555/555 [==============================] - 2s 4ms/step - loss: 246.6266 - val_loss: 193.3313\n",
      "Epoch 18/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 244.5455 - val_loss: 218.6934\n",
      "Epoch 19/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 239.8796 - val_loss: 194.1876\n",
      "Epoch 20/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 237.1041 - val_loss: 225.0751\n",
      "Epoch 21/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 232.0989 - val_loss: 204.5292\n",
      "Epoch 22/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 230.8937 - val_loss: 182.7525\n",
      "Epoch 23/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 231.6613 - val_loss: 183.1341\n",
      "Epoch 24/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 230.4131 - val_loss: 186.5785\n",
      "Epoch 25/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 229.5043 - val_loss: 245.2216\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "(17731, 30, 14) (17731, 1) (100, 30, 14)\n",
      "Epoch 1/25\n",
      "70/70 [==============================] - 2s 15ms/step - loss: 7943.7773 - val_loss: 6033.9663\n",
      "Epoch 2/25\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 7001.4604 - val_loss: 5602.9326\n",
      "Epoch 3/25\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 6598.0601 - val_loss: 5284.2207\n",
      "Epoch 4/25\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 6263.7988 - val_loss: 5000.0947\n",
      "Epoch 5/25\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 5960.1797 - val_loss: 4739.4224\n",
      "Epoch 6/25\n",
      "70/70 [==============================] - 1s 10ms/step - loss: 5674.9150 - val_loss: 4496.3286\n",
      "Epoch 7/25\n",
      "70/70 [==============================] - 1s 10ms/step - loss: 5414.9536 - val_loss: 4269.8843\n",
      "Epoch 8/25\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 5160.5020 - val_loss: 4057.5227\n",
      "Epoch 9/25\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 4930.8579 - val_loss: 3858.6179\n",
      "Epoch 10/25\n",
      "70/70 [==============================] - 1s 10ms/step - loss: 4709.3726 - val_loss: 3672.0930\n",
      "Epoch 11/25\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 4501.2427 - val_loss: 3498.7607\n",
      "Epoch 12/25\n",
      "70/70 [==============================] - 1s 10ms/step - loss: 4307.5273 - val_loss: 3336.0312\n",
      "Epoch 13/25\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 4128.4072 - val_loss: 3184.1013\n",
      "Epoch 14/25\n",
      "70/70 [==============================] - 1s 10ms/step - loss: 3954.0159 - val_loss: 3042.5605\n",
      "Epoch 15/25\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 3794.6797 - val_loss: 2910.2122\n",
      "Epoch 16/25\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 3639.3689 - val_loss: 2787.8293\n",
      "Epoch 17/25\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 3500.6221 - val_loss: 2673.5576\n",
      "Epoch 18/25\n",
      "70/70 [==============================] - 1s 10ms/step - loss: 3365.3181 - val_loss: 2567.9087\n",
      "Epoch 19/25\n",
      "70/70 [==============================] - 1s 10ms/step - loss: 3252.4827 - val_loss: 2470.1680\n",
      "Epoch 20/25\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 3132.4612 - val_loss: 2380.1965\n",
      "Epoch 21/25\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 3020.6504 - val_loss: 2297.3860\n",
      "Epoch 22/25\n",
      "70/70 [==============================] - 1s 10ms/step - loss: 2917.5706 - val_loss: 2221.5312\n",
      "Epoch 23/25\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 2826.0745 - val_loss: 2148.0747\n",
      "Epoch 24/25\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 2717.8254 - val_loss: 2046.4945\n",
      "Epoch 25/25\n",
      "70/70 [==============================] - 1s 10ms/step - loss: 2589.1726 - val_loss: 1934.4875\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "(17731, 30, 14) (17731, 1) (100, 30, 14)\n",
      "Epoch 1/25\n",
      "555/555 [==============================] - 6s 9ms/step - loss: 3683.6738 - val_loss: 1726.6694\n",
      "Epoch 2/25\n",
      "555/555 [==============================] - 5s 8ms/step - loss: 1942.2476 - val_loss: 1685.5557\n",
      "Epoch 3/25\n",
      "555/555 [==============================] - 4s 8ms/step - loss: 1734.3562 - val_loss: 914.5074\n",
      "Epoch 4/25\n",
      "555/555 [==============================] - 5s 9ms/step - loss: 837.5177 - val_loss: 527.8858\n",
      "Epoch 5/25\n",
      "555/555 [==============================] - 4s 8ms/step - loss: 421.6789 - val_loss: 251.3920\n",
      "Epoch 6/25\n",
      "555/555 [==============================] - 5s 8ms/step - loss: 298.0998 - val_loss: 392.7432\n",
      "Epoch 7/25\n",
      "555/555 [==============================] - 4s 8ms/step - loss: 258.3945 - val_loss: 268.6082\n",
      "Epoch 8/25\n",
      "555/555 [==============================] - 4s 8ms/step - loss: 256.5746 - val_loss: 272.6235\n",
      "Epoch 9/25\n",
      "555/555 [==============================] - 4s 8ms/step - loss: 230.4080 - val_loss: 267.1009\n",
      "Epoch 10/25\n",
      "555/555 [==============================] - 5s 8ms/step - loss: 228.5376 - val_loss: 241.5671\n",
      "Epoch 11/25\n",
      "555/555 [==============================] - 4s 8ms/step - loss: 220.2201 - val_loss: 214.1318\n",
      "Epoch 12/25\n",
      "555/555 [==============================] - 5s 8ms/step - loss: 215.6343 - val_loss: 208.4552\n",
      "Epoch 13/25\n",
      "555/555 [==============================] - 5s 8ms/step - loss: 216.8871 - val_loss: 235.4676\n",
      "Epoch 14/25\n",
      "555/555 [==============================] - 5s 8ms/step - loss: 207.6164 - val_loss: 239.3871\n",
      "Epoch 15/25\n",
      "555/555 [==============================] - 4s 8ms/step - loss: 211.2883 - val_loss: 215.4417\n",
      "Epoch 16/25\n",
      "555/555 [==============================] - 5s 8ms/step - loss: 206.7024 - val_loss: 243.5002\n",
      "Epoch 17/25\n",
      "555/555 [==============================] - 5s 8ms/step - loss: 208.8134 - val_loss: 240.0278\n",
      "Epoch 18/25\n",
      "555/555 [==============================] - 5s 8ms/step - loss: 205.6350 - val_loss: 320.5638\n",
      "Epoch 19/25\n",
      "555/555 [==============================] - 5s 8ms/step - loss: 204.5055 - val_loss: 216.7484\n",
      "Epoch 20/25\n",
      "555/555 [==============================] - 5s 8ms/step - loss: 198.9277 - val_loss: 242.9374\n",
      "Epoch 21/25\n",
      "555/555 [==============================] - 5s 9ms/step - loss: 195.6534 - val_loss: 228.9779\n",
      "Epoch 22/25\n",
      "555/555 [==============================] - 5s 8ms/step - loss: 193.7479 - val_loss: 234.4716\n",
      "Epoch 23/25\n",
      "555/555 [==============================] - 5s 8ms/step - loss: 193.9086 - val_loss: 219.2604\n",
      "Epoch 24/25\n",
      "555/555 [==============================] - 4s 8ms/step - loss: 193.4365 - val_loss: 214.0357\n",
      "Epoch 25/25\n",
      "555/555 [==============================] - 4s 8ms/step - loss: 189.7243 - val_loss: 235.6927\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "(17731, 30, 14) (17731, 1) (100, 30, 14)\n",
      "Epoch 1/25\n",
      "70/70 [==============================] - 5s 59ms/step - loss: 5499.0205 - val_loss: 3232.5115\n",
      "Epoch 2/25\n",
      "70/70 [==============================] - 4s 55ms/step - loss: 3426.4731 - val_loss: 2248.0237\n",
      "Epoch 3/25\n",
      "70/70 [==============================] - 4s 56ms/step - loss: 2539.6565 - val_loss: 1813.4153\n",
      "Epoch 4/25\n",
      "70/70 [==============================] - 4s 56ms/step - loss: 2126.4929 - val_loss: 1673.5520\n",
      "Epoch 5/25\n",
      "70/70 [==============================] - 4s 57ms/step - loss: 1959.5597 - val_loss: 1654.6069\n",
      "Epoch 6/25\n",
      "70/70 [==============================] - 4s 56ms/step - loss: 1895.6781 - val_loss: 1625.3431\n",
      "Epoch 7/25\n",
      "70/70 [==============================] - 4s 58ms/step - loss: 1688.0470 - val_loss: 1232.5686\n",
      "Epoch 8/25\n",
      "70/70 [==============================] - 4s 55ms/step - loss: 1053.2672 - val_loss: 648.8193\n",
      "Epoch 9/25\n",
      "70/70 [==============================] - 4s 56ms/step - loss: 865.0828 - val_loss: 636.4933\n",
      "Epoch 10/25\n",
      "70/70 [==============================] - 4s 57ms/step - loss: 595.1739 - val_loss: 524.0062\n",
      "Epoch 11/25\n",
      "70/70 [==============================] - 4s 56ms/step - loss: 421.4862 - val_loss: 270.2454\n",
      "Epoch 12/25\n",
      "70/70 [==============================] - 4s 59ms/step - loss: 351.1823 - val_loss: 220.6932\n",
      "Epoch 13/25\n",
      "70/70 [==============================] - 4s 58ms/step - loss: 302.5329 - val_loss: 227.2782\n",
      "Epoch 14/25\n",
      "70/70 [==============================] - 4s 57ms/step - loss: 279.7160 - val_loss: 209.2865\n",
      "Epoch 15/25\n",
      "70/70 [==============================] - 4s 56ms/step - loss: 253.9058 - val_loss: 266.8011\n",
      "Epoch 16/25\n",
      "70/70 [==============================] - 4s 55ms/step - loss: 253.9286 - val_loss: 268.6985\n",
      "Epoch 17/25\n",
      "70/70 [==============================] - 4s 56ms/step - loss: 265.5317 - val_loss: 226.7486\n",
      "Epoch 18/25\n",
      "70/70 [==============================] - 4s 56ms/step - loss: 229.5034 - val_loss: 277.0260\n",
      "Epoch 19/25\n",
      "70/70 [==============================] - 4s 56ms/step - loss: 227.2325 - val_loss: 268.1174\n",
      "Epoch 20/25\n",
      "70/70 [==============================] - 4s 56ms/step - loss: 234.1701 - val_loss: 213.4734\n",
      "Epoch 21/25\n",
      "70/70 [==============================] - 4s 56ms/step - loss: 228.9029 - val_loss: 255.2398\n",
      "Epoch 22/25\n",
      "70/70 [==============================] - 4s 55ms/step - loss: 229.5264 - val_loss: 258.3952\n",
      "Epoch 23/25\n",
      "70/70 [==============================] - 4s 55ms/step - loss: 229.3893 - val_loss: 268.5384\n",
      "Epoch 24/25\n",
      "70/70 [==============================] - 4s 56ms/step - loss: 224.4121 - val_loss: 210.9502\n",
      "Epoch 25/25\n",
      "70/70 [==============================] - 4s 56ms/step - loss: 216.7209 - val_loss: 288.6249\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "(17731, 30, 14) (17731, 1) (100, 30, 14)\n",
      "Epoch 1/25\n",
      "139/139 [==============================] - 8s 53ms/step - loss: 4451.7827 - val_loss: 2263.4065\n",
      "Epoch 2/25\n",
      "139/139 [==============================] - 7s 49ms/step - loss: 2350.0605 - val_loss: 1677.5082\n",
      "Epoch 3/25\n",
      "139/139 [==============================] - 6s 47ms/step - loss: 1923.0309 - val_loss: 1600.6703\n",
      "Epoch 4/25\n",
      "139/139 [==============================] - 7s 49ms/step - loss: 1589.9214 - val_loss: 954.2972\n",
      "Epoch 5/25\n",
      "139/139 [==============================] - 7s 48ms/step - loss: 883.8712 - val_loss: 390.2313\n",
      "Epoch 6/25\n",
      "139/139 [==============================] - 7s 48ms/step - loss: 512.8885 - val_loss: 297.4772\n",
      "Epoch 7/25\n",
      "139/139 [==============================] - 7s 48ms/step - loss: 348.0923 - val_loss: 232.5463\n",
      "Epoch 8/25\n",
      "139/139 [==============================] - 7s 48ms/step - loss: 269.1065 - val_loss: 280.1836\n",
      "Epoch 9/25\n",
      "139/139 [==============================] - 7s 49ms/step - loss: 264.1257 - val_loss: 227.9763\n",
      "Epoch 10/25\n",
      "139/139 [==============================] - 7s 48ms/step - loss: 243.3454 - val_loss: 220.7521\n",
      "Epoch 11/25\n",
      "139/139 [==============================] - 7s 49ms/step - loss: 222.1542 - val_loss: 247.7573\n",
      "Epoch 12/25\n",
      "139/139 [==============================] - 7s 51ms/step - loss: 228.5202 - val_loss: 274.8733\n",
      "Epoch 13/25\n",
      "139/139 [==============================] - 7s 49ms/step - loss: 239.9368 - val_loss: 324.8071\n",
      "Epoch 14/25\n",
      "139/139 [==============================] - 6s 46ms/step - loss: 229.1909 - val_loss: 214.3136\n",
      "Epoch 15/25\n",
      "139/139 [==============================] - 7s 47ms/step - loss: 213.0973 - val_loss: 208.3378\n",
      "Epoch 16/25\n",
      "139/139 [==============================] - 6s 47ms/step - loss: 215.7016 - val_loss: 226.0556\n",
      "Epoch 17/25\n",
      "139/139 [==============================] - 7s 48ms/step - loss: 215.9698 - val_loss: 226.2023\n",
      "Epoch 18/25\n",
      "139/139 [==============================] - 7s 47ms/step - loss: 209.0847 - val_loss: 221.2980\n",
      "Epoch 19/25\n",
      "139/139 [==============================] - 7s 48ms/step - loss: 209.7736 - val_loss: 209.0181\n",
      "Epoch 20/25\n",
      "139/139 [==============================] - 6s 47ms/step - loss: 206.0929 - val_loss: 206.8064\n",
      "Epoch 21/25\n",
      "139/139 [==============================] - 6s 47ms/step - loss: 203.8754 - val_loss: 228.1225\n",
      "Epoch 22/25\n",
      "139/139 [==============================] - 6s 46ms/step - loss: 200.4625 - val_loss: 231.1117\n",
      "Epoch 23/25\n",
      "139/139 [==============================] - 6s 46ms/step - loss: 199.6738 - val_loss: 209.2705\n",
      "Epoch 24/25\n",
      "139/139 [==============================] - 7s 47ms/step - loss: 205.5290 - val_loss: 210.0651\n",
      "Epoch 25/25\n",
      "139/139 [==============================] - 7s 47ms/step - loss: 200.1883 - val_loss: 252.9524\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "(17731, 30, 14) (17731, 1) (100, 30, 14)\n",
      "Epoch 1/25\n",
      "555/555 [==============================] - 4s 6ms/step - loss: 5137.1079 - val_loss: 2727.9998\n",
      "Epoch 2/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 2733.7524 - val_loss: 1779.8342\n",
      "Epoch 3/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 2058.9473 - val_loss: 1655.6179\n",
      "Epoch 4/25\n",
      "555/555 [==============================] - 3s 6ms/step - loss: 1934.5596 - val_loss: 1601.7662\n",
      "Epoch 5/25\n",
      "555/555 [==============================] - 3s 6ms/step - loss: 1090.6350 - val_loss: 546.9003\n",
      "Epoch 6/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 534.5097 - val_loss: 283.5685\n",
      "Epoch 7/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 384.8463 - val_loss: 217.6532\n",
      "Epoch 8/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 339.2420 - val_loss: 266.9906\n",
      "Epoch 9/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 312.8702 - val_loss: 227.7839\n",
      "Epoch 10/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 306.4827 - val_loss: 218.7932\n",
      "Epoch 11/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 289.1592 - val_loss: 290.7615\n",
      "Epoch 12/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 286.9593 - val_loss: 238.8091\n",
      "Epoch 13/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 286.3296 - val_loss: 223.9860\n",
      "Epoch 14/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 281.1457 - val_loss: 270.4729\n",
      "Epoch 15/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 284.9301 - val_loss: 203.3279\n",
      "Epoch 16/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 277.0490 - val_loss: 200.9976\n",
      "Epoch 17/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 272.4565 - val_loss: 211.7113\n",
      "Epoch 18/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 269.4970 - val_loss: 292.2563\n",
      "Epoch 19/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 271.7662 - val_loss: 203.1041\n",
      "Epoch 20/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 266.8897 - val_loss: 201.4220\n",
      "Epoch 21/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 267.6186 - val_loss: 267.6394\n",
      "Epoch 22/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 265.1217 - val_loss: 218.2961\n",
      "Epoch 23/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 266.7638 - val_loss: 199.1699\n",
      "Epoch 24/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 263.2724 - val_loss: 198.8094\n",
      "Epoch 25/25\n",
      "555/555 [==============================] - 3s 6ms/step - loss: 255.9744 - val_loss: 199.4861\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "(17731, 30, 14) (17731, 1) (100, 30, 14)\n",
      "Epoch 1/25\n",
      "555/555 [==============================] - 4s 6ms/step - loss: 5033.2632 - val_loss: 2670.9753\n",
      "Epoch 2/25\n",
      "555/555 [==============================] - 3s 6ms/step - loss: 2679.7261 - val_loss: 1729.9762\n",
      "Epoch 3/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 1522.0669 - val_loss: 720.4226\n",
      "Epoch 4/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 747.4565 - val_loss: 357.0583\n",
      "Epoch 5/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 432.9241 - val_loss: 231.1617\n",
      "Epoch 6/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 315.5050 - val_loss: 276.5941\n",
      "Epoch 7/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 278.0392 - val_loss: 201.9053\n",
      "Epoch 8/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 261.8754 - val_loss: 242.5380\n",
      "Epoch 9/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 258.1850 - val_loss: 220.9094\n",
      "Epoch 10/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 250.1107 - val_loss: 238.0015\n",
      "Epoch 11/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 244.3162 - val_loss: 236.4443\n",
      "Epoch 12/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 244.5601 - val_loss: 202.8760\n",
      "Epoch 13/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 239.1034 - val_loss: 255.6241\n",
      "Epoch 14/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 234.2954 - val_loss: 223.9104\n",
      "Epoch 15/25\n",
      "555/555 [==============================] - 3s 6ms/step - loss: 234.7566 - val_loss: 224.7758\n",
      "Epoch 16/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 231.1658 - val_loss: 225.2772\n",
      "Epoch 17/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 237.0397 - val_loss: 209.3659\n",
      "Epoch 18/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 227.8472 - val_loss: 278.8335\n",
      "Epoch 19/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 234.6775 - val_loss: 208.7951\n",
      "Epoch 20/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 226.8667 - val_loss: 237.7822\n",
      "Epoch 21/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 224.8700 - val_loss: 219.3924\n",
      "Epoch 22/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 228.5269 - val_loss: 215.4608\n",
      "Epoch 23/25\n",
      "555/555 [==============================] - 3s 6ms/step - loss: 223.1828 - val_loss: 213.2985\n",
      "Epoch 24/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 220.1158 - val_loss: 206.2001\n",
      "Epoch 25/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 219.0563 - val_loss: 238.5705\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "iteration  30\n",
      "(17731, 30, 14) (17731, 1) (100, 30, 14)\n",
      "Epoch 1/25\n",
      "70/70 [==============================] - 2s 18ms/step - loss: 7521.2520 - val_loss: 5530.9546\n",
      "Epoch 2/25\n",
      "70/70 [==============================] - 1s 12ms/step - loss: 6344.2686 - val_loss: 4915.4717\n",
      "Epoch 3/25\n",
      "70/70 [==============================] - 1s 13ms/step - loss: 5723.1064 - val_loss: 4412.0020\n",
      "Epoch 4/25\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 5192.5889 - val_loss: 3978.0359\n",
      "Epoch 5/25\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 4729.0513 - val_loss: 3601.7798\n",
      "Epoch 6/25\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 4317.5312 - val_loss: 3273.1440\n",
      "Epoch 7/25\n",
      "70/70 [==============================] - 1s 13ms/step - loss: 3957.6208 - val_loss: 2988.7905\n",
      "Epoch 8/25\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 3638.0547 - val_loss: 2743.0022\n",
      "Epoch 9/25\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 3363.8867 - val_loss: 2532.0088\n",
      "Epoch 10/25\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 3121.3645 - val_loss: 2352.4260\n",
      "Epoch 11/25\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 2908.3335 - val_loss: 2202.8093\n",
      "Epoch 12/25\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 2732.1921 - val_loss: 2077.5828\n",
      "Epoch 13/25\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 2581.4927 - val_loss: 1974.6294\n",
      "Epoch 14/25\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 2449.1348 - val_loss: 1891.1815\n",
      "Epoch 15/25\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 2337.8135 - val_loss: 1824.1108\n",
      "Epoch 16/25\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 2249.7209 - val_loss: 1772.3655\n",
      "Epoch 17/25\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 2173.0979 - val_loss: 1732.3727\n",
      "Epoch 18/25\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 2107.8320 - val_loss: 1703.1754\n",
      "Epoch 19/25\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 2056.7319 - val_loss: 1670.4664\n",
      "Epoch 20/25\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 1939.2966 - val_loss: 1483.7578\n",
      "Epoch 21/25\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 1714.2264 - val_loss: 1277.2280\n",
      "Epoch 22/25\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 1490.1969 - val_loss: 1047.2017\n",
      "Epoch 23/25\n",
      "70/70 [==============================] - 1s 13ms/step - loss: 1294.4462 - val_loss: 892.6372\n",
      "Epoch 24/25\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 1177.2034 - val_loss: 833.9849\n",
      "Epoch 25/25\n",
      "70/70 [==============================] - 1s 13ms/step - loss: 1055.0773 - val_loss: 722.7512\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "(17731, 30, 14) (17731, 1) (100, 30, 14)\n",
      "Epoch 1/25\n",
      "70/70 [==============================] - 3s 36ms/step - loss: 6691.3301 - val_loss: 4562.1646\n",
      "Epoch 2/25\n",
      "70/70 [==============================] - 2s 30ms/step - loss: 5080.5015 - val_loss: 3661.7642\n",
      "Epoch 3/25\n",
      "70/70 [==============================] - 2s 32ms/step - loss: 4192.9692 - val_loss: 3009.6140\n",
      "Epoch 4/25\n",
      "70/70 [==============================] - 2s 31ms/step - loss: 3515.3313 - val_loss: 2529.8848\n",
      "Epoch 5/25\n",
      "70/70 [==============================] - 2s 32ms/step - loss: 3015.0698 - val_loss: 2194.1277\n",
      "Epoch 6/25\n",
      "70/70 [==============================] - 2s 31ms/step - loss: 2649.9739 - val_loss: 1962.1842\n",
      "Epoch 7/25\n",
      "70/70 [==============================] - 2s 32ms/step - loss: 2384.4871 - val_loss: 1814.7762\n",
      "Epoch 8/25\n",
      "70/70 [==============================] - 2s 32ms/step - loss: 2205.6433 - val_loss: 1726.8375\n",
      "Epoch 9/25\n",
      "70/70 [==============================] - 2s 32ms/step - loss: 2089.8215 - val_loss: 1679.8416\n",
      "Epoch 10/25\n",
      "70/70 [==============================] - 2s 31ms/step - loss: 2005.3457 - val_loss: 1659.5797\n",
      "Epoch 11/25\n",
      "70/70 [==============================] - 2s 32ms/step - loss: 1960.8392 - val_loss: 1655.3995\n",
      "Epoch 12/25\n",
      "70/70 [==============================] - 2s 32ms/step - loss: 1938.2390 - val_loss: 1659.3372\n",
      "Epoch 13/25\n",
      "70/70 [==============================] - 2s 32ms/step - loss: 1919.9824 - val_loss: 1666.6449\n",
      "Epoch 14/25\n",
      "70/70 [==============================] - 2s 33ms/step - loss: 1908.2466 - val_loss: 1674.7816\n",
      "Epoch 15/25\n",
      "70/70 [==============================] - 2s 32ms/step - loss: 1900.5157 - val_loss: 1649.0515\n",
      "Epoch 16/25\n",
      "70/70 [==============================] - 2s 30ms/step - loss: 1782.6608 - val_loss: 1378.6577\n",
      "Epoch 17/25\n",
      "70/70 [==============================] - 2s 30ms/step - loss: 1306.0339 - val_loss: 1002.1335\n",
      "Epoch 18/25\n",
      "70/70 [==============================] - 2s 34ms/step - loss: 982.9518 - val_loss: 666.7639\n",
      "Epoch 19/25\n",
      "70/70 [==============================] - 2s 32ms/step - loss: 808.4747 - val_loss: 586.8685\n",
      "Epoch 20/25\n",
      "70/70 [==============================] - 2s 32ms/step - loss: 677.2482 - val_loss: 685.5844\n",
      "Epoch 21/25\n",
      "70/70 [==============================] - 2s 32ms/step - loss: 577.4192 - val_loss: 302.1989\n",
      "Epoch 22/25\n",
      "70/70 [==============================] - 2s 32ms/step - loss: 440.4592 - val_loss: 296.9536\n",
      "Epoch 23/25\n",
      "70/70 [==============================] - 2s 31ms/step - loss: 394.1750 - val_loss: 252.7614\n",
      "Epoch 24/25\n",
      "70/70 [==============================] - 2s 32ms/step - loss: 354.6827 - val_loss: 221.0309\n",
      "Epoch 25/25\n",
      "70/70 [==============================] - 2s 31ms/step - loss: 322.8806 - val_loss: 291.1205\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "(17731, 30, 14) (17731, 1) (100, 30, 14)\n",
      "Epoch 1/25\n",
      "70/70 [==============================] - 2s 18ms/step - loss: 7398.7417 - val_loss: 5376.9858\n",
      "Epoch 2/25\n",
      "70/70 [==============================] - 1s 13ms/step - loss: 6183.1079 - val_loss: 4776.1489\n",
      "Epoch 3/25\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 5572.5239 - val_loss: 4284.7329\n",
      "Epoch 4/25\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 5057.1587 - val_loss: 3862.2622\n",
      "Epoch 5/25\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 4609.7314 - val_loss: 3497.4043\n",
      "Epoch 6/25\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 4206.8926 - val_loss: 3179.6409\n",
      "Epoch 7/25\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 3860.1113 - val_loss: 2905.8530\n",
      "Epoch 8/25\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 3554.5583 - val_loss: 2670.4084\n",
      "Epoch 9/25\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 3285.8682 - val_loss: 2468.7585\n",
      "Epoch 10/25\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 3055.4214 - val_loss: 2297.9707\n",
      "Epoch 11/25\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 2855.4495 - val_loss: 2156.6404\n",
      "Epoch 12/25\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 2696.3535 - val_loss: 2039.0922\n",
      "Epoch 13/25\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 2550.8601 - val_loss: 1943.0881\n",
      "Epoch 14/25\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 2422.0408 - val_loss: 1865.8696\n",
      "Epoch 15/25\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 2321.1863 - val_loss: 1804.1335\n",
      "Epoch 16/25\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 2236.5471 - val_loss: 1757.1436\n",
      "Epoch 17/25\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 2172.7251 - val_loss: 1721.2098\n",
      "Epoch 18/25\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 2109.5486 - val_loss: 1695.3040\n",
      "Epoch 19/25\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 2064.0376 - val_loss: 1677.1577\n",
      "Epoch 20/25\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 2032.8699 - val_loss: 1665.4591\n",
      "Epoch 21/25\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 2009.5234 - val_loss: 1658.7019\n",
      "Epoch 22/25\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 1991.3695 - val_loss: 1655.7816\n",
      "Epoch 23/25\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 1963.7189 - val_loss: 1655.5618\n",
      "Epoch 24/25\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 1956.1814 - val_loss: 1657.2911\n",
      "Epoch 25/25\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 1942.1560 - val_loss: 1660.2455\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "(17731, 30, 14) (17731, 1) (100, 30, 14)\n",
      "Epoch 1/25\n",
      "278/278 [==============================] - 3s 6ms/step - loss: 6948.8428 - val_loss: 5004.3223\n",
      "Epoch 2/25\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 5559.8770 - val_loss: 4069.4893\n",
      "Epoch 3/25\n",
      "278/278 [==============================] - 2s 5ms/step - loss: 4631.9346 - val_loss: 3354.1497\n",
      "Epoch 4/25\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 3897.0129 - val_loss: 2806.6587\n",
      "Epoch 5/25\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 3328.3269 - val_loss: 2399.0232\n",
      "Epoch 6/25\n",
      "278/278 [==============================] - 2s 5ms/step - loss: 2893.8806 - val_loss: 2104.6143\n",
      "Epoch 7/25\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 2573.1604 - val_loss: 1903.8486\n",
      "Epoch 8/25\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 2337.8923 - val_loss: 1719.2175\n",
      "Epoch 9/25\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 2024.7490 - val_loss: 1422.7561\n",
      "Epoch 10/25\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 1578.1683 - val_loss: 964.3740\n",
      "Epoch 11/25\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 1220.7953 - val_loss: 710.7913\n",
      "Epoch 12/25\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 959.0324 - val_loss: 485.1571\n",
      "Epoch 13/25\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 771.8508 - val_loss: 372.9208\n",
      "Epoch 14/25\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 658.0278 - val_loss: 311.8524\n",
      "Epoch 15/25\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 558.0088 - val_loss: 300.0652\n",
      "Epoch 16/25\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 501.7019 - val_loss: 246.0411\n",
      "Epoch 17/25\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 439.0077 - val_loss: 254.6838\n",
      "Epoch 18/25\n",
      "278/278 [==============================] - 2s 5ms/step - loss: 412.8345 - val_loss: 226.0787\n",
      "Epoch 19/25\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 384.6337 - val_loss: 223.0180\n",
      "Epoch 20/25\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 373.7841 - val_loss: 277.6306\n",
      "Epoch 21/25\n",
      "278/278 [==============================] - 2s 5ms/step - loss: 362.7563 - val_loss: 250.0533\n",
      "Epoch 22/25\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 347.0461 - val_loss: 283.9812\n",
      "Epoch 23/25\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 346.4820 - val_loss: 210.8177\n",
      "Epoch 24/25\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 346.5688 - val_loss: 216.9984\n",
      "Epoch 25/25\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 341.1706 - val_loss: 264.3283\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "(17731, 30, 14) (17731, 1) (100, 30, 14)\n",
      "Epoch 1/25\n",
      "139/139 [==============================] - 4s 21ms/step - loss: 5726.7749 - val_loss: 3549.4009\n",
      "Epoch 2/25\n",
      "139/139 [==============================] - 3s 18ms/step - loss: 3740.4299 - val_loss: 2461.6934\n",
      "Epoch 3/25\n",
      "139/139 [==============================] - 3s 21ms/step - loss: 2770.0120 - val_loss: 1932.6118\n",
      "Epoch 4/25\n",
      "139/139 [==============================] - 3s 19ms/step - loss: 2265.1360 - val_loss: 1717.0853\n",
      "Epoch 5/25\n",
      "139/139 [==============================] - 3s 19ms/step - loss: 2037.1447 - val_loss: 1658.5841\n",
      "Epoch 6/25\n",
      "139/139 [==============================] - 3s 19ms/step - loss: 1945.4082 - val_loss: 1660.2368\n",
      "Epoch 7/25\n",
      "139/139 [==============================] - 3s 19ms/step - loss: 1916.6793 - val_loss: 1665.2008\n",
      "Epoch 8/25\n",
      "139/139 [==============================] - 3s 20ms/step - loss: 1752.4641 - val_loss: 1204.0643\n",
      "Epoch 9/25\n",
      "139/139 [==============================] - 3s 20ms/step - loss: 1054.9950 - val_loss: 803.3141\n",
      "Epoch 10/25\n",
      "139/139 [==============================] - 3s 19ms/step - loss: 805.7210 - val_loss: 630.7908\n",
      "Epoch 11/25\n",
      "139/139 [==============================] - 3s 19ms/step - loss: 586.5763 - val_loss: 411.8954\n",
      "Epoch 12/25\n",
      "139/139 [==============================] - 3s 18ms/step - loss: 409.5255 - val_loss: 233.5678\n",
      "Epoch 13/25\n",
      "139/139 [==============================] - 3s 19ms/step - loss: 335.1700 - val_loss: 330.6473\n",
      "Epoch 14/25\n",
      "139/139 [==============================] - 3s 19ms/step - loss: 315.6177 - val_loss: 252.8586\n",
      "Epoch 15/25\n",
      "139/139 [==============================] - 3s 19ms/step - loss: 275.3423 - val_loss: 203.0940\n",
      "Epoch 16/25\n",
      "139/139 [==============================] - 3s 18ms/step - loss: 276.7684 - val_loss: 234.6799\n",
      "Epoch 17/25\n",
      "139/139 [==============================] - 3s 19ms/step - loss: 264.8791 - val_loss: 212.9903\n",
      "Epoch 18/25\n",
      "139/139 [==============================] - 3s 18ms/step - loss: 258.5974 - val_loss: 244.6793\n",
      "Epoch 19/25\n",
      "139/139 [==============================] - 3s 19ms/step - loss: 257.3386 - val_loss: 252.8191\n",
      "Epoch 20/25\n",
      "139/139 [==============================] - 3s 19ms/step - loss: 241.7682 - val_loss: 217.7233\n",
      "Epoch 21/25\n",
      "139/139 [==============================] - 3s 19ms/step - loss: 239.5954 - val_loss: 250.6161\n",
      "Epoch 22/25\n",
      "139/139 [==============================] - 3s 18ms/step - loss: 234.7016 - val_loss: 233.4760\n",
      "Epoch 23/25\n",
      "139/139 [==============================] - 3s 19ms/step - loss: 240.4259 - val_loss: 231.2827\n",
      "Epoch 24/25\n",
      "139/139 [==============================] - 3s 18ms/step - loss: 236.0128 - val_loss: 215.2107\n",
      "Epoch 25/25\n",
      "139/139 [==============================] - 3s 18ms/step - loss: 241.9453 - val_loss: 226.3302\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "(17731, 30, 14) (17731, 1) (100, 30, 14)\n",
      "Epoch 1/25\n",
      "70/70 [==============================] - 2s 20ms/step - loss: 7406.2646 - val_loss: 5395.6230\n",
      "Epoch 2/25\n",
      "70/70 [==============================] - 1s 13ms/step - loss: 6193.6982 - val_loss: 4783.7617\n",
      "Epoch 3/25\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 5581.3247 - val_loss: 4285.6504\n",
      "Epoch 4/25\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 5052.8447 - val_loss: 3855.8240\n",
      "Epoch 5/25\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 4599.9858 - val_loss: 3488.2351\n",
      "Epoch 6/25\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 4194.3462 - val_loss: 3169.5071\n",
      "Epoch 7/25\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 3847.9399 - val_loss: 2895.5825\n",
      "Epoch 8/25\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 3542.2793 - val_loss: 2660.4534\n",
      "Epoch 9/25\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 3274.3491 - val_loss: 2459.5002\n",
      "Epoch 10/25\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 3044.0669 - val_loss: 2289.5833\n",
      "Epoch 11/25\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 2845.4590 - val_loss: 2149.1782\n",
      "Epoch 12/25\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 2686.8630 - val_loss: 2032.5576\n",
      "Epoch 13/25\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 2542.5256 - val_loss: 1937.5090\n",
      "Epoch 14/25\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 2414.6152 - val_loss: 1861.2030\n",
      "Epoch 15/25\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 2315.0398 - val_loss: 1800.3210\n",
      "Epoch 16/25\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 2231.2134 - val_loss: 1754.1000\n",
      "Epoch 17/25\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 2168.2317 - val_loss: 1718.8679\n",
      "Epoch 18/25\n",
      "70/70 [==============================] - 1s 13ms/step - loss: 2105.7900 - val_loss: 1693.5883\n",
      "Epoch 19/25\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 2060.9636 - val_loss: 1675.9745\n",
      "Epoch 20/25\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 2030.5704 - val_loss: 1664.7126\n",
      "Epoch 21/25\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 2006.6099 - val_loss: 1655.7354\n",
      "Epoch 22/25\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 1970.0869 - val_loss: 1597.7100\n",
      "Epoch 23/25\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 1853.3383 - val_loss: 1467.2065\n",
      "Epoch 24/25\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 1644.1013 - val_loss: 1214.6741\n",
      "Epoch 25/25\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 1407.8861 - val_loss: 1190.7002\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "(17731, 30, 14) (17731, 1) (100, 30, 14)\n",
      "Epoch 1/25\n",
      "139/139 [==============================] - 2s 8ms/step - loss: 7545.7534 - val_loss: 5680.7861\n",
      "Epoch 2/25\n",
      "139/139 [==============================] - 1s 7ms/step - loss: 6513.3276 - val_loss: 5072.3247\n",
      "Epoch 3/25\n",
      "139/139 [==============================] - 1s 7ms/step - loss: 5894.5659 - val_loss: 4563.8989\n",
      "Epoch 4/25\n",
      "139/139 [==============================] - 1s 7ms/step - loss: 5355.7266 - val_loss: 4120.0908\n",
      "Epoch 5/25\n",
      "139/139 [==============================] - 1s 7ms/step - loss: 4881.7822 - val_loss: 3731.3508\n",
      "Epoch 6/25\n",
      "139/139 [==============================] - 1s 8ms/step - loss: 4458.6426 - val_loss: 3389.2332\n",
      "Epoch 7/25\n",
      "139/139 [==============================] - 1s 7ms/step - loss: 4085.8691 - val_loss: 3090.5178\n",
      "Epoch 8/25\n",
      "139/139 [==============================] - 1s 7ms/step - loss: 3754.2939 - val_loss: 2830.5188\n",
      "Epoch 9/25\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 3465.4624 - val_loss: 2605.5220\n",
      "Epoch 10/25\n",
      "139/139 [==============================] - 1s 7ms/step - loss: 3206.5061 - val_loss: 2412.7134\n",
      "Epoch 11/25\n",
      "139/139 [==============================] - 1s 7ms/step - loss: 2981.3394 - val_loss: 2249.5835\n",
      "Epoch 12/25\n",
      "139/139 [==============================] - 1s 7ms/step - loss: 2791.1011 - val_loss: 2112.1833\n",
      "Epoch 13/25\n",
      "139/139 [==============================] - 1s 7ms/step - loss: 2626.5107 - val_loss: 1998.7551\n",
      "Epoch 14/25\n",
      "139/139 [==============================] - 1s 7ms/step - loss: 2484.5510 - val_loss: 1906.5486\n",
      "Epoch 15/25\n",
      "139/139 [==============================] - 1s 7ms/step - loss: 2362.8164 - val_loss: 1832.3651\n",
      "Epoch 16/25\n",
      "139/139 [==============================] - 1s 7ms/step - loss: 2263.1069 - val_loss: 1774.9755\n",
      "Epoch 17/25\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 2182.5771 - val_loss: 1731.5956\n",
      "Epoch 18/25\n",
      "139/139 [==============================] - 1s 7ms/step - loss: 2116.3547 - val_loss: 1699.9509\n",
      "Epoch 19/25\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 2059.0376 - val_loss: 1678.3315\n",
      "Epoch 20/25\n",
      "139/139 [==============================] - 1s 8ms/step - loss: 2017.1952 - val_loss: 1664.7638\n",
      "Epoch 21/25\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 1982.6180 - val_loss: 1657.6572\n",
      "Epoch 22/25\n",
      "139/139 [==============================] - 1s 7ms/step - loss: 1965.6897 - val_loss: 1655.3755\n",
      "Epoch 23/25\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 1942.8086 - val_loss: 1656.0715\n",
      "Epoch 24/25\n",
      "139/139 [==============================] - 1s 7ms/step - loss: 1845.9034 - val_loss: 1394.6741\n",
      "Epoch 25/25\n",
      "139/139 [==============================] - 1s 7ms/step - loss: 1398.0558 - val_loss: 925.6899\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "(17731, 30, 14) (17731, 1) (100, 30, 14)\n",
      "Epoch 1/25\n",
      "555/555 [==============================] - 13s 21ms/step - loss: 2695.4497 - val_loss: 1689.6234\n",
      "Epoch 2/25\n",
      "555/555 [==============================] - 11s 20ms/step - loss: 1225.9142 - val_loss: 704.9337\n",
      "Epoch 3/25\n",
      "555/555 [==============================] - 11s 20ms/step - loss: 415.0727 - val_loss: 395.6978\n",
      "Epoch 4/25\n",
      "555/555 [==============================] - 12s 21ms/step - loss: 258.7907 - val_loss: 272.3255\n",
      "Epoch 5/25\n",
      "555/555 [==============================] - 11s 20ms/step - loss: 226.8085 - val_loss: 244.6282\n",
      "Epoch 6/25\n",
      "555/555 [==============================] - 11s 20ms/step - loss: 220.1087 - val_loss: 335.0060\n",
      "Epoch 7/25\n",
      "555/555 [==============================] - 11s 20ms/step - loss: 211.4532 - val_loss: 233.6232\n",
      "Epoch 8/25\n",
      "555/555 [==============================] - 11s 21ms/step - loss: 205.4880 - val_loss: 206.9731\n",
      "Epoch 9/25\n",
      "555/555 [==============================] - 11s 20ms/step - loss: 202.5446 - val_loss: 233.4238\n",
      "Epoch 10/25\n",
      "555/555 [==============================] - 11s 20ms/step - loss: 201.6855 - val_loss: 228.7610\n",
      "Epoch 11/25\n",
      "555/555 [==============================] - 11s 20ms/step - loss: 197.1245 - val_loss: 270.0937\n",
      "Epoch 12/25\n",
      "555/555 [==============================] - 11s 21ms/step - loss: 198.9353 - val_loss: 200.0218\n",
      "Epoch 13/25\n",
      "555/555 [==============================] - 11s 20ms/step - loss: 194.2086 - val_loss: 207.5161\n",
      "Epoch 14/25\n",
      "555/555 [==============================] - 11s 20ms/step - loss: 194.4483 - val_loss: 199.0479\n",
      "Epoch 15/25\n",
      "555/555 [==============================] - 11s 20ms/step - loss: 192.3553 - val_loss: 221.1928\n",
      "Epoch 16/25\n",
      "555/555 [==============================] - 11s 20ms/step - loss: 190.3480 - val_loss: 254.5601\n",
      "Epoch 17/25\n",
      "555/555 [==============================] - 11s 20ms/step - loss: 190.5885 - val_loss: 214.5347\n",
      "Epoch 18/25\n",
      "555/555 [==============================] - 11s 20ms/step - loss: 193.7822 - val_loss: 227.4802\n",
      "Epoch 19/25\n",
      "555/555 [==============================] - 11s 20ms/step - loss: 189.9194 - val_loss: 224.8579\n",
      "Epoch 20/25\n",
      "555/555 [==============================] - 11s 20ms/step - loss: 189.6116 - val_loss: 241.2244\n",
      "Epoch 21/25\n",
      "555/555 [==============================] - 11s 20ms/step - loss: 187.3606 - val_loss: 235.9288\n",
      "Epoch 22/25\n",
      "555/555 [==============================] - 11s 20ms/step - loss: 188.3560 - val_loss: 226.6166\n",
      "Epoch 23/25\n",
      "555/555 [==============================] - 11s 20ms/step - loss: 185.8786 - val_loss: 225.0511\n",
      "Epoch 24/25\n",
      "555/555 [==============================] - 11s 20ms/step - loss: 185.3837 - val_loss: 232.7605\n",
      "Epoch 25/25\n",
      "555/555 [==============================] - 11s 20ms/step - loss: 182.2814 - val_loss: 244.6618\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "(17731, 30, 14) (17731, 1) (100, 30, 14)\n",
      "Epoch 1/25\n",
      "278/278 [==============================] - 9s 29ms/step - loss: 3519.0444 - val_loss: 1690.8760\n",
      "Epoch 2/25\n",
      "278/278 [==============================] - 8s 28ms/step - loss: 1921.5612 - val_loss: 1577.1932\n",
      "Epoch 3/25\n",
      "278/278 [==============================] - 3773s 14s/step - loss: 1082.7700 - val_loss: 577.9343\n",
      "Epoch 4/25\n",
      "278/278 [==============================] - 9s 31ms/step - loss: 499.0789 - val_loss: 394.3288\n",
      "Epoch 5/25\n",
      "278/278 [==============================] - 9s 32ms/step - loss: 341.7243 - val_loss: 288.8201\n",
      "Epoch 6/25\n",
      "278/278 [==============================] - 7s 26ms/step - loss: 267.9781 - val_loss: 297.5087\n",
      "Epoch 7/25\n",
      "278/278 [==============================] - 2710s 10s/step - loss: 262.1839 - val_loss: 213.6930\n",
      "Epoch 8/25\n",
      "278/278 [==============================] - 8s 28ms/step - loss: 247.7670 - val_loss: 354.8888\n",
      "Epoch 9/25\n",
      "278/278 [==============================] - 8s 28ms/step - loss: 242.4115 - val_loss: 216.7045\n",
      "Epoch 10/25\n",
      "278/278 [==============================] - 7s 26ms/step - loss: 228.5855 - val_loss: 357.2215\n",
      "Epoch 11/25\n",
      "278/278 [==============================] - 7s 25ms/step - loss: 238.6871 - val_loss: 276.6255\n",
      "Epoch 12/25\n",
      "278/278 [==============================] - 7s 26ms/step - loss: 228.5787 - val_loss: 317.9524\n",
      "Epoch 13/25\n",
      "278/278 [==============================] - 7s 25ms/step - loss: 218.8083 - val_loss: 232.4781\n",
      "Epoch 14/25\n",
      "278/278 [==============================] - 8s 27ms/step - loss: 210.3289 - val_loss: 369.4998\n",
      "Epoch 15/25\n",
      "278/278 [==============================] - 8s 27ms/step - loss: 224.7753 - val_loss: 220.9737\n",
      "Epoch 16/25\n",
      "278/278 [==============================] - 7s 27ms/step - loss: 210.9452 - val_loss: 276.2418\n",
      "Epoch 17/25\n",
      "278/278 [==============================] - 7s 26ms/step - loss: 215.5488 - val_loss: 207.3366\n",
      "Epoch 18/25\n",
      "278/278 [==============================] - 7s 26ms/step - loss: 213.1636 - val_loss: 288.1452\n",
      "Epoch 19/25\n",
      "278/278 [==============================] - 8s 27ms/step - loss: 215.3225 - val_loss: 261.2305\n",
      "Epoch 20/25\n",
      "278/278 [==============================] - 7s 26ms/step - loss: 207.5574 - val_loss: 218.8134\n",
      "Epoch 21/25\n",
      "278/278 [==============================] - 7s 26ms/step - loss: 205.7299 - val_loss: 229.2735\n",
      "Epoch 22/25\n",
      "278/278 [==============================] - 7s 27ms/step - loss: 202.5385 - val_loss: 253.9558\n",
      "Epoch 23/25\n",
      "278/278 [==============================] - 8s 27ms/step - loss: 210.8952 - val_loss: 202.5121\n",
      "Epoch 24/25\n",
      "278/278 [==============================] - 8s 27ms/step - loss: 198.0156 - val_loss: 204.8320\n",
      "Epoch 25/25\n",
      "278/278 [==============================] - 7s 27ms/step - loss: 200.1138 - val_loss: 257.9834\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "(17731, 30, 14) (17731, 1) (100, 30, 14)\n",
      "Epoch 1/25\n",
      "555/555 [==============================] - 4s 6ms/step - loss: 5135.0464 - val_loss: 2727.8816\n",
      "Epoch 2/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 2727.1055 - val_loss: 1777.4641\n",
      "Epoch 3/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 1800.4435 - val_loss: 877.5591\n",
      "Epoch 4/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 891.9918 - val_loss: 559.5255\n",
      "Epoch 5/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 510.3490 - val_loss: 240.0480\n",
      "Epoch 6/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 332.4668 - val_loss: 241.6432\n",
      "Epoch 7/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 287.0346 - val_loss: 201.5975\n",
      "Epoch 8/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 263.0918 - val_loss: 210.8762\n",
      "Epoch 9/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 260.9918 - val_loss: 211.9339\n",
      "Epoch 10/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 257.7242 - val_loss: 254.6941\n",
      "Epoch 11/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 243.7713 - val_loss: 200.9651\n",
      "Epoch 12/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 245.7075 - val_loss: 198.7355\n",
      "Epoch 13/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 243.7422 - val_loss: 249.2590\n",
      "Epoch 14/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 235.8157 - val_loss: 257.5934\n",
      "Epoch 15/25\n",
      "555/555 [==============================] - 3s 6ms/step - loss: 236.9186 - val_loss: 205.6254\n",
      "Epoch 16/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 232.1257 - val_loss: 195.8062\n",
      "Epoch 17/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 232.9342 - val_loss: 201.7104\n",
      "Epoch 18/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 228.2456 - val_loss: 313.1563\n",
      "Epoch 19/25\n",
      "555/555 [==============================] - 3s 6ms/step - loss: 234.6083 - val_loss: 208.8194\n",
      "Epoch 20/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 223.7889 - val_loss: 218.9107\n",
      "Epoch 21/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 229.2016 - val_loss: 237.6214\n",
      "Epoch 22/25\n",
      "555/555 [==============================] - 3s 6ms/step - loss: 228.9966 - val_loss: 201.2518\n",
      "Epoch 23/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 222.5140 - val_loss: 198.9746\n",
      "Epoch 24/25\n",
      "555/555 [==============================] - 3s 6ms/step - loss: 222.2963 - val_loss: 194.8167\n",
      "Epoch 25/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 220.2894 - val_loss: 225.0895\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "iteration  40\n",
      "(17731, 30, 14) (17731, 1) (100, 30, 14)\n",
      "Epoch 1/25\n",
      "555/555 [==============================] - 6s 9ms/step - loss: 3700.1943 - val_loss: 1732.4996\n",
      "Epoch 2/25\n",
      "555/555 [==============================] - 5s 9ms/step - loss: 1952.7135 - val_loss: 1683.4659\n",
      "Epoch 3/25\n",
      "555/555 [==============================] - 5s 9ms/step - loss: 1508.7283 - val_loss: 725.8233\n",
      "Epoch 4/25\n",
      "555/555 [==============================] - 5s 9ms/step - loss: 574.9332 - val_loss: 317.6825\n",
      "Epoch 5/25\n",
      "555/555 [==============================] - 5s 9ms/step - loss: 319.5743 - val_loss: 222.1359\n",
      "Epoch 6/25\n",
      "555/555 [==============================] - 5s 9ms/step - loss: 262.0354 - val_loss: 300.3417\n",
      "Epoch 7/25\n",
      "555/555 [==============================] - 5s 9ms/step - loss: 240.5502 - val_loss: 216.1383\n",
      "Epoch 8/25\n",
      "555/555 [==============================] - 5s 9ms/step - loss: 226.1080 - val_loss: 197.3956\n",
      "Epoch 9/25\n",
      "555/555 [==============================] - 5s 8ms/step - loss: 221.8012 - val_loss: 193.3129\n",
      "Epoch 10/25\n",
      "555/555 [==============================] - 5s 9ms/step - loss: 212.9727 - val_loss: 217.4575\n",
      "Epoch 11/25\n",
      "555/555 [==============================] - 5s 9ms/step - loss: 212.7101 - val_loss: 220.3373\n",
      "Epoch 12/25\n",
      "555/555 [==============================] - 5s 9ms/step - loss: 210.0507 - val_loss: 196.6815\n",
      "Epoch 13/25\n",
      "555/555 [==============================] - 5s 9ms/step - loss: 210.0856 - val_loss: 206.8671\n",
      "Epoch 14/25\n",
      "555/555 [==============================] - 5s 9ms/step - loss: 203.4465 - val_loss: 191.2219\n",
      "Epoch 15/25\n",
      "555/555 [==============================] - 5s 9ms/step - loss: 205.6471 - val_loss: 209.4376\n",
      "Epoch 16/25\n",
      "555/555 [==============================] - 5s 9ms/step - loss: 205.1638 - val_loss: 227.9079\n",
      "Epoch 17/25\n",
      "555/555 [==============================] - 5s 9ms/step - loss: 203.8906 - val_loss: 224.1988\n",
      "Epoch 18/25\n",
      "555/555 [==============================] - 5s 9ms/step - loss: 205.7250 - val_loss: 207.9611\n",
      "Epoch 19/25\n",
      "555/555 [==============================] - 5s 9ms/step - loss: 199.8270 - val_loss: 219.8389\n",
      "Epoch 20/25\n",
      "555/555 [==============================] - 5s 9ms/step - loss: 199.0916 - val_loss: 229.9295\n",
      "Epoch 21/25\n",
      "555/555 [==============================] - 5s 9ms/step - loss: 199.1792 - val_loss: 209.2993\n",
      "Epoch 22/25\n",
      "555/555 [==============================] - 5s 9ms/step - loss: 197.6111 - val_loss: 205.4851\n",
      "Epoch 23/25\n",
      "555/555 [==============================] - 5s 9ms/step - loss: 198.6236 - val_loss: 209.4002\n",
      "Epoch 24/25\n",
      "555/555 [==============================] - 6s 11ms/step - loss: 199.2030 - val_loss: 216.9257\n",
      "Epoch 25/25\n",
      "555/555 [==============================] - 5s 9ms/step - loss: 195.4557 - val_loss: 221.1298\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "(17731, 30, 14) (17731, 1) (100, 30, 14)\n",
      "Epoch 1/25\n",
      "278/278 [==============================] - 10s 31ms/step - loss: 3550.0342 - val_loss: 1693.0465\n",
      "Epoch 2/25\n",
      "278/278 [==============================] - 8s 30ms/step - loss: 1869.1085 - val_loss: 1404.4816\n",
      "Epoch 3/25\n",
      "278/278 [==============================] - 8s 30ms/step - loss: 891.5718 - val_loss: 573.1785\n",
      "Epoch 4/25\n",
      "278/278 [==============================] - 8s 30ms/step - loss: 448.6804 - val_loss: 218.5508\n",
      "Epoch 5/25\n",
      "278/278 [==============================] - 8s 30ms/step - loss: 302.5705 - val_loss: 201.0634\n",
      "Epoch 6/25\n",
      "278/278 [==============================] - 8s 29ms/step - loss: 256.4742 - val_loss: 578.6597\n",
      "Epoch 7/25\n",
      "278/278 [==============================] - 8s 30ms/step - loss: 256.1704 - val_loss: 210.5887\n",
      "Epoch 8/25\n",
      "278/278 [==============================] - 8s 30ms/step - loss: 234.8836 - val_loss: 301.8919\n",
      "Epoch 9/25\n",
      "278/278 [==============================] - 9s 31ms/step - loss: 232.5356 - val_loss: 221.2859\n",
      "Epoch 10/25\n",
      "278/278 [==============================] - 8s 30ms/step - loss: 218.6078 - val_loss: 334.2702\n",
      "Epoch 11/25\n",
      "278/278 [==============================] - 8s 30ms/step - loss: 321.0328 - val_loss: 256.5234\n",
      "Epoch 12/25\n",
      "278/278 [==============================] - 8s 29ms/step - loss: 221.3395 - val_loss: 301.0909\n",
      "Epoch 13/25\n",
      "278/278 [==============================] - 8s 29ms/step - loss: 209.5428 - val_loss: 236.8045\n",
      "Epoch 14/25\n",
      "278/278 [==============================] - 8s 29ms/step - loss: 199.0641 - val_loss: 346.8518\n",
      "Epoch 15/25\n",
      "278/278 [==============================] - 8s 30ms/step - loss: 216.3883 - val_loss: 212.9515\n",
      "Epoch 16/25\n",
      "278/278 [==============================] - 9s 32ms/step - loss: 196.5031 - val_loss: 294.1449\n",
      "Epoch 17/25\n",
      "278/278 [==============================] - 11s 38ms/step - loss: 208.1166 - val_loss: 214.0128\n",
      "Epoch 18/25\n",
      "278/278 [==============================] - 9s 32ms/step - loss: 202.5385 - val_loss: 231.8610\n",
      "Epoch 19/25\n",
      "278/278 [==============================] - 9s 31ms/step - loss: 196.9877 - val_loss: 344.9863\n",
      "Epoch 20/25\n",
      "278/278 [==============================] - 8s 30ms/step - loss: 196.1126 - val_loss: 209.1025\n",
      "Epoch 21/25\n",
      "278/278 [==============================] - 8s 30ms/step - loss: 193.7662 - val_loss: 225.4883\n",
      "Epoch 22/25\n",
      "278/278 [==============================] - 8s 30ms/step - loss: 193.0956 - val_loss: 266.8284\n",
      "Epoch 23/25\n",
      "278/278 [==============================] - 8s 30ms/step - loss: 197.2759 - val_loss: 207.7633\n",
      "Epoch 24/25\n",
      "278/278 [==============================] - 8s 31ms/step - loss: 185.5765 - val_loss: 200.6705\n",
      "Epoch 25/25\n",
      "278/278 [==============================] - 8s 30ms/step - loss: 188.2697 - val_loss: 225.3535\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "(17731, 30, 14) (17731, 1) (100, 30, 14)\n",
      "Epoch 1/25\n",
      "278/278 [==============================] - 10s 31ms/step - loss: 3419.7290 - val_loss: 1678.8875\n",
      "Epoch 2/25\n",
      "278/278 [==============================] - 8s 29ms/step - loss: 1854.9926 - val_loss: 1383.8928\n",
      "Epoch 3/25\n",
      "278/278 [==============================] - 9s 31ms/step - loss: 916.8148 - val_loss: 457.0854\n",
      "Epoch 4/25\n",
      "278/278 [==============================] - 8s 30ms/step - loss: 525.7098 - val_loss: 311.2013\n",
      "Epoch 5/25\n",
      "278/278 [==============================] - 8s 30ms/step - loss: 311.5058 - val_loss: 247.7675\n",
      "Epoch 6/25\n",
      "278/278 [==============================] - 9s 33ms/step - loss: 269.0533 - val_loss: 347.5578\n",
      "Epoch 7/25\n",
      "278/278 [==============================] - 8s 30ms/step - loss: 253.7113 - val_loss: 218.0040\n",
      "Epoch 8/25\n",
      "278/278 [==============================] - 8s 30ms/step - loss: 242.5128 - val_loss: 211.8938\n",
      "Epoch 9/25\n",
      "278/278 [==============================] - 8s 30ms/step - loss: 249.4378 - val_loss: 217.1461\n",
      "Epoch 10/25\n",
      "278/278 [==============================] - 8s 30ms/step - loss: 228.6361 - val_loss: 468.8842\n",
      "Epoch 11/25\n",
      "278/278 [==============================] - 8s 31ms/step - loss: 235.7823 - val_loss: 254.4930\n",
      "Epoch 12/25\n",
      "278/278 [==============================] - 9s 31ms/step - loss: 241.0987 - val_loss: 329.2374\n",
      "Epoch 13/25\n",
      "278/278 [==============================] - 9s 31ms/step - loss: 221.6810 - val_loss: 226.2697\n",
      "Epoch 14/25\n",
      "278/278 [==============================] - 8s 30ms/step - loss: 214.7801 - val_loss: 397.1286\n",
      "Epoch 15/25\n",
      "278/278 [==============================] - 8s 29ms/step - loss: 235.1989 - val_loss: 206.5268\n",
      "Epoch 16/25\n",
      "278/278 [==============================] - 8s 30ms/step - loss: 218.2762 - val_loss: 335.9140\n",
      "Epoch 17/25\n",
      "278/278 [==============================] - 9s 32ms/step - loss: 218.0495 - val_loss: 302.4659\n",
      "Epoch 18/25\n",
      "278/278 [==============================] - 8s 30ms/step - loss: 219.4871 - val_loss: 323.1248\n",
      "Epoch 19/25\n",
      "278/278 [==============================] - 8s 30ms/step - loss: 221.6570 - val_loss: 226.5297\n",
      "Epoch 20/25\n",
      "278/278 [==============================] - 9s 31ms/step - loss: 209.4808 - val_loss: 238.1028\n",
      "Epoch 21/25\n",
      "278/278 [==============================] - 9s 33ms/step - loss: 210.1237 - val_loss: 204.9515\n",
      "Epoch 22/25\n",
      "278/278 [==============================] - 9s 32ms/step - loss: 206.0876 - val_loss: 227.8507\n",
      "Epoch 23/25\n",
      "278/278 [==============================] - 9s 31ms/step - loss: 207.2099 - val_loss: 213.7848\n",
      "Epoch 24/25\n",
      "278/278 [==============================] - 9s 31ms/step - loss: 198.0927 - val_loss: 203.7718\n",
      "Epoch 25/25\n",
      "278/278 [==============================] - 9s 31ms/step - loss: 204.1476 - val_loss: 251.2919\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "(17731, 30, 14) (17731, 1) (100, 30, 14)\n",
      "Epoch 1/25\n",
      "278/278 [==============================] - 3s 6ms/step - loss: 7120.3223 - val_loss: 5175.1108\n",
      "Epoch 2/25\n",
      "278/278 [==============================] - 2s 5ms/step - loss: 5738.6880 - val_loss: 4215.5254\n",
      "Epoch 3/25\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 4784.4141 - val_loss: 3475.2458\n",
      "Epoch 4/25\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 4025.3821 - val_loss: 2903.8625\n",
      "Epoch 5/25\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 3430.6099 - val_loss: 2474.2561\n",
      "Epoch 6/25\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 2975.3516 - val_loss: 2159.6072\n",
      "Epoch 7/25\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 2576.5198 - val_loss: 1800.3739\n",
      "Epoch 8/25\n",
      "278/278 [==============================] - 2s 5ms/step - loss: 2174.5771 - val_loss: 1552.5703\n",
      "Epoch 9/25\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 1779.5583 - val_loss: 1167.2183\n",
      "Epoch 10/25\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 1435.6488 - val_loss: 901.2625\n",
      "Epoch 11/25\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 1155.8640 - val_loss: 638.0145\n",
      "Epoch 12/25\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 952.4449 - val_loss: 490.3898\n",
      "Epoch 13/25\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 795.0198 - val_loss: 410.1442\n",
      "Epoch 14/25\n",
      "278/278 [==============================] - 2s 5ms/step - loss: 690.7769 - val_loss: 316.7538\n",
      "Epoch 15/25\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 583.4766 - val_loss: 276.7487\n",
      "Epoch 16/25\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 519.5847 - val_loss: 260.5565\n",
      "Epoch 17/25\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 462.9000 - val_loss: 231.0137\n",
      "Epoch 18/25\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 429.5637 - val_loss: 226.5071\n",
      "Epoch 19/25\n",
      "278/278 [==============================] - 2s 5ms/step - loss: 399.2860 - val_loss: 273.6262\n",
      "Epoch 20/25\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 383.5061 - val_loss: 261.1324\n",
      "Epoch 21/25\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 369.4442 - val_loss: 204.9968\n",
      "Epoch 22/25\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 352.1906 - val_loss: 274.0057\n",
      "Epoch 23/25\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 353.0987 - val_loss: 205.7810\n",
      "Epoch 24/25\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 353.3102 - val_loss: 210.0340\n",
      "Epoch 25/25\n",
      "278/278 [==============================] - 2s 5ms/step - loss: 343.2802 - val_loss: 225.5765\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "(17731, 30, 14) (17731, 1) (100, 30, 14)\n",
      "Epoch 1/25\n",
      "278/278 [==============================] - 3s 8ms/step - loss: 6102.5264 - val_loss: 3886.2100\n",
      "Epoch 2/25\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 4077.9304 - val_loss: 2689.0906\n",
      "Epoch 3/25\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 2990.4419 - val_loss: 2054.2981\n",
      "Epoch 4/25\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 2393.8914 - val_loss: 1764.4730\n",
      "Epoch 5/25\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 2051.5635 - val_loss: 1439.6188\n",
      "Epoch 6/25\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 1431.8951 - val_loss: 833.4799\n",
      "Epoch 7/25\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 918.3845 - val_loss: 535.1228\n",
      "Epoch 8/25\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 627.1528 - val_loss: 364.2440\n",
      "Epoch 9/25\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 463.8517 - val_loss: 246.5831\n",
      "Epoch 10/25\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 374.6657 - val_loss: 227.1034\n",
      "Epoch 11/25\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 303.9616 - val_loss: 277.2707\n",
      "Epoch 12/25\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 284.2253 - val_loss: 232.7854\n",
      "Epoch 13/25\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 263.1449 - val_loss: 231.3458\n",
      "Epoch 14/25\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 254.9228 - val_loss: 215.6026\n",
      "Epoch 15/25\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 251.0942 - val_loss: 228.5027\n",
      "Epoch 16/25\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 246.6650 - val_loss: 204.8443\n",
      "Epoch 17/25\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 242.2986 - val_loss: 209.6063\n",
      "Epoch 18/25\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 242.7382 - val_loss: 210.3689\n",
      "Epoch 19/25\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 242.8624 - val_loss: 204.1705\n",
      "Epoch 20/25\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 233.3818 - val_loss: 324.5566\n",
      "Epoch 21/25\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 237.1919 - val_loss: 199.1466\n",
      "Epoch 22/25\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 237.5379 - val_loss: 211.3461\n",
      "Epoch 23/25\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 230.9881 - val_loss: 237.6876\n",
      "Epoch 24/25\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 230.4966 - val_loss: 202.9169\n",
      "Epoch 25/25\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 230.4062 - val_loss: 280.8752\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "(17731, 30, 14) (17731, 1) (100, 30, 14)\n",
      "Epoch 1/25\n",
      "555/555 [==============================] - 14s 24ms/step - loss: 2718.1006 - val_loss: 1652.7372\n",
      "Epoch 2/25\n",
      "555/555 [==============================] - 12s 22ms/step - loss: 937.4880 - val_loss: 603.0607\n",
      "Epoch 3/25\n",
      "555/555 [==============================] - 13s 23ms/step - loss: 393.4739 - val_loss: 278.2662\n",
      "Epoch 4/25\n",
      "555/555 [==============================] - 12s 21ms/step - loss: 286.0813 - val_loss: 296.2895\n",
      "Epoch 5/25\n",
      "555/555 [==============================] - 12s 21ms/step - loss: 254.0367 - val_loss: 205.9111\n",
      "Epoch 6/25\n",
      "555/555 [==============================] - 11s 20ms/step - loss: 256.3329 - val_loss: 296.9722\n",
      "Epoch 7/25\n",
      "555/555 [==============================] - 11s 20ms/step - loss: 243.0625 - val_loss: 203.5919\n",
      "Epoch 8/25\n",
      "555/555 [==============================] - 11s 20ms/step - loss: 246.7092 - val_loss: 219.3390\n",
      "Epoch 9/25\n",
      "555/555 [==============================] - 11s 20ms/step - loss: 246.8749 - val_loss: 230.3293\n",
      "Epoch 10/25\n",
      "555/555 [==============================] - 11s 20ms/step - loss: 236.0362 - val_loss: 300.4548\n",
      "Epoch 11/25\n",
      "555/555 [==============================] - 11s 20ms/step - loss: 249.3139 - val_loss: 229.4088\n",
      "Epoch 12/25\n",
      "555/555 [==============================] - 11s 20ms/step - loss: 223.3038 - val_loss: 216.5369\n",
      "Epoch 13/25\n",
      "555/555 [==============================] - 11s 20ms/step - loss: 223.9409 - val_loss: 246.2319\n",
      "Epoch 14/25\n",
      "555/555 [==============================] - 11s 20ms/step - loss: 211.1671 - val_loss: 273.0490\n",
      "Epoch 15/25\n",
      "555/555 [==============================] - 11s 20ms/step - loss: 220.5230 - val_loss: 203.3757\n",
      "Epoch 16/25\n",
      "555/555 [==============================] - 11s 20ms/step - loss: 218.4347 - val_loss: 211.7656\n",
      "Epoch 17/25\n",
      "555/555 [==============================] - 11s 20ms/step - loss: 215.8914 - val_loss: 196.0276\n",
      "Epoch 18/25\n",
      "555/555 [==============================] - 11s 20ms/step - loss: 209.5005 - val_loss: 321.7658\n",
      "Epoch 19/25\n",
      "555/555 [==============================] - 11s 20ms/step - loss: 219.1123 - val_loss: 205.7763\n",
      "Epoch 20/25\n",
      "555/555 [==============================] - 11s 20ms/step - loss: 208.9393 - val_loss: 209.8452\n",
      "Epoch 21/25\n",
      "555/555 [==============================] - 11s 20ms/step - loss: 210.0682 - val_loss: 203.0291\n",
      "Epoch 22/25\n",
      "555/555 [==============================] - 11s 20ms/step - loss: 214.3852 - val_loss: 219.3175\n",
      "Epoch 23/25\n",
      "555/555 [==============================] - 11s 20ms/step - loss: 207.1046 - val_loss: 207.1363\n",
      "Epoch 24/25\n",
      "555/555 [==============================] - 11s 20ms/step - loss: 200.9995 - val_loss: 219.0484\n",
      "Epoch 25/25\n",
      "555/555 [==============================] - 11s 20ms/step - loss: 196.9124 - val_loss: 203.3816\n",
      "4/4 [==============================] - 0s 8ms/step\n",
      "(17731, 30, 14) (17731, 1) (100, 30, 14)\n",
      "Epoch 1/25\n",
      "139/139 [==============================] - 2s 8ms/step - loss: 7689.5029 - val_loss: 5727.9712\n",
      "Epoch 2/25\n",
      "139/139 [==============================] - 1s 7ms/step - loss: 6552.7979 - val_loss: 5098.6567\n",
      "Epoch 3/25\n",
      "139/139 [==============================] - 1s 7ms/step - loss: 5919.0234 - val_loss: 4582.2510\n",
      "Epoch 4/25\n",
      "139/139 [==============================] - 1s 7ms/step - loss: 5372.8096 - val_loss: 4133.9844\n",
      "Epoch 5/25\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 4897.9331 - val_loss: 3742.6191\n",
      "Epoch 6/25\n",
      "139/139 [==============================] - 1s 7ms/step - loss: 4471.7378 - val_loss: 3398.4534\n",
      "Epoch 7/25\n",
      "139/139 [==============================] - 1s 8ms/step - loss: 4099.6445 - val_loss: 3098.4460\n",
      "Epoch 8/25\n",
      "139/139 [==============================] - 1s 7ms/step - loss: 3768.7429 - val_loss: 2837.5476\n",
      "Epoch 9/25\n",
      "139/139 [==============================] - 1s 7ms/step - loss: 3480.1909 - val_loss: 2611.8547\n",
      "Epoch 10/25\n",
      "139/139 [==============================] - 1s 7ms/step - loss: 3222.6858 - val_loss: 2418.4248\n",
      "Epoch 11/25\n",
      "139/139 [==============================] - 1s 7ms/step - loss: 2996.4629 - val_loss: 2253.3599\n",
      "Epoch 12/25\n",
      "139/139 [==============================] - 1s 8ms/step - loss: 2779.2937 - val_loss: 2047.2166\n",
      "Epoch 13/25\n",
      "139/139 [==============================] - 1s 7ms/step - loss: 2541.2229 - val_loss: 1865.6915\n",
      "Epoch 14/25\n",
      "139/139 [==============================] - 1s 7ms/step - loss: 2332.3035 - val_loss: 1676.0054\n",
      "Epoch 15/25\n",
      "139/139 [==============================] - 1s 7ms/step - loss: 2134.3994 - val_loss: 1520.9603\n",
      "Epoch 16/25\n",
      "139/139 [==============================] - 1s 8ms/step - loss: 1898.6636 - val_loss: 1302.5294\n",
      "Epoch 17/25\n",
      "139/139 [==============================] - 1s 7ms/step - loss: 1679.8516 - val_loss: 1116.4999\n",
      "Epoch 18/25\n",
      "139/139 [==============================] - 1s 7ms/step - loss: 1475.7351 - val_loss: 919.8129\n",
      "Epoch 19/25\n",
      "139/139 [==============================] - 1s 7ms/step - loss: 1304.1765 - val_loss: 799.9886\n",
      "Epoch 20/25\n",
      "139/139 [==============================] - 1s 7ms/step - loss: 1175.3766 - val_loss: 699.4976\n",
      "Epoch 21/25\n",
      "139/139 [==============================] - 1s 7ms/step - loss: 1048.3044 - val_loss: 617.5203\n",
      "Epoch 22/25\n",
      "139/139 [==============================] - 1s 7ms/step - loss: 948.8718 - val_loss: 536.7974\n",
      "Epoch 23/25\n",
      "139/139 [==============================] - 1s 7ms/step - loss: 853.0378 - val_loss: 483.2909\n",
      "Epoch 24/25\n",
      "139/139 [==============================] - 1s 7ms/step - loss: 778.2357 - val_loss: 425.3622\n",
      "Epoch 25/25\n",
      "139/139 [==============================] - 1s 7ms/step - loss: 705.1837 - val_loss: 379.4776\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "(17731, 30, 14) (17731, 1) (100, 30, 14)\n",
      "Epoch 1/25\n",
      "555/555 [==============================] - 7s 10ms/step - loss: 3660.5388 - val_loss: 1723.5463\n",
      "Epoch 2/25\n",
      "555/555 [==============================] - 5s 9ms/step - loss: 1940.4257 - val_loss: 1685.9396\n",
      "Epoch 3/25\n",
      "555/555 [==============================] - 5s 9ms/step - loss: 1847.0337 - val_loss: 1491.1826\n",
      "Epoch 4/25\n",
      "555/555 [==============================] - 5s 9ms/step - loss: 660.0536 - val_loss: 815.6719\n",
      "Epoch 5/25\n",
      "555/555 [==============================] - 5s 9ms/step - loss: 339.7854 - val_loss: 227.6001\n",
      "Epoch 6/25\n",
      "555/555 [==============================] - 5s 9ms/step - loss: 261.5974 - val_loss: 259.0442\n",
      "Epoch 7/25\n",
      "555/555 [==============================] - 5s 9ms/step - loss: 240.5000 - val_loss: 201.2160\n",
      "Epoch 8/25\n",
      "555/555 [==============================] - 5s 9ms/step - loss: 234.7161 - val_loss: 193.4812\n",
      "Epoch 9/25\n",
      "555/555 [==============================] - 5s 9ms/step - loss: 225.2388 - val_loss: 833.2915\n",
      "Epoch 10/25\n",
      "555/555 [==============================] - 5s 9ms/step - loss: 236.2159 - val_loss: 233.1140\n",
      "Epoch 11/25\n",
      "555/555 [==============================] - 5s 9ms/step - loss: 221.7973 - val_loss: 200.4612\n",
      "Epoch 12/25\n",
      "555/555 [==============================] - 5s 9ms/step - loss: 215.6909 - val_loss: 220.4388\n",
      "Epoch 13/25\n",
      "555/555 [==============================] - 5s 9ms/step - loss: 217.3528 - val_loss: 222.7270\n",
      "Epoch 14/25\n",
      "555/555 [==============================] - 5s 9ms/step - loss: 207.1108 - val_loss: 290.7382\n",
      "Epoch 15/25\n",
      "555/555 [==============================] - 5s 9ms/step - loss: 210.5170 - val_loss: 203.0460\n",
      "Epoch 16/25\n",
      "555/555 [==============================] - 5s 9ms/step - loss: 202.1618 - val_loss: 218.9381\n",
      "Epoch 17/25\n",
      "555/555 [==============================] - 5s 9ms/step - loss: 203.8182 - val_loss: 195.8074\n",
      "Epoch 18/25\n",
      "555/555 [==============================] - 5s 9ms/step - loss: 204.8485 - val_loss: 364.3931\n",
      "Epoch 19/25\n",
      "555/555 [==============================] - 5s 9ms/step - loss: 202.2601 - val_loss: 198.1696\n",
      "Epoch 20/25\n",
      "555/555 [==============================] - 5s 9ms/step - loss: 198.6462 - val_loss: 198.5624\n",
      "Epoch 21/25\n",
      "555/555 [==============================] - 5s 9ms/step - loss: 196.7729 - val_loss: 217.4256\n",
      "Epoch 22/25\n",
      "555/555 [==============================] - 5s 9ms/step - loss: 195.3031 - val_loss: 216.5570\n",
      "Epoch 23/25\n",
      "555/555 [==============================] - 5s 10ms/step - loss: 192.1133 - val_loss: 193.6911\n",
      "Epoch 24/25\n",
      "555/555 [==============================] - 5s 9ms/step - loss: 193.7033 - val_loss: 201.2148\n",
      "Epoch 25/25\n",
      "555/555 [==============================] - 5s 9ms/step - loss: 193.3026 - val_loss: 213.6060\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "(17731, 30, 14) (17731, 1) (100, 30, 14)\n",
      "Epoch 1/25\n",
      "70/70 [==============================] - 4s 38ms/step - loss: 6634.5908 - val_loss: 4493.1279\n",
      "Epoch 2/25\n",
      "70/70 [==============================] - 2s 31ms/step - loss: 5010.4570 - val_loss: 3614.0613\n",
      "Epoch 3/25\n",
      "70/70 [==============================] - 2s 33ms/step - loss: 4142.4438 - val_loss: 2973.8171\n",
      "Epoch 4/25\n",
      "70/70 [==============================] - 2s 33ms/step - loss: 3474.3442 - val_loss: 2498.2947\n",
      "Epoch 5/25\n",
      "70/70 [==============================] - 2s 34ms/step - loss: 2973.7869 - val_loss: 2167.3406\n",
      "Epoch 6/25\n",
      "70/70 [==============================] - 2s 33ms/step - loss: 2614.2559 - val_loss: 1944.5197\n",
      "Epoch 7/25\n",
      "70/70 [==============================] - 2s 34ms/step - loss: 2361.0486 - val_loss: 1803.5028\n",
      "Epoch 8/25\n",
      "70/70 [==============================] - 2s 33ms/step - loss: 2184.6833 - val_loss: 1720.1809\n",
      "Epoch 9/25\n",
      "70/70 [==============================] - 2s 35ms/step - loss: 2071.9172 - val_loss: 1676.3796\n",
      "Epoch 10/25\n",
      "70/70 [==============================] - 2s 32ms/step - loss: 1994.5219 - val_loss: 1658.3822\n",
      "Epoch 11/25\n",
      "70/70 [==============================] - 2s 35ms/step - loss: 1950.7155 - val_loss: 1655.5863\n",
      "Epoch 12/25\n",
      "70/70 [==============================] - 2s 33ms/step - loss: 1926.8323 - val_loss: 1660.3627\n",
      "Epoch 13/25\n",
      "70/70 [==============================] - 2s 35ms/step - loss: 1906.9968 - val_loss: 1668.2433\n",
      "Epoch 14/25\n",
      "70/70 [==============================] - 2s 31ms/step - loss: 1898.7001 - val_loss: 1676.5094\n",
      "Epoch 15/25\n",
      "70/70 [==============================] - 2s 33ms/step - loss: 1895.3325 - val_loss: 1684.4644\n",
      "Epoch 16/25\n",
      "70/70 [==============================] - 2s 34ms/step - loss: 1892.4830 - val_loss: 1659.1605\n",
      "Epoch 17/25\n",
      "70/70 [==============================] - 2s 32ms/step - loss: 1788.9841 - val_loss: 1471.8013\n",
      "Epoch 18/25\n",
      "70/70 [==============================] - 2s 33ms/step - loss: 1371.3629 - val_loss: 829.9468\n",
      "Epoch 19/25\n",
      "70/70 [==============================] - 2s 33ms/step - loss: 942.7443 - val_loss: 679.2480\n",
      "Epoch 20/25\n",
      "70/70 [==============================] - 2s 32ms/step - loss: 789.2365 - val_loss: 591.2829\n",
      "Epoch 21/25\n",
      "70/70 [==============================] - 2s 33ms/step - loss: 721.2847 - val_loss: 635.0352\n",
      "Epoch 22/25\n",
      "70/70 [==============================] - 2s 32ms/step - loss: 584.6790 - val_loss: 374.2093\n",
      "Epoch 23/25\n",
      "70/70 [==============================] - 2s 33ms/step - loss: 484.5022 - val_loss: 273.1609\n",
      "Epoch 24/25\n",
      "70/70 [==============================] - 2s 34ms/step - loss: 419.6412 - val_loss: 259.5719\n",
      "Epoch 25/25\n",
      "70/70 [==============================] - 2s 32ms/step - loss: 342.1981 - val_loss: 340.1491\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "(17731, 30, 14) (17731, 1) (100, 30, 14)\n",
      "Epoch 1/25\n",
      "139/139 [==============================] - 8s 51ms/step - loss: 4482.0210 - val_loss: 2260.4651\n",
      "Epoch 2/25\n",
      "139/139 [==============================] - 7s 48ms/step - loss: 2353.6604 - val_loss: 1677.0372\n",
      "Epoch 3/25\n",
      "139/139 [==============================] - 7s 52ms/step - loss: 1941.0973 - val_loss: 1669.2521\n",
      "Epoch 4/25\n",
      "139/139 [==============================] - 7s 50ms/step - loss: 1891.9462 - val_loss: 1685.4808\n",
      "Epoch 5/25\n",
      "139/139 [==============================] - 7s 48ms/step - loss: 1683.1084 - val_loss: 1001.6398\n",
      "Epoch 6/25\n",
      "139/139 [==============================] - 7s 48ms/step - loss: 1013.1276 - val_loss: 765.0577\n",
      "Epoch 7/25\n",
      "139/139 [==============================] - 7s 50ms/step - loss: 761.1577 - val_loss: 561.1824\n",
      "Epoch 8/25\n",
      "139/139 [==============================] - 7s 48ms/step - loss: 567.7457 - val_loss: 437.9289\n",
      "Epoch 9/25\n",
      "139/139 [==============================] - 7s 49ms/step - loss: 388.7682 - val_loss: 331.7215\n",
      "Epoch 10/25\n",
      "139/139 [==============================] - 7s 52ms/step - loss: 342.3338 - val_loss: 261.4081\n",
      "Epoch 11/25\n",
      "139/139 [==============================] - 7s 49ms/step - loss: 311.1946 - val_loss: 238.7568\n",
      "Epoch 12/25\n",
      "139/139 [==============================] - 7s 50ms/step - loss: 306.4308 - val_loss: 305.2073\n",
      "Epoch 13/25\n",
      "139/139 [==============================] - 7s 48ms/step - loss: 303.3846 - val_loss: 368.4466\n",
      "Epoch 14/25\n",
      "139/139 [==============================] - 7s 47ms/step - loss: 279.3217 - val_loss: 226.6545\n",
      "Epoch 15/25\n",
      "139/139 [==============================] - 7s 48ms/step - loss: 265.7173 - val_loss: 235.7484\n",
      "Epoch 16/25\n",
      "139/139 [==============================] - 7s 48ms/step - loss: 268.5670 - val_loss: 230.3473\n",
      "Epoch 17/25\n",
      "139/139 [==============================] - 7s 49ms/step - loss: 244.3931 - val_loss: 229.7224\n",
      "Epoch 18/25\n",
      "139/139 [==============================] - 7s 49ms/step - loss: 249.1735 - val_loss: 215.8480\n",
      "Epoch 19/25\n",
      "139/139 [==============================] - 7s 50ms/step - loss: 238.6757 - val_loss: 238.3745\n",
      "Epoch 20/25\n",
      "139/139 [==============================] - 7s 50ms/step - loss: 248.0387 - val_loss: 308.5434\n",
      "Epoch 21/25\n",
      "139/139 [==============================] - 7s 49ms/step - loss: 233.4910 - val_loss: 204.0575\n",
      "Epoch 22/25\n",
      "139/139 [==============================] - 7s 49ms/step - loss: 235.9830 - val_loss: 241.6026\n",
      "Epoch 23/25\n",
      "139/139 [==============================] - 7s 50ms/step - loss: 238.4921 - val_loss: 209.9917\n",
      "Epoch 24/25\n",
      "139/139 [==============================] - 7s 51ms/step - loss: 242.7104 - val_loss: 233.4055\n",
      "Epoch 25/25\n",
      "139/139 [==============================] - 7s 49ms/step - loss: 228.6893 - val_loss: 270.2889\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "iteration  50\n",
      "(17731, 30, 14) (17731, 1) (100, 30, 14)\n",
      "Epoch 1/25\n",
      "555/555 [==============================] - 4s 6ms/step - loss: 5115.5425 - val_loss: 2708.2300\n",
      "Epoch 2/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 2710.4734 - val_loss: 1771.9834\n",
      "Epoch 3/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 2024.6467 - val_loss: 1489.4470\n",
      "Epoch 4/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 1138.1583 - val_loss: 651.5310\n",
      "Epoch 5/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 572.0739 - val_loss: 303.3505\n",
      "Epoch 6/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 368.7623 - val_loss: 259.8788\n",
      "Epoch 7/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 300.5343 - val_loss: 213.0095\n",
      "Epoch 8/25\n",
      "555/555 [==============================] - 3s 6ms/step - loss: 275.6584 - val_loss: 215.7628\n",
      "Epoch 9/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 268.5598 - val_loss: 220.5716\n",
      "Epoch 10/25\n",
      "555/555 [==============================] - 3s 6ms/step - loss: 264.3250 - val_loss: 243.4302\n",
      "Epoch 11/25\n",
      "555/555 [==============================] - 3s 6ms/step - loss: 249.9678 - val_loss: 211.8452\n",
      "Epoch 12/25\n",
      "555/555 [==============================] - 3s 6ms/step - loss: 254.0313 - val_loss: 224.1153\n",
      "Epoch 13/25\n",
      "555/555 [==============================] - 3s 6ms/step - loss: 249.0629 - val_loss: 216.2235\n",
      "Epoch 14/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 240.8640 - val_loss: 288.6283\n",
      "Epoch 15/25\n",
      "555/555 [==============================] - 3s 6ms/step - loss: 245.0489 - val_loss: 217.3961\n",
      "Epoch 16/25\n",
      "555/555 [==============================] - 3s 6ms/step - loss: 236.3982 - val_loss: 205.2434\n",
      "Epoch 17/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 236.0151 - val_loss: 204.9364\n",
      "Epoch 18/25\n",
      "555/555 [==============================] - 3s 6ms/step - loss: 233.1714 - val_loss: 292.2731\n",
      "Epoch 19/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 235.0057 - val_loss: 207.6434\n",
      "Epoch 20/25\n",
      "555/555 [==============================] - 3s 6ms/step - loss: 229.0353 - val_loss: 239.2457\n",
      "Epoch 21/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 228.1442 - val_loss: 266.5708\n",
      "Epoch 22/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 233.6414 - val_loss: 210.1561\n",
      "Epoch 23/25\n",
      "555/555 [==============================] - 3s 6ms/step - loss: 225.3691 - val_loss: 213.4731\n",
      "Epoch 24/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 223.1457 - val_loss: 205.6116\n",
      "Epoch 25/25\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 219.6358 - val_loss: 206.0884\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "CPU times: total: 19min 10s\n",
      "Wall time: 3h 5min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = pd.DataFrame(columns=['RMSE', 'std_RMSE', \n",
    "                                'S_score','std_S_score',\n",
    "                                'MSE', 'std_MSE',\n",
    "                                'nodes', 'dropout',\n",
    "                                'activation', 'batch_size'])\n",
    "\n",
    "\n",
    "for i in range(ITERATIONS):\n",
    "    if ITERATIONS < 10:\n",
    "        print('iteration ', i+1)\n",
    "    elif ((i+1) % 10 == 0):\n",
    "        print('iteration ', i+1)    \n",
    "    tf.random.set_seed(SEED)\n",
    "    mse = []\n",
    "    R2_val = []\n",
    "    RMSE = []\n",
    "    score_val = []\n",
    "    \n",
    "    \n",
    "    # parameter's sample\n",
    "    weights_file = \"model_weight/weights_file_gru.h5\"\n",
    "    alpha = 0.3\n",
    "    sequence_length = 30\n",
    "    epochs = 25\n",
    "    nodes_per_layer = random.sample(nodes_list, 1)[0]\n",
    "    dropout = random.sample(dropouts, 1)[0]\n",
    "    activation = random.sample(activation_functions, 1)[0]\n",
    "    batch_size = random.sample(batch_size_list, 1)[0]\n",
    "    remaining_sensors = remaining_sensors\n",
    "    drop_sensors = [element for element in sensor_names if element not in remaining_sensors]\n",
    "\n",
    "    # create model\n",
    "    input_shape = (sequence_length, len(remaining_sensors))\n",
    "    model = model_gru_1layer(input_shape, nodes_per_layer[0], dropout,\n",
    "                             activation, weights_file)\n",
    "    \n",
    "    # Data prepration\n",
    "    X_train_interim, X_test_interim = prep_data(train, test, drop_sensors, remaining_sensors, alpha)\n",
    "\n",
    "    # create sequences train, test\n",
    "    train_array = gen_data_wrapper(X_train_interim, sequence_length,remaining_sensors)\n",
    "    label_array = gen_label_wrapper(X_train_interim, sequence_length, ['RUL'])\n",
    "\n",
    "    test_gen = (list(gen_test_data(X_test_interim[X_test_interim['Unit']==unit_nr], sequence_length,remaining_sensors, -99.))\n",
    "               for unit_nr in X_test_interim['Unit'].unique())\n",
    "    \n",
    "    test_array = np.concatenate(list(test_gen)).astype(np.float32)\n",
    "    test_rul = rul_piecewise_fct(y_test,rul_piecewise)\n",
    "    print(train_array.shape, label_array.shape, test_array.shape)\n",
    "    \n",
    "    # Model fitting\n",
    "    with tf.device('/device:GPU:0'):\n",
    "        history = model.fit(train_array, label_array,\n",
    "                                validation_data=(test_array, test_rul),\n",
    "                                epochs=epochs,\n",
    "                                batch_size=batch_size,\n",
    "                                # callbacks=[cb],\n",
    "                                verbose=1)\n",
    "        mse.append(history.history['val_loss'][-1])\n",
    "\n",
    "        y_hat_val_split = model.predict(test_array)\n",
    "        R2_val.append(r2_score(test_rul, y_hat_val_split))\n",
    "        RMSE.append(np.sqrt(mean_squared_error(test_rul, y_hat_val_split)))\n",
    "        score_val.append(compute_s_score(test_rul, y_hat_val_split))\n",
    "            \n",
    "        \n",
    "    #  append results\n",
    "    d = {'RMSE' :np.mean(RMSE), 'std_RMSE' :np.std(RMSE),\n",
    "         'S_score' :np.mean(score_val), 'std_S_score' :np.std(score_val),\n",
    "         'MSE':np.mean(mse), 'std_MSE':np.std(mse),\n",
    "         'nodes':str(nodes_per_layer), 'dropout':dropout, \n",
    "         'activation':activation, 'batch_size':batch_size}\n",
    "\n",
    "#     results = results.append(pd.DataFrame(d, index=[0]), ignore_index=True)\n",
    "    results = pd.concat([results, pd.DataFrame(d, index=[0])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE</th>\n",
       "      <th>std_RMSE</th>\n",
       "      <th>S_score</th>\n",
       "      <th>std_S_score</th>\n",
       "      <th>MSE</th>\n",
       "      <th>std_MSE</th>\n",
       "      <th>nodes</th>\n",
       "      <th>dropout</th>\n",
       "      <th>activation</th>\n",
       "      <th>batch_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>14.261192</td>\n",
       "      <td>0.0</td>\n",
       "      <td>346.845151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>203.381607</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[256]</td>\n",
       "      <td>0.3</td>\n",
       "      <td>tanh</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>14.123953</td>\n",
       "      <td>0.0</td>\n",
       "      <td>364.835581</td>\n",
       "      <td>0.0</td>\n",
       "      <td>199.486069</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[64]</td>\n",
       "      <td>0.3</td>\n",
       "      <td>tanh</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>14.355779</td>\n",
       "      <td>0.0</td>\n",
       "      <td>382.946065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>206.088364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[64]</td>\n",
       "      <td>0.2</td>\n",
       "      <td>tanh</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>14.615267</td>\n",
       "      <td>0.0</td>\n",
       "      <td>392.689486</td>\n",
       "      <td>0.0</td>\n",
       "      <td>213.606049</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[128]</td>\n",
       "      <td>0.1</td>\n",
       "      <td>tanh</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>14.602270</td>\n",
       "      <td>0.0</td>\n",
       "      <td>407.648872</td>\n",
       "      <td>0.0</td>\n",
       "      <td>213.226288</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[128]</td>\n",
       "      <td>0.1</td>\n",
       "      <td>tanh</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         RMSE  std_RMSE     S_score  std_S_score         MSE  std_MSE  nodes  \\\n",
       "44  14.261192       0.0  346.845151          0.0  203.381607      0.0  [256]   \n",
       "27  14.123953       0.0  364.835581          0.0  199.486069      0.0   [64]   \n",
       "49  14.355779       0.0  382.946065          0.0  206.088364      0.0   [64]   \n",
       "46  14.615267       0.0  392.689486          0.0  213.606049      0.0  [128]   \n",
       "16  14.602270       0.0  407.648872          0.0  213.226288      0.0  [128]   \n",
       "\n",
       "    dropout activation batch_size  \n",
       "44      0.3       tanh         32  \n",
       "27      0.3       tanh         32  \n",
       "49      0.2       tanh         32  \n",
       "46      0.1       tanh         32  \n",
       "16      0.1       tanh         32  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.to_csv(\"fd001_result/optim_result_1layer.csv\")\n",
    "results.sort_values(by='S_score').head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 layers FD001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Model function\n",
    "def model_gru_2layer(input_shape, nodes_per_layer, dropout, activation, weights_file):\n",
    "    \n",
    "    cb = keras.callbacks.EarlyStopping(monitor='loss', patience=10)\n",
    "    model = Sequential()\n",
    "    model.add(GRU(units = 256, activation=activation, \n",
    "                  input_shape=input_shape, return_sequences=True))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(GRU(units = nodes_per_layer, activation=activation, \n",
    "                  input_shape=input_shape))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error',\n",
    "                  optimizer=Adam(learning_rate=0.001))\n",
    "    model.save_weights(weights_file)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8064"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lower alpha's perform better, so we can ditch a few high ones to reduce the search space\n",
    "alpha_list = [0.01, 0.05] + list(np.arange(10,60+1,10)/100)\n",
    "\n",
    "sequence_list = list(np.arange(10,40+1,5))\n",
    "epoch_list = list(np.arange(5,20+1,5))\n",
    "nodes_list = [[32], [64], [128]]\n",
    "\n",
    "# lowest dropout=0.1, because I know zero dropout will yield better training results but worse generalization\n",
    "dropouts = list(np.arange(1,4)/10)  \n",
    "\n",
    "# again, earlier testing revealed relu performed significantly worse, so I removed it from the options\n",
    "activation_functions = ['tanh']\n",
    "batch_size_list = [32, 64, 128, 256]\n",
    "sensor_list = [sensor_names]\n",
    "\n",
    "tuning_options = np.prod([len(alpha_list),\n",
    "                          len(sequence_list),\n",
    "                          len(epoch_list),\n",
    "                          len(nodes_list),\n",
    "                          len(dropouts),\n",
    "                          len(activation_functions),\n",
    "                          len(batch_size_list),\n",
    "                          len(sensor_list)])\n",
    "tuning_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "results = pd.DataFrame(columns=['RMSE', 'std_RMSE', \n",
    "                                'S_score','std_S_score',\n",
    "                                'MSE', 'std_MSE',\n",
    "                                'nodes', 'dropout',\n",
    "                                'activation', 'batch_size'])\n",
    "\n",
    "\n",
    "for i in range(ITERATIONS):\n",
    "    if ITERATIONS < 10:\n",
    "        print('iteration ', i+1)\n",
    "    elif ((i+1) % 10 == 0):\n",
    "        print('iteration ', i+1)    \n",
    "    tf.random.set_seed(SEED)\n",
    "    mse = []\n",
    "    R2_val = []\n",
    "    RMSE = []\n",
    "    score_val = []\n",
    "    \n",
    "    \n",
    "    # parameter's sample\n",
    "    weights_file = \"model_weight/weights_file_gru.h5\"\n",
    "    alpha = 0.3\n",
    "    sequence_length = 30\n",
    "    epochs = 25\n",
    "    nodes_per_layer = random.sample(nodes_list, 1)[0]\n",
    "    dropout = random.sample(dropouts, 1)[0]\n",
    "    activation = random.sample(activation_functions, 1)[0]\n",
    "    batch_size = random.sample(batch_size_list, 1)[0]\n",
    "    remaining_sensors = remaining_sensors\n",
    "    drop_sensors = [element for element in sensor_names if element not in remaining_sensors]\n",
    "\n",
    "    # create model\n",
    "    input_shape = (sequence_length, len(remaining_sensors))\n",
    "    model = model_gru_2layer(input_shape, nodes_per_layer[0], dropout,\n",
    "                             activation, weights_file)\n",
    "    \n",
    "    # Data prepration\n",
    "    X_train_interim, X_test_interim = prep_data(train, test, drop_sensors, remaining_sensors, alpha)\n",
    "\n",
    "    # create sequences train, test\n",
    "    train_array = gen_data_wrapper(X_train_interim, sequence_length,remaining_sensors)\n",
    "    label_array = gen_label_wrapper(X_train_interim, sequence_length, ['RUL'])\n",
    "\n",
    "    test_gen = (list(gen_test_data(X_test_interim[X_test_interim['Unit']==unit_nr], sequence_length,remaining_sensors, -99.))\n",
    "               for unit_nr in X_test_interim['Unit'].unique())\n",
    "    \n",
    "    test_array = np.concatenate(list(test_gen)).astype(np.float32)\n",
    "    test_rul = rul_piecewise_fct(y_test,rul_piecewise)\n",
    "    print(train_array.shape, label_array.shape, test_array.shape)\n",
    "    \n",
    "    # Model fitting\n",
    "    with tf.device('/device:GPU:0'):\n",
    "        history = model.fit(train_array, label_array,\n",
    "                                validation_data=(test_array, test_rul),\n",
    "                                epochs=epochs,\n",
    "                                batch_size=batch_size,\n",
    "                                # callbacks=[cb],\n",
    "                                verbose=1)\n",
    "        mse.append(history.history['val_loss'][-1])\n",
    "\n",
    "        y_hat_val_split = model.predict(test_array)\n",
    "        R2_val.append(r2_score(test_rul, y_hat_val_split))\n",
    "        RMSE.append(np.sqrt(mean_squared_error(test_rul, y_hat_val_split)))\n",
    "        score_val.append(compute_s_score(test_rul, y_hat_val_split))\n",
    "            \n",
    "        \n",
    "    #  append results\n",
    "    d = {'RMSE' :np.mean(RMSE), 'std_RMSE' :np.std(RMSE),\n",
    "         'S_score' :np.mean(score_val), 'std_S_score' :np.std(score_val),\n",
    "         'MSE':np.mean(mse), 'std_MSE':np.std(mse),\n",
    "         'nodes':str(nodes_per_layer), 'dropout':dropout, \n",
    "         'activation':activation, 'batch_size':batch_size}\n",
    "\n",
    "#     results = results.append(pd.DataFrame(d, index=[0]), ignore_index=True)\n",
    "    results = pd.concat([results, pd.DataFrame(d, index=[0])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE</th>\n",
       "      <th>std_RMSE</th>\n",
       "      <th>S_score</th>\n",
       "      <th>std_S_score</th>\n",
       "      <th>MSE</th>\n",
       "      <th>std_MSE</th>\n",
       "      <th>nodes</th>\n",
       "      <th>dropout</th>\n",
       "      <th>activation</th>\n",
       "      <th>batch_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>14.114525</td>\n",
       "      <td>0.0</td>\n",
       "      <td>315.553602</td>\n",
       "      <td>0.0</td>\n",
       "      <td>199.219849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[64]</td>\n",
       "      <td>0.1</td>\n",
       "      <td>tanh</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>16.640436</td>\n",
       "      <td>0.0</td>\n",
       "      <td>344.560096</td>\n",
       "      <td>0.0</td>\n",
       "      <td>276.904114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[128]</td>\n",
       "      <td>0.1</td>\n",
       "      <td>tanh</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.643668</td>\n",
       "      <td>0.0</td>\n",
       "      <td>356.079892</td>\n",
       "      <td>0.0</td>\n",
       "      <td>214.437012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[64]</td>\n",
       "      <td>0.2</td>\n",
       "      <td>tanh</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>15.545598</td>\n",
       "      <td>0.0</td>\n",
       "      <td>362.195469</td>\n",
       "      <td>0.0</td>\n",
       "      <td>241.665604</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[128]</td>\n",
       "      <td>0.2</td>\n",
       "      <td>tanh</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.640487</td>\n",
       "      <td>0.0</td>\n",
       "      <td>396.175194</td>\n",
       "      <td>0.0</td>\n",
       "      <td>214.343872</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[32]</td>\n",
       "      <td>0.3</td>\n",
       "      <td>tanh</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>14.175282</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400.861973</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200.938629</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[128]</td>\n",
       "      <td>0.1</td>\n",
       "      <td>tanh</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14.060606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>403.599550</td>\n",
       "      <td>0.0</td>\n",
       "      <td>197.700668</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[64]</td>\n",
       "      <td>0.1</td>\n",
       "      <td>tanh</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14.648993</td>\n",
       "      <td>0.0</td>\n",
       "      <td>411.117829</td>\n",
       "      <td>0.0</td>\n",
       "      <td>214.593002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[32]</td>\n",
       "      <td>0.3</td>\n",
       "      <td>tanh</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.421577</td>\n",
       "      <td>0.0</td>\n",
       "      <td>413.279977</td>\n",
       "      <td>0.0</td>\n",
       "      <td>207.981888</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[64]</td>\n",
       "      <td>0.2</td>\n",
       "      <td>tanh</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>14.306092</td>\n",
       "      <td>0.0</td>\n",
       "      <td>437.686065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>204.664291</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[128]</td>\n",
       "      <td>0.1</td>\n",
       "      <td>tanh</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>14.897422</td>\n",
       "      <td>0.0</td>\n",
       "      <td>472.989229</td>\n",
       "      <td>0.0</td>\n",
       "      <td>221.933197</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[128]</td>\n",
       "      <td>0.1</td>\n",
       "      <td>tanh</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.822816</td>\n",
       "      <td>0.0</td>\n",
       "      <td>517.741775</td>\n",
       "      <td>0.0</td>\n",
       "      <td>250.361481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[128]</td>\n",
       "      <td>0.2</td>\n",
       "      <td>tanh</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>15.648989</td>\n",
       "      <td>0.0</td>\n",
       "      <td>557.924282</td>\n",
       "      <td>0.0</td>\n",
       "      <td>244.890854</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[32]</td>\n",
       "      <td>0.1</td>\n",
       "      <td>tanh</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>15.715394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>558.047808</td>\n",
       "      <td>0.0</td>\n",
       "      <td>246.973618</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[128]</td>\n",
       "      <td>0.1</td>\n",
       "      <td>tanh</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>15.914882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>561.501959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>253.283478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[32]</td>\n",
       "      <td>0.1</td>\n",
       "      <td>tanh</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>16.187532</td>\n",
       "      <td>0.0</td>\n",
       "      <td>563.185618</td>\n",
       "      <td>0.0</td>\n",
       "      <td>262.036163</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[32]</td>\n",
       "      <td>0.1</td>\n",
       "      <td>tanh</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16.389977</td>\n",
       "      <td>0.0</td>\n",
       "      <td>574.913499</td>\n",
       "      <td>0.0</td>\n",
       "      <td>268.631317</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[32]</td>\n",
       "      <td>0.2</td>\n",
       "      <td>tanh</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45.695227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7456.039379</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2088.053955</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[32]</td>\n",
       "      <td>0.3</td>\n",
       "      <td>tanh</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>45.770907</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7516.436983</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2094.976074</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[32]</td>\n",
       "      <td>0.1</td>\n",
       "      <td>tanh</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>46.011640</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7715.151213</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2117.071045</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[32]</td>\n",
       "      <td>0.1</td>\n",
       "      <td>tanh</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>46.309804</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7974.746932</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2144.597900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[32]</td>\n",
       "      <td>0.1</td>\n",
       "      <td>tanh</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>40.751524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13606.659410</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1660.686768</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[32]</td>\n",
       "      <td>0.3</td>\n",
       "      <td>tanh</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>40.762754</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13834.224818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1661.602173</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[32]</td>\n",
       "      <td>0.1</td>\n",
       "      <td>tanh</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>40.763050</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13840.052005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1661.626221</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[32]</td>\n",
       "      <td>0.1</td>\n",
       "      <td>tanh</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         RMSE  std_RMSE       S_score  std_S_score          MSE  std_MSE  \\\n",
       "10  14.114525       0.0    315.553602          0.0   199.219849      0.0   \n",
       "5   16.640436       0.0    344.560096          0.0   276.904114      0.0   \n",
       "0   14.643668       0.0    356.079892          0.0   214.437012      0.0   \n",
       "21  15.545598       0.0    362.195469          0.0   241.665604      0.0   \n",
       "2   14.640487       0.0    396.175194          0.0   214.343872      0.0   \n",
       "18  14.175282       0.0    400.861973          0.0   200.938629      0.0   \n",
       "14  14.060606       0.0    403.599550          0.0   197.700668      0.0   \n",
       "9   14.648993       0.0    411.117829          0.0   214.593002      0.0   \n",
       "1   14.421577       0.0    413.279977          0.0   207.981888      0.0   \n",
       "23  14.306092       0.0    437.686065          0.0   204.664291      0.0   \n",
       "22  14.897422       0.0    472.989229          0.0   221.933197      0.0   \n",
       "3   15.822816       0.0    517.741775          0.0   250.361481      0.0   \n",
       "19  15.648989       0.0    557.924282          0.0   244.890854      0.0   \n",
       "20  15.715394       0.0    558.047808          0.0   246.973618      0.0   \n",
       "17  15.914882       0.0    561.501959          0.0   253.283478      0.0   \n",
       "7   16.187532       0.0    563.185618          0.0   262.036163      0.0   \n",
       "16  16.389977       0.0    574.913499          0.0   268.631317      0.0   \n",
       "4   45.695227       0.0   7456.039379          0.0  2088.053955      0.0   \n",
       "11  45.770907       0.0   7516.436983          0.0  2094.976074      0.0   \n",
       "8   46.011640       0.0   7715.151213          0.0  2117.071045      0.0   \n",
       "12  46.309804       0.0   7974.746932          0.0  2144.597900      0.0   \n",
       "6   40.751524       0.0  13606.659410          0.0  1660.686768      0.0   \n",
       "13  40.762754       0.0  13834.224818          0.0  1661.602173      0.0   \n",
       "15  40.763050       0.0  13840.052005          0.0  1661.626221      0.0   \n",
       "\n",
       "    nodes  dropout activation batch_size  \n",
       "10   [64]      0.1       tanh        128  \n",
       "5   [128]      0.1       tanh        256  \n",
       "0    [64]      0.2       tanh        128  \n",
       "21  [128]      0.2       tanh        256  \n",
       "2    [32]      0.3       tanh         64  \n",
       "18  [128]      0.1       tanh         32  \n",
       "14   [64]      0.1       tanh         32  \n",
       "9    [32]      0.3       tanh         64  \n",
       "1    [64]      0.2       tanh         64  \n",
       "23  [128]      0.1       tanh         32  \n",
       "22  [128]      0.1       tanh         64  \n",
       "3   [128]      0.2       tanh         32  \n",
       "19   [32]      0.1       tanh         32  \n",
       "20  [128]      0.1       tanh         32  \n",
       "17   [32]      0.1       tanh         32  \n",
       "7    [32]      0.1       tanh         64  \n",
       "16   [32]      0.2       tanh         32  \n",
       "4    [32]      0.3       tanh        256  \n",
       "11   [32]      0.1       tanh        256  \n",
       "8    [32]      0.1       tanh        256  \n",
       "12   [32]      0.1       tanh        256  \n",
       "6    [32]      0.3       tanh        128  \n",
       "13   [32]      0.1       tanh        128  \n",
       "15   [32]      0.1       tanh        128  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.to_csv('fd001_result/2layergru.csv')\n",
    "results.sort_values(by=\"S_score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. FD002 <a class = \"anchor\" id=\"fd002\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53759, 27) (33991, 26) (259, 1)\n"
     ]
    }
   ],
   "source": [
    "# Data preparation\n",
    "# Data loading\n",
    "\n",
    "train, test, y_test = prepare_data('FD002.txt')\n",
    "print(train.shape, test.shape, y_test.shape)\n",
    "sensor_names = ['T20','T24','T30','T50','P20','P15','P30','Nf','Nc','epr','Ps30','phi',\n",
    "                'NRf','NRc','BPR','farB','htBleed','Nf_dmd','PCNfR_dmd','W31','W32']\n",
    "\n",
    "remaining_sensors = ['T24','T30','T50','P30','Nf','Nc','Ps30','phi',\n",
    "                'NRf','NRc','BPR','htBleed','W31','W32'] # selection based on main_notebook\n",
    "\n",
    "drop_sensors = [element for element in sensor_names if element not in remaining_sensors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "rul_piecewise = 130\n",
    "train['RUL'].clip(upper=rul_piecewise, inplace=True)\n",
    "ITERATIONS = 20\n",
    "SEED = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(\"fd002_result/optim_result_2layer.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46219, 30, 14) (46219, 1) (259, 30, 14)\n",
      "Epoch 1/25\n",
      "1445/1445 [==============================] - 7s 5ms/step - loss: 4816.7974 - val_loss: 2634.2185\n",
      "Epoch 2/25\n",
      "1445/1445 [==============================] - 6s 4ms/step - loss: 2338.8611 - val_loss: 1905.2845\n",
      "Epoch 3/25\n",
      "1445/1445 [==============================] - 6s 4ms/step - loss: 1051.1212 - val_loss: 441.3098\n",
      "Epoch 4/25\n",
      "1445/1445 [==============================] - 6s 4ms/step - loss: 446.8473 - val_loss: 398.5717\n",
      "Epoch 5/25\n",
      "1445/1445 [==============================] - 6s 4ms/step - loss: 353.8566 - val_loss: 356.0776\n",
      "Epoch 6/25\n",
      "1445/1445 [==============================] - 7s 5ms/step - loss: 336.4653 - val_loss: 338.7506\n",
      "Epoch 7/25\n",
      "1445/1445 [==============================] - 6s 4ms/step - loss: 328.2233 - val_loss: 355.0739\n",
      "Epoch 8/25\n",
      "1445/1445 [==============================] - 6s 4ms/step - loss: 322.9799 - val_loss: 376.3207\n",
      "Epoch 9/25\n",
      "1445/1445 [==============================] - 6s 4ms/step - loss: 315.9064 - val_loss: 279.1780\n",
      "Epoch 10/25\n",
      "1445/1445 [==============================] - 6s 4ms/step - loss: 315.9019 - val_loss: 290.9109\n",
      "Epoch 11/25\n",
      "1445/1445 [==============================] - 7s 5ms/step - loss: 308.2054 - val_loss: 250.3514\n",
      "Epoch 12/25\n",
      "1445/1445 [==============================] - 6s 4ms/step - loss: 307.2238 - val_loss: 277.8127\n",
      "Epoch 13/25\n",
      "1445/1445 [==============================] - 6s 4ms/step - loss: 307.7733 - val_loss: 284.7511\n",
      "Epoch 14/25\n",
      "1445/1445 [==============================] - 7s 5ms/step - loss: 306.7995 - val_loss: 258.7305\n",
      "Epoch 15/25\n",
      "1445/1445 [==============================] - 7s 5ms/step - loss: 302.7309 - val_loss: 260.8152\n",
      "Epoch 16/25\n",
      "1445/1445 [==============================] - 6s 4ms/step - loss: 300.4143 - val_loss: 317.8098\n",
      "Epoch 17/25\n",
      "1445/1445 [==============================] - 7s 5ms/step - loss: 297.6186 - val_loss: 276.6919\n",
      "Epoch 18/25\n",
      "1445/1445 [==============================] - 7s 5ms/step - loss: 298.2639 - val_loss: 281.5301\n",
      "Epoch 19/25\n",
      "1445/1445 [==============================] - 6s 4ms/step - loss: 293.6754 - val_loss: 270.4845\n",
      "Epoch 20/25\n",
      "1445/1445 [==============================] - 7s 5ms/step - loss: 293.5443 - val_loss: 289.3876\n",
      "Epoch 21/25\n",
      "1445/1445 [==============================] - 6s 4ms/step - loss: 291.0714 - val_loss: 273.2634\n",
      "Epoch 22/25\n",
      "1445/1445 [==============================] - 6s 4ms/step - loss: 290.0111 - val_loss: 294.3295\n",
      "Epoch 23/25\n",
      "1445/1445 [==============================] - 6s 4ms/step - loss: 287.7518 - val_loss: 335.4256\n",
      "Epoch 24/25\n",
      "1445/1445 [==============================] - 7s 5ms/step - loss: 287.5099 - val_loss: 393.8256\n",
      "Epoch 25/25\n",
      "1445/1445 [==============================] - 6s 4ms/step - loss: 287.2672 - val_loss: 396.2911\n",
      "9/9 [==============================] - 0s 5ms/step\n",
      "(46219, 30, 14) (46219, 1) (259, 30, 14)\n",
      "Epoch 1/25\n",
      "1445/1445 [==============================] - 13s 8ms/step - loss: 2434.4700 - val_loss: 816.6234\n",
      "Epoch 2/25\n",
      "1445/1445 [==============================] - 11s 8ms/step - loss: 543.2908 - val_loss: 709.5993\n",
      "Epoch 3/25\n",
      "1445/1445 [==============================] - 11s 8ms/step - loss: 359.8571 - val_loss: 568.0692\n",
      "Epoch 4/25\n",
      "1445/1445 [==============================] - 11s 8ms/step - loss: 326.0102 - val_loss: 440.7232\n",
      "Epoch 5/25\n",
      "1445/1445 [==============================] - 11s 8ms/step - loss: 314.9480 - val_loss: 464.2425\n",
      "Epoch 6/25\n",
      "1445/1445 [==============================] - 11s 8ms/step - loss: 309.3744 - val_loss: 386.7339\n",
      "Epoch 7/25\n",
      "1445/1445 [==============================] - 11s 8ms/step - loss: 309.6308 - val_loss: 333.9124\n",
      "Epoch 8/25\n",
      "1445/1445 [==============================] - 12s 8ms/step - loss: 304.9806 - val_loss: 295.3221\n",
      "Epoch 9/25\n",
      "1445/1445 [==============================] - 11s 8ms/step - loss: 300.2478 - val_loss: 263.7211\n",
      "Epoch 10/25\n",
      "1445/1445 [==============================] - 11s 8ms/step - loss: 299.7818 - val_loss: 254.3027\n",
      "Epoch 11/25\n",
      "1445/1445 [==============================] - 11s 8ms/step - loss: 295.5568 - val_loss: 253.3156\n",
      "Epoch 12/25\n",
      "1445/1445 [==============================] - 11s 8ms/step - loss: 293.4754 - val_loss: 244.4804\n",
      "Epoch 13/25\n",
      "1445/1445 [==============================] - 11s 8ms/step - loss: 293.8497 - val_loss: 237.9216\n",
      "Epoch 14/25\n",
      "1445/1445 [==============================] - 11s 8ms/step - loss: 292.3756 - val_loss: 240.3566\n",
      "Epoch 15/25\n",
      "1445/1445 [==============================] - 11s 7ms/step - loss: 290.7398 - val_loss: 236.7667\n",
      "Epoch 16/25\n",
      "1445/1445 [==============================] - 11s 8ms/step - loss: 289.9910 - val_loss: 261.7479\n",
      "Epoch 17/25\n",
      "1445/1445 [==============================] - 11s 8ms/step - loss: 286.4287 - val_loss: 237.4741\n",
      "Epoch 18/25\n",
      "1445/1445 [==============================] - 11s 8ms/step - loss: 285.5340 - val_loss: 241.2388\n",
      "Epoch 19/25\n",
      "1445/1445 [==============================] - 11s 8ms/step - loss: 282.0721 - val_loss: 232.7405\n",
      "Epoch 20/25\n",
      "1445/1445 [==============================] - 12s 8ms/step - loss: 281.4801 - val_loss: 229.9415\n",
      "Epoch 21/25\n",
      "1445/1445 [==============================] - 13s 9ms/step - loss: 280.1440 - val_loss: 221.8978\n",
      "Epoch 22/25\n",
      "1445/1445 [==============================] - 14s 10ms/step - loss: 280.4666 - val_loss: 220.9554\n",
      "Epoch 23/25\n",
      "1445/1445 [==============================] - 12s 9ms/step - loss: 276.7980 - val_loss: 230.7224\n",
      "Epoch 24/25\n",
      "1445/1445 [==============================] - 12s 8ms/step - loss: 274.6739 - val_loss: 250.0881\n",
      "Epoch 25/25\n",
      "1445/1445 [==============================] - 12s 9ms/step - loss: 272.8394 - val_loss: 221.8869\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "(46219, 30, 14) (46219, 1) (259, 30, 14)\n",
      "Epoch 1/25\n",
      "181/181 [==============================] - 12s 59ms/step - loss: 3943.8398 - val_loss: 2204.1504\n",
      "Epoch 2/25\n",
      "181/181 [==============================] - 10s 55ms/step - loss: 2067.1372 - val_loss: 1956.8219\n",
      "Epoch 3/25\n",
      "181/181 [==============================] - 10s 54ms/step - loss: 1578.5035 - val_loss: 1210.4930\n",
      "Epoch 4/25\n",
      "181/181 [==============================] - 10s 54ms/step - loss: 673.3417 - val_loss: 880.1183\n",
      "Epoch 5/25\n",
      "181/181 [==============================] - 10s 54ms/step - loss: 429.0777 - val_loss: 798.8443\n",
      "Epoch 6/25\n",
      "181/181 [==============================] - 10s 53ms/step - loss: 377.2505 - val_loss: 776.2787\n",
      "Epoch 7/25\n",
      "181/181 [==============================] - 10s 53ms/step - loss: 343.9436 - val_loss: 952.8528\n",
      "Epoch 8/25\n",
      "181/181 [==============================] - 10s 54ms/step - loss: 333.9462 - val_loss: 825.4283\n",
      "Epoch 9/25\n",
      "181/181 [==============================] - 10s 54ms/step - loss: 332.5900 - val_loss: 827.5881\n",
      "Epoch 10/25\n",
      "181/181 [==============================] - 10s 54ms/step - loss: 328.8714 - val_loss: 776.5190\n",
      "Epoch 11/25\n",
      "181/181 [==============================] - 10s 54ms/step - loss: 322.0113 - val_loss: 594.3073\n",
      "Epoch 12/25\n",
      "181/181 [==============================] - 10s 53ms/step - loss: 307.9881 - val_loss: 620.4946\n",
      "Epoch 13/25\n",
      "181/181 [==============================] - 10s 54ms/step - loss: 305.9597 - val_loss: 604.5353\n",
      "Epoch 14/25\n",
      "181/181 [==============================] - 10s 54ms/step - loss: 302.7450 - val_loss: 594.1125\n",
      "Epoch 15/25\n",
      "181/181 [==============================] - 10s 53ms/step - loss: 299.5558 - val_loss: 598.3060\n",
      "Epoch 16/25\n",
      "181/181 [==============================] - 10s 53ms/step - loss: 310.3331 - val_loss: 247.4156\n",
      "Epoch 17/25\n",
      "181/181 [==============================] - 10s 53ms/step - loss: 299.7247 - val_loss: 256.9788\n",
      "Epoch 18/25\n",
      "181/181 [==============================] - 10s 53ms/step - loss: 295.3337 - val_loss: 243.7785\n",
      "Epoch 19/25\n",
      "181/181 [==============================] - 10s 54ms/step - loss: 291.5083 - val_loss: 230.5476\n",
      "Epoch 20/25\n",
      "181/181 [==============================] - 10s 53ms/step - loss: 300.4427 - val_loss: 241.6034\n",
      "Epoch 21/25\n",
      "181/181 [==============================] - 10s 54ms/step - loss: 289.9125 - val_loss: 229.9106\n",
      "Epoch 22/25\n",
      "181/181 [==============================] - 10s 54ms/step - loss: 287.5442 - val_loss: 235.0803\n",
      "Epoch 23/25\n",
      "181/181 [==============================] - 10s 54ms/step - loss: 288.4341 - val_loss: 266.9569\n",
      "Epoch 24/25\n",
      "181/181 [==============================] - 10s 54ms/step - loss: 286.6962 - val_loss: 349.8222\n",
      "Epoch 25/25\n",
      "181/181 [==============================] - 10s 54ms/step - loss: 292.3426 - val_loss: 349.6653\n",
      "9/9 [==============================] - 0s 7ms/step\n",
      "(46219, 30, 14) (46219, 1) (259, 30, 14)\n",
      "Epoch 1/25\n",
      "723/723 [==============================] - 13s 13ms/step - loss: 3297.8796 - val_loss: 1885.6991\n",
      "Epoch 2/25\n",
      "723/723 [==============================] - 8s 12ms/step - loss: 950.0267 - val_loss: 395.6541\n",
      "Epoch 3/25\n",
      "723/723 [==============================] - 8s 12ms/step - loss: 399.7418 - val_loss: 270.2139\n",
      "Epoch 4/25\n",
      "723/723 [==============================] - 9s 12ms/step - loss: 331.2541 - val_loss: 249.0613\n",
      "Epoch 5/25\n",
      "723/723 [==============================] - 9s 12ms/step - loss: 312.6301 - val_loss: 236.6204\n",
      "Epoch 6/25\n",
      "723/723 [==============================] - 10s 13ms/step - loss: 304.4068 - val_loss: 272.6989\n",
      "Epoch 7/25\n",
      "723/723 [==============================] - 9s 12ms/step - loss: 301.9828 - val_loss: 239.9720\n",
      "Epoch 8/25\n",
      "723/723 [==============================] - 9s 12ms/step - loss: 296.7916 - val_loss: 241.9435\n",
      "Epoch 9/25\n",
      "723/723 [==============================] - 9s 12ms/step - loss: 294.4634 - val_loss: 250.6919\n",
      "Epoch 10/25\n",
      "723/723 [==============================] - 9s 12ms/step - loss: 291.7717 - val_loss: 240.9870\n",
      "Epoch 11/25\n",
      "723/723 [==============================] - 9s 12ms/step - loss: 287.8264 - val_loss: 234.9656\n",
      "Epoch 12/25\n",
      "723/723 [==============================] - 8s 11ms/step - loss: 287.1497 - val_loss: 250.7294\n",
      "Epoch 13/25\n",
      "723/723 [==============================] - 9s 12ms/step - loss: 284.0429 - val_loss: 231.7535\n",
      "Epoch 14/25\n",
      "723/723 [==============================] - 10s 13ms/step - loss: 284.8482 - val_loss: 250.4467\n",
      "Epoch 15/25\n",
      "723/723 [==============================] - 16s 22ms/step - loss: 281.2551 - val_loss: 232.7578\n",
      "Epoch 16/25\n",
      "723/723 [==============================] - 12s 16ms/step - loss: 280.6526 - val_loss: 254.1249\n",
      "Epoch 17/25\n",
      "723/723 [==============================] - 11s 16ms/step - loss: 278.0257 - val_loss: 235.5288\n",
      "Epoch 18/25\n",
      "723/723 [==============================] - 13s 19ms/step - loss: 278.5401 - val_loss: 225.3723\n",
      "Epoch 19/25\n",
      "723/723 [==============================] - 13s 17ms/step - loss: 275.4205 - val_loss: 218.6570\n",
      "Epoch 20/25\n",
      "723/723 [==============================] - 10s 14ms/step - loss: 272.5913 - val_loss: 216.2312\n",
      "Epoch 21/25\n",
      "723/723 [==============================] - 12s 16ms/step - loss: 270.7070 - val_loss: 214.5694\n",
      "Epoch 22/25\n",
      "723/723 [==============================] - 12s 16ms/step - loss: 270.6884 - val_loss: 215.3582\n",
      "Epoch 23/25\n",
      "723/723 [==============================] - 11s 15ms/step - loss: 265.1043 - val_loss: 212.7815\n",
      "Epoch 24/25\n",
      "723/723 [==============================] - 11s 15ms/step - loss: 264.4662 - val_loss: 209.5123\n",
      "Epoch 25/25\n",
      "723/723 [==============================] - 11s 15ms/step - loss: 263.1584 - val_loss: 215.3871\n",
      "9/9 [==============================] - 1s 7ms/step\n",
      "(46219, 30, 14) (46219, 1) (259, 30, 14)\n",
      "Epoch 1/25\n",
      "362/362 [==============================] - 6s 11ms/step - loss: 5790.8516 - val_loss: 3734.8982\n",
      "Epoch 2/25\n",
      "362/362 [==============================] - 4s 11ms/step - loss: 3522.0254 - val_loss: 2537.0063\n",
      "Epoch 3/25\n",
      "362/362 [==============================] - 4s 12ms/step - loss: 2498.8196 - val_loss: 2072.5444\n",
      "Epoch 4/25\n",
      "362/362 [==============================] - 4s 12ms/step - loss: 2069.8599 - val_loss: 1909.2943\n",
      "Epoch 5/25\n",
      "362/362 [==============================] - 4s 12ms/step - loss: 1452.5747 - val_loss: 901.8033\n",
      "Epoch 6/25\n",
      "362/362 [==============================] - 4s 12ms/step - loss: 795.4969 - val_loss: 582.4309\n",
      "Epoch 7/25\n",
      "362/362 [==============================] - 3s 9ms/step - loss: 538.2407 - val_loss: 398.7466\n",
      "Epoch 8/25\n",
      "362/362 [==============================] - 5s 14ms/step - loss: 409.1701 - val_loss: 287.6505\n",
      "Epoch 9/25\n",
      "362/362 [==============================] - 5s 14ms/step - loss: 352.0575 - val_loss: 290.3483\n",
      "Epoch 10/25\n",
      "362/362 [==============================] - 4s 12ms/step - loss: 332.2586 - val_loss: 295.1689\n",
      "Epoch 11/25\n",
      "362/362 [==============================] - 4s 12ms/step - loss: 316.6244 - val_loss: 258.8233\n",
      "Epoch 12/25\n",
      "362/362 [==============================] - 4s 11ms/step - loss: 302.2009 - val_loss: 272.4877\n",
      "Epoch 13/25\n",
      "362/362 [==============================] - 5s 13ms/step - loss: 296.5392 - val_loss: 244.9462\n",
      "Epoch 14/25\n",
      "362/362 [==============================] - 4s 12ms/step - loss: 297.4380 - val_loss: 311.0840\n",
      "Epoch 15/25\n",
      "362/362 [==============================] - 4s 12ms/step - loss: 292.9732 - val_loss: 247.4958\n",
      "Epoch 16/25\n",
      "362/362 [==============================] - 5s 15ms/step - loss: 291.6401 - val_loss: 321.8673\n",
      "Epoch 17/25\n",
      "362/362 [==============================] - 4s 10ms/step - loss: 292.3340 - val_loss: 257.1308\n",
      "Epoch 18/25\n",
      "362/362 [==============================] - 4s 12ms/step - loss: 290.0948 - val_loss: 249.5388\n",
      "Epoch 19/25\n",
      "362/362 [==============================] - 4s 12ms/step - loss: 285.5058 - val_loss: 238.2215\n",
      "Epoch 20/25\n",
      "362/362 [==============================] - 4s 11ms/step - loss: 288.5869 - val_loss: 240.9523\n",
      "Epoch 21/25\n",
      "362/362 [==============================] - 5s 14ms/step - loss: 282.5367 - val_loss: 234.8826\n",
      "Epoch 22/25\n",
      "362/362 [==============================] - 4s 11ms/step - loss: 280.7656 - val_loss: 236.7436\n",
      "Epoch 23/25\n",
      "362/362 [==============================] - 5s 14ms/step - loss: 281.3376 - val_loss: 236.0355\n",
      "Epoch 24/25\n",
      "362/362 [==============================] - 4s 12ms/step - loss: 282.5159 - val_loss: 232.0174\n",
      "Epoch 25/25\n",
      "362/362 [==============================] - 5s 13ms/step - loss: 281.6282 - val_loss: 233.4180\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "(46219, 30, 14) (46219, 1) (259, 30, 14)\n",
      "Epoch 1/25\n",
      "181/181 [==============================] - 4s 15ms/step - loss: 6601.9067 - val_loss: 4804.8306\n",
      "Epoch 2/25\n",
      "181/181 [==============================] - 3s 17ms/step - loss: 4943.8774 - val_loss: 3759.4497\n",
      "Epoch 3/25\n",
      "181/181 [==============================] - 3s 14ms/step - loss: 3917.9033 - val_loss: 3037.7979\n",
      "Epoch 4/25\n",
      "181/181 [==============================] - 3s 17ms/step - loss: 3191.3442 - val_loss: 2556.3359\n",
      "Epoch 5/25\n",
      "181/181 [==============================] - 3s 18ms/step - loss: 2689.7244 - val_loss: 2254.3005\n",
      "Epoch 6/25\n",
      "181/181 [==============================] - 4s 20ms/step - loss: 2356.6584 - val_loss: 2080.9783\n",
      "Epoch 7/25\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 2146.3608 - val_loss: 1994.5239\n",
      "Epoch 8/25\n",
      "181/181 [==============================] - 4s 23ms/step - loss: 2032.0981 - val_loss: 1962.0831\n",
      "Epoch 9/25\n",
      "181/181 [==============================] - 2s 11ms/step - loss: 1962.6434 - val_loss: 1958.6188\n",
      "Epoch 10/25\n",
      "181/181 [==============================] - 4s 21ms/step - loss: 1929.4608 - val_loss: 1967.6448\n",
      "Epoch 11/25\n",
      "181/181 [==============================] - 3s 18ms/step - loss: 1751.1538 - val_loss: 1762.5573\n",
      "Epoch 12/25\n",
      "181/181 [==============================] - 3s 18ms/step - loss: 1050.6456 - val_loss: 1222.3348\n",
      "Epoch 13/25\n",
      "181/181 [==============================] - 4s 20ms/step - loss: 808.5461 - val_loss: 1037.2240\n",
      "Epoch 14/25\n",
      "181/181 [==============================] - 3s 16ms/step - loss: 652.5681 - val_loss: 917.9955\n",
      "Epoch 15/25\n",
      "181/181 [==============================] - 3s 17ms/step - loss: 525.1429 - val_loss: 885.9312\n",
      "Epoch 16/25\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 478.8989 - val_loss: 828.1234\n",
      "Epoch 17/25\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 414.1859 - val_loss: 901.6059\n",
      "Epoch 18/25\n",
      "181/181 [==============================] - 3s 16ms/step - loss: 395.2455 - val_loss: 849.1159\n",
      "Epoch 19/25\n",
      "181/181 [==============================] - 4s 20ms/step - loss: 369.6484 - val_loss: 849.7585\n",
      "Epoch 20/25\n",
      "181/181 [==============================] - 3s 17ms/step - loss: 356.9000 - val_loss: 829.8868\n",
      "Epoch 21/25\n",
      "181/181 [==============================] - 4s 20ms/step - loss: 337.4972 - val_loss: 827.7419\n",
      "Epoch 22/25\n",
      "181/181 [==============================] - 3s 16ms/step - loss: 335.3442 - val_loss: 825.1647\n",
      "Epoch 23/25\n",
      "181/181 [==============================] - 3s 19ms/step - loss: 330.7732 - val_loss: 839.6002\n",
      "Epoch 24/25\n",
      "181/181 [==============================] - 4s 20ms/step - loss: 327.4860 - val_loss: 813.7645\n",
      "Epoch 25/25\n",
      "181/181 [==============================] - 5s 26ms/step - loss: 326.2524 - val_loss: 810.2430\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "(46219, 30, 14) (46219, 1) (259, 30, 14)\n",
      "Epoch 1/25\n",
      "1445/1445 [==============================] - 34s 23ms/step - loss: 1520.9802 - val_loss: 732.7436\n",
      "Epoch 2/25\n",
      "1445/1445 [==============================] - 30s 21ms/step - loss: 377.5385 - val_loss: 819.4370\n",
      "Epoch 3/25\n",
      "1445/1445 [==============================] - 31s 22ms/step - loss: 335.0069 - val_loss: 830.6606\n",
      "Epoch 4/25\n",
      "1445/1445 [==============================] - 32s 22ms/step - loss: 305.8358 - val_loss: 905.0225\n",
      "Epoch 5/25\n",
      "1445/1445 [==============================] - 33s 23ms/step - loss: 289.5297 - val_loss: 976.6941\n",
      "Epoch 6/25\n",
      "1445/1445 [==============================] - 31s 21ms/step - loss: 284.8576 - val_loss: 838.4720\n",
      "Epoch 7/25\n",
      "1445/1445 [==============================] - 31s 22ms/step - loss: 278.6483 - val_loss: 424.5178\n",
      "Epoch 8/25\n",
      "1445/1445 [==============================] - 32s 22ms/step - loss: 276.9454 - val_loss: 387.6146\n",
      "Epoch 9/25\n",
      "1445/1445 [==============================] - 29s 20ms/step - loss: 267.6782 - val_loss: 733.6288\n",
      "Epoch 10/25\n",
      "1445/1445 [==============================] - 32s 22ms/step - loss: 266.1670 - val_loss: 255.2444\n",
      "Epoch 11/25\n",
      "1445/1445 [==============================] - 29s 20ms/step - loss: 258.5682 - val_loss: 215.1433\n",
      "Epoch 12/25\n",
      "1445/1445 [==============================] - 31s 21ms/step - loss: 256.1399 - val_loss: 242.2462\n",
      "Epoch 13/25\n",
      "1445/1445 [==============================] - 30s 21ms/step - loss: 257.8053 - val_loss: 207.9693\n",
      "Epoch 14/25\n",
      "1445/1445 [==============================] - 30s 21ms/step - loss: 250.3693 - val_loss: 219.4372\n",
      "Epoch 15/25\n",
      "1445/1445 [==============================] - 32s 22ms/step - loss: 248.5201 - val_loss: 196.4121\n",
      "Epoch 16/25\n",
      "1445/1445 [==============================] - 32s 22ms/step - loss: 243.2246 - val_loss: 218.7351\n",
      "Epoch 17/25\n",
      "1445/1445 [==============================] - 33s 23ms/step - loss: 242.9435 - val_loss: 205.8435\n",
      "Epoch 18/25\n",
      "1445/1445 [==============================] - 31s 21ms/step - loss: 238.5044 - val_loss: 211.8908\n",
      "Epoch 19/25\n",
      "1445/1445 [==============================] - 29s 20ms/step - loss: 235.1278 - val_loss: 204.5327\n",
      "Epoch 20/25\n",
      "1445/1445 [==============================] - 31s 21ms/step - loss: 232.4195 - val_loss: 202.0873\n",
      "Epoch 21/25\n",
      "1445/1445 [==============================] - 31s 22ms/step - loss: 227.6941 - val_loss: 216.4346\n",
      "Epoch 22/25\n",
      "1445/1445 [==============================] - 32s 22ms/step - loss: 225.1202 - val_loss: 196.6453\n",
      "Epoch 23/25\n",
      "1445/1445 [==============================] - 30s 21ms/step - loss: 223.4429 - val_loss: 193.7905\n",
      "Epoch 24/25\n",
      "1445/1445 [==============================] - 31s 22ms/step - loss: 220.6982 - val_loss: 212.7130\n",
      "Epoch 25/25\n",
      "1445/1445 [==============================] - 30s 21ms/step - loss: 217.8631 - val_loss: 197.7300\n",
      "9/9 [==============================] - 1s 14ms/step\n",
      "(46219, 30, 14) (46219, 1) (259, 30, 14)\n",
      "Epoch 1/25\n",
      "181/181 [==============================] - 4s 11ms/step - loss: 7267.8604 - val_loss: 5679.4604\n",
      "Epoch 2/25\n",
      "181/181 [==============================] - 1s 8ms/step - loss: 6156.4658 - val_loss: 4974.7891\n",
      "Epoch 3/25\n",
      "181/181 [==============================] - 2s 12ms/step - loss: 5430.4932 - val_loss: 4390.1646\n",
      "Epoch 4/25\n",
      "181/181 [==============================] - 2s 9ms/step - loss: 4815.6748 - val_loss: 3896.9609\n",
      "Epoch 5/25\n",
      "181/181 [==============================] - 2s 10ms/step - loss: 4287.6191 - val_loss: 3481.5154\n",
      "Epoch 6/25\n",
      "181/181 [==============================] - 1s 8ms/step - loss: 3834.8267 - val_loss: 3133.9963\n",
      "Epoch 7/25\n",
      "181/181 [==============================] - 2s 11ms/step - loss: 3452.0400 - val_loss: 2846.5540\n",
      "Epoch 8/25\n",
      "181/181 [==============================] - 2s 10ms/step - loss: 3130.0125 - val_loss: 2612.7585\n",
      "Epoch 9/25\n",
      "181/181 [==============================] - 2s 10ms/step - loss: 2866.1040 - val_loss: 2425.6118\n",
      "Epoch 10/25\n",
      "181/181 [==============================] - 2s 10ms/step - loss: 2647.2275 - val_loss: 2279.4233\n",
      "Epoch 11/25\n",
      "181/181 [==============================] - 2s 11ms/step - loss: 2461.2205 - val_loss: 2167.9175\n",
      "Epoch 12/25\n",
      "181/181 [==============================] - 2s 11ms/step - loss: 2319.0032 - val_loss: 2086.0059\n",
      "Epoch 13/25\n",
      "181/181 [==============================] - 2s 9ms/step - loss: 2209.8347 - val_loss: 2028.7579\n",
      "Epoch 14/25\n",
      "181/181 [==============================] - 2s 13ms/step - loss: 2128.2151 - val_loss: 1991.6715\n",
      "Epoch 15/25\n",
      "181/181 [==============================] - 2s 11ms/step - loss: 2059.6292 - val_loss: 1969.8507\n",
      "Epoch 16/25\n",
      "181/181 [==============================] - 2s 9ms/step - loss: 2020.8762 - val_loss: 1959.7361\n",
      "Epoch 17/25\n",
      "181/181 [==============================] - 2s 13ms/step - loss: 1990.2617 - val_loss: 1957.8213\n",
      "Epoch 18/25\n",
      "181/181 [==============================] - 2s 9ms/step - loss: 1961.2185 - val_loss: 1961.0233\n",
      "Epoch 19/25\n",
      "181/181 [==============================] - 1s 8ms/step - loss: 1947.9840 - val_loss: 1967.2632\n",
      "Epoch 20/25\n",
      "181/181 [==============================] - 2s 11ms/step - loss: 1936.3335 - val_loss: 1974.2865\n",
      "Epoch 21/25\n",
      "181/181 [==============================] - 2s 11ms/step - loss: 1851.2894 - val_loss: 1572.8591\n",
      "Epoch 22/25\n",
      "181/181 [==============================] - 1s 7ms/step - loss: 1277.2449 - val_loss: 827.4457\n",
      "Epoch 23/25\n",
      "181/181 [==============================] - 2s 9ms/step - loss: 1018.6852 - val_loss: 734.9857\n",
      "Epoch 24/25\n",
      "181/181 [==============================] - 2s 11ms/step - loss: 847.1481 - val_loss: 596.8621\n",
      "Epoch 25/25\n",
      "181/181 [==============================] - 2s 10ms/step - loss: 726.0536 - val_loss: 482.0093\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "(46219, 30, 14) (46219, 1) (259, 30, 14)\n",
      "Epoch 1/25\n",
      "362/362 [==============================] - 5s 11ms/step - loss: 5871.2905 - val_loss: 3825.5293\n",
      "Epoch 2/25\n",
      "362/362 [==============================] - 4s 12ms/step - loss: 3624.7764 - val_loss: 2594.3000\n",
      "Epoch 3/25\n",
      "362/362 [==============================] - 4s 11ms/step - loss: 2572.6802 - val_loss: 2096.8906\n",
      "Epoch 4/25\n",
      "362/362 [==============================] - 4s 10ms/step - loss: 2121.9346 - val_loss: 1964.7950\n",
      "Epoch 5/25\n",
      "362/362 [==============================] - 4s 12ms/step - loss: 1710.3496 - val_loss: 1026.7632\n",
      "Epoch 6/25\n",
      "362/362 [==============================] - 4s 10ms/step - loss: 948.7316 - val_loss: 583.4436\n",
      "Epoch 7/25\n",
      "362/362 [==============================] - 4s 12ms/step - loss: 666.1590 - val_loss: 411.2079\n",
      "Epoch 8/25\n",
      "362/362 [==============================] - 4s 11ms/step - loss: 492.3915 - val_loss: 325.5022\n",
      "Epoch 9/25\n",
      "362/362 [==============================] - 4s 11ms/step - loss: 424.8159 - val_loss: 293.2043\n",
      "Epoch 10/25\n",
      "362/362 [==============================] - 5s 13ms/step - loss: 401.2569 - val_loss: 291.5353\n",
      "Epoch 11/25\n",
      "362/362 [==============================] - 4s 11ms/step - loss: 378.9041 - val_loss: 265.3205\n",
      "Epoch 12/25\n",
      "362/362 [==============================] - 4s 12ms/step - loss: 362.8857 - val_loss: 267.5398\n",
      "Epoch 13/25\n",
      "362/362 [==============================] - 4s 10ms/step - loss: 353.8690 - val_loss: 246.7655\n",
      "Epoch 14/25\n",
      "362/362 [==============================] - 4s 11ms/step - loss: 351.8493 - val_loss: 313.7618\n",
      "Epoch 15/25\n",
      "362/362 [==============================] - 5s 13ms/step - loss: 348.9596 - val_loss: 256.7249\n",
      "Epoch 16/25\n",
      "362/362 [==============================] - 4s 12ms/step - loss: 344.6604 - val_loss: 354.3059\n",
      "Epoch 17/25\n",
      "362/362 [==============================] - 4s 11ms/step - loss: 345.2249 - val_loss: 237.8851\n",
      "Epoch 18/25\n",
      "362/362 [==============================] - 4s 12ms/step - loss: 337.1144 - val_loss: 239.4890\n",
      "Epoch 19/25\n",
      "362/362 [==============================] - 4s 12ms/step - loss: 335.7063 - val_loss: 239.5251\n",
      "Epoch 20/25\n",
      "362/362 [==============================] - 4s 11ms/step - loss: 336.4534 - val_loss: 239.1476\n",
      "Epoch 21/25\n",
      "362/362 [==============================] - 4s 12ms/step - loss: 329.2657 - val_loss: 232.9678\n",
      "Epoch 22/25\n",
      "362/362 [==============================] - 4s 11ms/step - loss: 329.9261 - val_loss: 230.1541\n",
      "Epoch 23/25\n",
      "362/362 [==============================] - 4s 10ms/step - loss: 328.5995 - val_loss: 240.9313\n",
      "Epoch 24/25\n",
      "362/362 [==============================] - 3s 9ms/step - loss: 332.1124 - val_loss: 229.3806\n",
      "Epoch 25/25\n",
      "362/362 [==============================] - 3s 9ms/step - loss: 328.0024 - val_loss: 224.3309\n",
      "9/9 [==============================] - 0s 6ms/step\n",
      "iteration  10\n",
      "(46219, 30, 14) (46219, 1) (259, 30, 14)\n",
      "Epoch 1/25\n",
      "1445/1445 [==============================] - 9s 5ms/step - loss: 4935.0269 - val_loss: 2689.7554\n",
      "Epoch 2/25\n",
      "1445/1445 [==============================] - 8s 6ms/step - loss: 2414.9629 - val_loss: 1966.0367\n",
      "Epoch 3/25\n",
      "1445/1445 [==============================] - 7s 5ms/step - loss: 1551.1121 - val_loss: 600.5550\n",
      "Epoch 4/25\n",
      "1445/1445 [==============================] - 7s 5ms/step - loss: 596.6198 - val_loss: 314.0537\n",
      "Epoch 5/25\n",
      "1445/1445 [==============================] - 7s 5ms/step - loss: 453.8098 - val_loss: 272.0013\n",
      "Epoch 6/25\n",
      "1445/1445 [==============================] - 7s 5ms/step - loss: 426.4750 - val_loss: 256.4135\n",
      "Epoch 7/25\n",
      "1445/1445 [==============================] - 7s 5ms/step - loss: 411.1138 - val_loss: 245.8629\n",
      "Epoch 8/25\n",
      "1445/1445 [==============================] - 8s 5ms/step - loss: 400.6486 - val_loss: 242.9210\n",
      "Epoch 9/25\n",
      "1445/1445 [==============================] - 8s 6ms/step - loss: 394.8098 - val_loss: 251.2124\n",
      "Epoch 10/25\n",
      "1445/1445 [==============================] - 8s 5ms/step - loss: 387.3499 - val_loss: 286.7315\n",
      "Epoch 11/25\n",
      "1445/1445 [==============================] - 7s 5ms/step - loss: 382.8581 - val_loss: 236.5733\n",
      "Epoch 12/25\n",
      "1445/1445 [==============================] - 9s 6ms/step - loss: 378.8333 - val_loss: 241.0359\n",
      "Epoch 13/25\n",
      "1445/1445 [==============================] - 8s 5ms/step - loss: 373.6571 - val_loss: 227.1364\n",
      "Epoch 14/25\n",
      "1445/1445 [==============================] - 8s 6ms/step - loss: 373.2963 - val_loss: 263.8281\n",
      "Epoch 15/25\n",
      "1445/1445 [==============================] - 7s 5ms/step - loss: 372.7763 - val_loss: 226.2447\n",
      "Epoch 16/25\n",
      "1445/1445 [==============================] - 8s 6ms/step - loss: 365.8987 - val_loss: 243.2492\n",
      "Epoch 17/25\n",
      "1445/1445 [==============================] - 7s 5ms/step - loss: 367.8958 - val_loss: 221.5392\n",
      "Epoch 18/25\n",
      "1445/1445 [==============================] - 8s 5ms/step - loss: 362.8791 - val_loss: 229.4276\n",
      "Epoch 19/25\n",
      "1445/1445 [==============================] - 7s 5ms/step - loss: 359.8878 - val_loss: 232.5045\n",
      "Epoch 20/25\n",
      "1445/1445 [==============================] - 7s 5ms/step - loss: 359.4237 - val_loss: 236.3268\n",
      "Epoch 21/25\n",
      "1445/1445 [==============================] - 7s 5ms/step - loss: 356.5724 - val_loss: 222.6575\n",
      "Epoch 22/25\n",
      "1445/1445 [==============================] - 7s 5ms/step - loss: 356.5633 - val_loss: 215.8168\n",
      "Epoch 23/25\n",
      "1445/1445 [==============================] - 7s 5ms/step - loss: 353.0823 - val_loss: 216.2781\n",
      "Epoch 24/25\n",
      "1445/1445 [==============================] - 7s 5ms/step - loss: 352.1847 - val_loss: 253.6839\n",
      "Epoch 25/25\n",
      "1445/1445 [==============================] - 7s 5ms/step - loss: 349.7392 - val_loss: 216.0391\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "(46219, 30, 14) (46219, 1) (259, 30, 14)\n",
      "Epoch 1/25\n",
      "181/181 [==============================] - 4s 14ms/step - loss: 6649.5239 - val_loss: 4842.0640\n",
      "Epoch 2/25\n",
      "181/181 [==============================] - 3s 18ms/step - loss: 4973.1719 - val_loss: 3776.0259\n",
      "Epoch 3/25\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 3932.2998 - val_loss: 3046.4746\n",
      "Epoch 4/25\n",
      "181/181 [==============================] - 3s 18ms/step - loss: 3199.3723 - val_loss: 2561.1082\n",
      "Epoch 5/25\n",
      "181/181 [==============================] - 4s 20ms/step - loss: 2694.4539 - val_loss: 2256.8230\n",
      "Epoch 6/25\n",
      "181/181 [==============================] - 3s 14ms/step - loss: 2359.0874 - val_loss: 2082.2363\n",
      "Epoch 7/25\n",
      "181/181 [==============================] - 4s 20ms/step - loss: 2147.8960 - val_loss: 1995.0581\n",
      "Epoch 8/25\n",
      "181/181 [==============================] - 3s 14ms/step - loss: 2033.0715 - val_loss: 1962.2229\n",
      "Epoch 9/25\n",
      "181/181 [==============================] - 4s 20ms/step - loss: 1959.4830 - val_loss: 1887.0493\n",
      "Epoch 10/25\n",
      "181/181 [==============================] - 3s 16ms/step - loss: 1621.9757 - val_loss: 1011.3925\n",
      "Epoch 11/25\n",
      "181/181 [==============================] - 3s 14ms/step - loss: 1083.6877 - val_loss: 910.0097\n",
      "Epoch 12/25\n",
      "181/181 [==============================] - 3s 17ms/step - loss: 887.6304 - val_loss: 795.5647\n",
      "Epoch 13/25\n",
      "181/181 [==============================] - 3s 19ms/step - loss: 732.0954 - val_loss: 810.0356\n",
      "Epoch 14/25\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 621.4948 - val_loss: 764.0302\n",
      "Epoch 15/25\n",
      "181/181 [==============================] - 3s 19ms/step - loss: 538.8392 - val_loss: 622.9926\n",
      "Epoch 16/25\n",
      "181/181 [==============================] - 3s 14ms/step - loss: 480.6618 - val_loss: 574.3780\n",
      "Epoch 17/25\n",
      "181/181 [==============================] - 4s 20ms/step - loss: 430.8275 - val_loss: 504.7736\n",
      "Epoch 18/25\n",
      "181/181 [==============================] - 3s 14ms/step - loss: 410.8370 - val_loss: 349.6796\n",
      "Epoch 19/25\n",
      "181/181 [==============================] - 4s 21ms/step - loss: 386.7100 - val_loss: 297.3134\n",
      "Epoch 20/25\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 374.6204 - val_loss: 315.0392\n",
      "Epoch 21/25\n",
      "181/181 [==============================] - 3s 16ms/step - loss: 357.6313 - val_loss: 277.5281\n",
      "Epoch 22/25\n",
      "181/181 [==============================] - 3s 16ms/step - loss: 348.1438 - val_loss: 295.4519\n",
      "Epoch 23/25\n",
      "181/181 [==============================] - 4s 19ms/step - loss: 346.2056 - val_loss: 310.9463\n",
      "Epoch 24/25\n",
      "181/181 [==============================] - 3s 14ms/step - loss: 339.8736 - val_loss: 264.0879\n",
      "Epoch 25/25\n",
      "181/181 [==============================] - 4s 20ms/step - loss: 339.1131 - val_loss: 254.1476\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "(46219, 30, 14) (46219, 1) (259, 30, 14)\n",
      "Epoch 1/25\n",
      "723/723 [==============================] - 8s 8ms/step - loss: 4621.1172 - val_loss: 2538.4695\n",
      "Epoch 2/25\n",
      "723/723 [==============================] - 6s 8ms/step - loss: 2292.2473 - val_loss: 1961.5695\n",
      "Epoch 3/25\n",
      "723/723 [==============================] - 6s 8ms/step - loss: 1917.7222 - val_loss: 1991.7389\n",
      "Epoch 4/25\n",
      "723/723 [==============================] - 6s 8ms/step - loss: 1388.0258 - val_loss: 538.3060\n",
      "Epoch 5/25\n",
      "723/723 [==============================] - 7s 9ms/step - loss: 497.7206 - val_loss: 306.3512\n",
      "Epoch 6/25\n",
      "723/723 [==============================] - 5s 8ms/step - loss: 356.3238 - val_loss: 330.2886\n",
      "Epoch 7/25\n",
      "723/723 [==============================] - 6s 9ms/step - loss: 322.2406 - val_loss: 276.3325\n",
      "Epoch 8/25\n",
      "723/723 [==============================] - 6s 8ms/step - loss: 311.0759 - val_loss: 300.6257\n",
      "Epoch 9/25\n",
      "723/723 [==============================] - 6s 8ms/step - loss: 302.0087 - val_loss: 377.2211\n",
      "Epoch 10/25\n",
      "723/723 [==============================] - 6s 8ms/step - loss: 298.2975 - val_loss: 428.7510\n",
      "Epoch 11/25\n",
      "723/723 [==============================] - 5s 7ms/step - loss: 294.1147 - val_loss: 427.8410\n",
      "Epoch 12/25\n",
      "723/723 [==============================] - 6s 8ms/step - loss: 290.4208 - val_loss: 461.1468\n",
      "Epoch 13/25\n",
      "723/723 [==============================] - 6s 8ms/step - loss: 288.1164 - val_loss: 371.8088\n",
      "Epoch 14/25\n",
      "723/723 [==============================] - 6s 8ms/step - loss: 289.6218 - val_loss: 323.1370\n",
      "Epoch 15/25\n",
      "723/723 [==============================] - 5s 7ms/step - loss: 286.1221 - val_loss: 302.6065\n",
      "Epoch 16/25\n",
      "723/723 [==============================] - 6s 8ms/step - loss: 281.5952 - val_loss: 323.5874\n",
      "Epoch 17/25\n",
      "723/723 [==============================] - 5s 7ms/step - loss: 282.9914 - val_loss: 317.4346\n",
      "Epoch 18/25\n",
      "723/723 [==============================] - 5s 7ms/step - loss: 280.6740 - val_loss: 282.0652\n",
      "Epoch 19/25\n",
      "723/723 [==============================] - 5s 7ms/step - loss: 275.8912 - val_loss: 292.2821\n",
      "Epoch 20/25\n",
      "723/723 [==============================] - 7s 9ms/step - loss: 276.8404 - val_loss: 282.4763\n",
      "Epoch 21/25\n",
      "723/723 [==============================] - 5s 8ms/step - loss: 274.9029 - val_loss: 270.7524\n",
      "Epoch 22/25\n",
      "723/723 [==============================] - 6s 8ms/step - loss: 274.5321 - val_loss: 273.4335\n",
      "Epoch 23/25\n",
      "723/723 [==============================] - 6s 9ms/step - loss: 268.7665 - val_loss: 257.0083\n",
      "Epoch 24/25\n",
      "723/723 [==============================] - 6s 9ms/step - loss: 271.1479 - val_loss: 271.1545\n",
      "Epoch 25/25\n",
      "723/723 [==============================] - 6s 9ms/step - loss: 268.8717 - val_loss: 246.7582\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "(46219, 30, 14) (46219, 1) (259, 30, 14)\n",
      "Epoch 1/25\n",
      "181/181 [==============================] - 9s 42ms/step - loss: 5487.4341 - val_loss: 3495.9751\n",
      "Epoch 2/25\n",
      "181/181 [==============================] - 7s 38ms/step - loss: 3307.2856 - val_loss: 2412.6074\n",
      "Epoch 3/25\n",
      "181/181 [==============================] - 6s 35ms/step - loss: 2383.1326 - val_loss: 2031.6445\n",
      "Epoch 4/25\n",
      "181/181 [==============================] - 7s 39ms/step - loss: 2030.7319 - val_loss: 1958.0592\n",
      "Epoch 5/25\n",
      "181/181 [==============================] - 6s 34ms/step - loss: 1919.9640 - val_loss: 1901.7384\n",
      "Epoch 6/25\n",
      "181/181 [==============================] - 7s 37ms/step - loss: 1424.2823 - val_loss: 1276.8984\n",
      "Epoch 7/25\n",
      "181/181 [==============================] - 7s 40ms/step - loss: 808.9623 - val_loss: 799.2343\n",
      "Epoch 8/25\n",
      "181/181 [==============================] - 7s 36ms/step - loss: 564.3993 - val_loss: 654.6294\n",
      "Epoch 9/25\n",
      "181/181 [==============================] - 8s 43ms/step - loss: 453.6096 - val_loss: 659.6322\n",
      "Epoch 10/25\n",
      "181/181 [==============================] - 9s 49ms/step - loss: 394.7255 - val_loss: 666.1019\n",
      "Epoch 11/25\n",
      "181/181 [==============================] - 9s 50ms/step - loss: 370.6564 - val_loss: 706.8370\n",
      "Epoch 12/25\n",
      "181/181 [==============================] - 9s 48ms/step - loss: 354.6347 - val_loss: 754.5056\n",
      "Epoch 13/25\n",
      "181/181 [==============================] - 8s 45ms/step - loss: 344.4553 - val_loss: 736.4180\n",
      "Epoch 14/25\n",
      "181/181 [==============================] - 8s 45ms/step - loss: 331.3855 - val_loss: 736.3747\n",
      "Epoch 15/25\n",
      "181/181 [==============================] - 7s 37ms/step - loss: 318.6647 - val_loss: 770.2907\n",
      "Epoch 16/25\n",
      "181/181 [==============================] - 7s 37ms/step - loss: 317.9903 - val_loss: 785.9507\n",
      "Epoch 17/25\n",
      "181/181 [==============================] - 7s 36ms/step - loss: 307.4296 - val_loss: 818.3882\n",
      "Epoch 18/25\n",
      "181/181 [==============================] - 7s 37ms/step - loss: 306.5513 - val_loss: 774.3167\n",
      "Epoch 19/25\n",
      "181/181 [==============================] - 7s 40ms/step - loss: 307.7763 - val_loss: 800.2984\n",
      "Epoch 20/25\n",
      "181/181 [==============================] - 7s 40ms/step - loss: 310.5980 - val_loss: 789.1760\n",
      "Epoch 21/25\n",
      "181/181 [==============================] - 7s 39ms/step - loss: 299.7863 - val_loss: 782.2884\n",
      "Epoch 22/25\n",
      "181/181 [==============================] - 7s 41ms/step - loss: 298.1312 - val_loss: 783.4083\n",
      "Epoch 23/25\n",
      "181/181 [==============================] - 7s 37ms/step - loss: 295.2095 - val_loss: 826.9948\n",
      "Epoch 24/25\n",
      "181/181 [==============================] - 7s 38ms/step - loss: 296.8606 - val_loss: 790.9752\n",
      "Epoch 25/25\n",
      "181/181 [==============================] - 7s 36ms/step - loss: 300.6777 - val_loss: 777.6451\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "(46219, 30, 14) (46219, 1) (259, 30, 14)\n",
      "Epoch 1/25\n",
      "181/181 [==============================] - 8s 36ms/step - loss: 5484.9136 - val_loss: 3462.3418\n",
      "Epoch 2/25\n",
      "181/181 [==============================] - 5s 30ms/step - loss: 3271.3525 - val_loss: 2396.3020\n",
      "Epoch 3/25\n",
      "181/181 [==============================] - 6s 33ms/step - loss: 2370.6951 - val_loss: 2028.3577\n",
      "Epoch 4/25\n",
      "181/181 [==============================] - 6s 34ms/step - loss: 2027.3649 - val_loss: 1957.9464\n",
      "Epoch 5/25\n",
      "181/181 [==============================] - 7s 37ms/step - loss: 1922.1204 - val_loss: 1972.9363\n",
      "Epoch 6/25\n",
      "181/181 [==============================] - 8s 45ms/step - loss: 1811.3019 - val_loss: 2042.9301\n",
      "Epoch 7/25\n",
      "181/181 [==============================] - 8s 44ms/step - loss: 1003.4784 - val_loss: 1162.1138\n",
      "Epoch 8/25\n",
      "181/181 [==============================] - 5s 29ms/step - loss: 680.3187 - val_loss: 1041.3732\n",
      "Epoch 9/25\n",
      "181/181 [==============================] - 6s 33ms/step - loss: 510.9727 - val_loss: 974.9885\n",
      "Epoch 10/25\n",
      "181/181 [==============================] - 6s 34ms/step - loss: 401.0990 - val_loss: 935.8525\n",
      "Epoch 11/25\n",
      "181/181 [==============================] - 6s 31ms/step - loss: 354.0965 - val_loss: 939.3807\n",
      "Epoch 12/25\n",
      "181/181 [==============================] - 6s 33ms/step - loss: 329.4588 - val_loss: 1001.8300\n",
      "Epoch 13/25\n",
      "181/181 [==============================] - 6s 32ms/step - loss: 324.4471 - val_loss: 935.0720\n",
      "Epoch 14/25\n",
      "181/181 [==============================] - 6s 33ms/step - loss: 313.4576 - val_loss: 940.4871\n",
      "Epoch 15/25\n",
      "181/181 [==============================] - 7s 38ms/step - loss: 302.3765 - val_loss: 968.6502\n",
      "Epoch 16/25\n",
      "181/181 [==============================] - 8s 47ms/step - loss: 302.7867 - val_loss: 917.5193\n",
      "Epoch 17/25\n",
      "181/181 [==============================] - 7s 38ms/step - loss: 296.5672 - val_loss: 913.9559\n",
      "Epoch 18/25\n",
      "181/181 [==============================] - 10s 53ms/step - loss: 295.5747 - val_loss: 882.0427\n",
      "Epoch 19/25\n",
      "181/181 [==============================] - 6s 36ms/step - loss: 292.8832 - val_loss: 898.2885\n",
      "Epoch 20/25\n",
      "181/181 [==============================] - 8s 47ms/step - loss: 297.1480 - val_loss: 889.4761\n",
      "Epoch 21/25\n",
      "181/181 [==============================] - 8s 46ms/step - loss: 288.5273 - val_loss: 877.7997\n",
      "Epoch 22/25\n",
      "181/181 [==============================] - 8s 42ms/step - loss: 286.9608 - val_loss: 861.7507\n",
      "Epoch 23/25\n",
      "181/181 [==============================] - 8s 43ms/step - loss: 285.6028 - val_loss: 749.6409\n",
      "Epoch 24/25\n",
      "181/181 [==============================] - 8s 42ms/step - loss: 282.8354 - val_loss: 749.6694\n",
      "Epoch 25/25\n",
      "181/181 [==============================] - 7s 38ms/step - loss: 286.7928 - val_loss: 758.5832\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "(46219, 30, 14) (46219, 1) (259, 30, 14)\n",
      "Epoch 1/25\n",
      "362/362 [==============================] - 6s 12ms/step - loss: 5734.6973 - val_loss: 3726.8025\n",
      "Epoch 2/25\n",
      "362/362 [==============================] - 4s 12ms/step - loss: 3520.7205 - val_loss: 2539.0317\n",
      "Epoch 3/25\n",
      "362/362 [==============================] - 4s 12ms/step - loss: 2501.6880 - val_loss: 2074.1104\n",
      "Epoch 4/25\n",
      "362/362 [==============================] - 4s 12ms/step - loss: 1956.1250 - val_loss: 1535.6835\n",
      "Epoch 5/25\n",
      "362/362 [==============================] - 5s 13ms/step - loss: 1219.9124 - val_loss: 785.4995\n",
      "Epoch 6/25\n",
      "362/362 [==============================] - 4s 12ms/step - loss: 750.0196 - val_loss: 503.6107\n",
      "Epoch 7/25\n",
      "362/362 [==============================] - 4s 11ms/step - loss: 516.6320 - val_loss: 335.6374\n",
      "Epoch 8/25\n",
      "362/362 [==============================] - 5s 14ms/step - loss: 408.3318 - val_loss: 316.0991\n",
      "Epoch 9/25\n",
      "362/362 [==============================] - 4s 11ms/step - loss: 358.9578 - val_loss: 283.6906\n",
      "Epoch 10/25\n",
      "362/362 [==============================] - 4s 11ms/step - loss: 327.8946 - val_loss: 262.2523\n",
      "Epoch 11/25\n",
      "362/362 [==============================] - 4s 11ms/step - loss: 314.4089 - val_loss: 248.4214\n",
      "Epoch 12/25\n",
      "362/362 [==============================] - 4s 12ms/step - loss: 305.1092 - val_loss: 273.1724\n",
      "Epoch 13/25\n",
      "362/362 [==============================] - 4s 12ms/step - loss: 296.6501 - val_loss: 246.2533\n",
      "Epoch 14/25\n",
      "362/362 [==============================] - 4s 10ms/step - loss: 298.2921 - val_loss: 307.2300\n",
      "Epoch 15/25\n",
      "362/362 [==============================] - 4s 11ms/step - loss: 292.3252 - val_loss: 234.9903\n",
      "Epoch 16/25\n",
      "362/362 [==============================] - 5s 13ms/step - loss: 290.8558 - val_loss: 335.9525\n",
      "Epoch 17/25\n",
      "362/362 [==============================] - 5s 13ms/step - loss: 290.8423 - val_loss: 283.8462\n",
      "Epoch 18/25\n",
      "362/362 [==============================] - 3s 9ms/step - loss: 290.7039 - val_loss: 239.0637\n",
      "Epoch 19/25\n",
      "362/362 [==============================] - 5s 13ms/step - loss: 286.0028 - val_loss: 230.3728\n",
      "Epoch 20/25\n",
      "362/362 [==============================] - 4s 11ms/step - loss: 289.0486 - val_loss: 238.7443\n",
      "Epoch 21/25\n",
      "362/362 [==============================] - 4s 12ms/step - loss: 281.9428 - val_loss: 236.8846\n",
      "Epoch 22/25\n",
      "362/362 [==============================] - 5s 13ms/step - loss: 280.9396 - val_loss: 235.5141\n",
      "Epoch 23/25\n",
      "362/362 [==============================] - 3s 9ms/step - loss: 279.3556 - val_loss: 231.6874\n",
      "Epoch 24/25\n",
      "362/362 [==============================] - 5s 13ms/step - loss: 282.8733 - val_loss: 229.2623\n",
      "Epoch 25/25\n",
      "362/362 [==============================] - 4s 10ms/step - loss: 280.1468 - val_loss: 231.2953\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "(46219, 30, 14) (46219, 1) (259, 30, 14)\n",
      "Epoch 1/25\n",
      "1445/1445 [==============================] - 33s 22ms/step - loss: 1599.1627 - val_loss: 658.8712\n",
      "Epoch 2/25\n",
      "1445/1445 [==============================] - 30s 21ms/step - loss: 412.3960 - val_loss: 255.4637\n",
      "Epoch 3/25\n",
      "1445/1445 [==============================] - 30s 21ms/step - loss: 321.7384 - val_loss: 280.0777\n",
      "Epoch 4/25\n",
      "1445/1445 [==============================] - 33s 23ms/step - loss: 297.2762 - val_loss: 258.1920\n",
      "Epoch 5/25\n",
      "1445/1445 [==============================] - 32s 22ms/step - loss: 285.8457 - val_loss: 244.5337\n",
      "Epoch 6/25\n",
      "1445/1445 [==============================] - 32s 22ms/step - loss: 279.5353 - val_loss: 241.3589\n",
      "Epoch 7/25\n",
      "1445/1445 [==============================] - 31s 21ms/step - loss: 275.7693 - val_loss: 232.7683\n",
      "Epoch 8/25\n",
      "1445/1445 [==============================] - 31s 21ms/step - loss: 271.2365 - val_loss: 229.3735\n",
      "Epoch 9/25\n",
      "1445/1445 [==============================] - 32s 22ms/step - loss: 266.2068 - val_loss: 238.8610\n",
      "Epoch 10/25\n",
      "1445/1445 [==============================] - 31s 22ms/step - loss: 264.1358 - val_loss: 222.1460\n",
      "Epoch 11/25\n",
      "1445/1445 [==============================] - 31s 21ms/step - loss: 260.4094 - val_loss: 222.4245\n",
      "Epoch 12/25\n",
      "1445/1445 [==============================] - 31s 22ms/step - loss: 255.5624 - val_loss: 244.7552\n",
      "Epoch 13/25\n",
      "1445/1445 [==============================] - 31s 21ms/step - loss: 253.8982 - val_loss: 240.9394\n",
      "Epoch 14/25\n",
      "1445/1445 [==============================] - 32s 22ms/step - loss: 249.1382 - val_loss: 218.7447\n",
      "Epoch 15/25\n",
      "1445/1445 [==============================] - 36s 25ms/step - loss: 244.9494 - val_loss: 221.1125\n",
      "Epoch 16/25\n",
      "1445/1445 [==============================] - 32s 22ms/step - loss: 240.1569 - val_loss: 219.7569\n",
      "Epoch 17/25\n",
      "1445/1445 [==============================] - 32s 22ms/step - loss: 236.2899 - val_loss: 205.0172\n",
      "Epoch 18/25\n",
      "1445/1445 [==============================] - 32s 22ms/step - loss: 234.1275 - val_loss: 221.5756\n",
      "Epoch 19/25\n",
      "1445/1445 [==============================] - 32s 22ms/step - loss: 228.8340 - val_loss: 218.4393\n",
      "Epoch 20/25\n",
      "1445/1445 [==============================] - 30s 21ms/step - loss: 227.1157 - val_loss: 224.6100\n",
      "Epoch 21/25\n",
      "1445/1445 [==============================] - 31s 21ms/step - loss: 223.2693 - val_loss: 206.9461\n",
      "Epoch 22/25\n",
      "1445/1445 [==============================] - 32s 22ms/step - loss: 218.5560 - val_loss: 236.2787\n",
      "Epoch 23/25\n",
      "1445/1445 [==============================] - 32s 22ms/step - loss: 215.2517 - val_loss: 191.1777\n",
      "Epoch 24/25\n",
      "1445/1445 [==============================] - 32s 22ms/step - loss: 213.3401 - val_loss: 228.5950\n",
      "Epoch 25/25\n",
      "1445/1445 [==============================] - 31s 21ms/step - loss: 210.7770 - val_loss: 219.9770\n",
      "9/9 [==============================] - 0s 5ms/step\n",
      "(46219, 30, 14) (46219, 1) (259, 30, 14)\n",
      "Epoch 1/25\n",
      "181/181 [==============================] - 8s 39ms/step - loss: 5336.8354 - val_loss: 3369.3955\n",
      "Epoch 2/25\n",
      "181/181 [==============================] - 7s 41ms/step - loss: 3182.2070 - val_loss: 2345.1736\n",
      "Epoch 3/25\n",
      "181/181 [==============================] - 7s 39ms/step - loss: 2320.8496 - val_loss: 2011.3433\n",
      "Epoch 4/25\n",
      "181/181 [==============================] - 7s 37ms/step - loss: 2003.7545 - val_loss: 1889.7257\n",
      "Epoch 5/25\n",
      "181/181 [==============================] - 7s 39ms/step - loss: 1548.2897 - val_loss: 1130.0543\n",
      "Epoch 6/25\n",
      "181/181 [==============================] - 7s 36ms/step - loss: 895.5038 - val_loss: 813.6107\n",
      "Epoch 7/25\n",
      "181/181 [==============================] - 7s 38ms/step - loss: 652.3010 - val_loss: 712.7442\n",
      "Epoch 8/25\n",
      "181/181 [==============================] - 7s 37ms/step - loss: 497.1961 - val_loss: 535.6227\n",
      "Epoch 9/25\n",
      "181/181 [==============================] - 7s 36ms/step - loss: 398.7051 - val_loss: 418.8085\n",
      "Epoch 10/25\n",
      "181/181 [==============================] - 6s 35ms/step - loss: 354.2102 - val_loss: 258.0928\n",
      "Epoch 11/25\n",
      "181/181 [==============================] - 7s 41ms/step - loss: 342.1582 - val_loss: 264.4247\n",
      "Epoch 12/25\n",
      "181/181 [==============================] - 7s 36ms/step - loss: 331.3112 - val_loss: 285.7543\n",
      "Epoch 13/25\n",
      "181/181 [==============================] - 8s 42ms/step - loss: 322.1898 - val_loss: 243.8716\n",
      "Epoch 14/25\n",
      "181/181 [==============================] - 7s 39ms/step - loss: 314.7985 - val_loss: 247.1979\n",
      "Epoch 15/25\n",
      "181/181 [==============================] - 7s 37ms/step - loss: 307.9003 - val_loss: 294.0550\n",
      "Epoch 16/25\n",
      "181/181 [==============================] - 7s 36ms/step - loss: 310.1068 - val_loss: 248.0161\n",
      "Epoch 17/25\n",
      "181/181 [==============================] - 7s 40ms/step - loss: 300.5915 - val_loss: 324.1032\n",
      "Epoch 18/25\n",
      "181/181 [==============================] - 7s 39ms/step - loss: 299.3173 - val_loss: 235.1696\n",
      "Epoch 19/25\n",
      "181/181 [==============================] - 6s 33ms/step - loss: 297.0104 - val_loss: 262.3249\n",
      "Epoch 20/25\n",
      "181/181 [==============================] - 7s 39ms/step - loss: 301.4376 - val_loss: 259.3991\n",
      "Epoch 21/25\n",
      "181/181 [==============================] - 6s 32ms/step - loss: 292.3963 - val_loss: 232.1207\n",
      "Epoch 22/25\n",
      "181/181 [==============================] - 5s 28ms/step - loss: 291.5133 - val_loss: 230.6302\n",
      "Epoch 23/25\n",
      "181/181 [==============================] - 6s 33ms/step - loss: 288.4641 - val_loss: 299.2579\n",
      "Epoch 24/25\n",
      "181/181 [==============================] - 7s 37ms/step - loss: 290.0684 - val_loss: 233.7540\n",
      "Epoch 25/25\n",
      "181/181 [==============================] - 8s 46ms/step - loss: 291.2906 - val_loss: 229.4380\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "(46219, 30, 14) (46219, 1) (259, 30, 14)\n",
      "Epoch 1/25\n",
      "1445/1445 [==============================] - 10s 6ms/step - loss: 4925.6978 - val_loss: 2680.7886\n",
      "Epoch 2/25\n",
      "1445/1445 [==============================] - 8s 5ms/step - loss: 2364.3474 - val_loss: 1559.7551\n",
      "Epoch 3/25\n",
      "1445/1445 [==============================] - 8s 6ms/step - loss: 1010.8395 - val_loss: 440.3973\n",
      "Epoch 4/25\n",
      "1445/1445 [==============================] - 8s 5ms/step - loss: 485.3116 - val_loss: 308.8464\n",
      "Epoch 5/25\n",
      "1445/1445 [==============================] - 8s 5ms/step - loss: 399.1617 - val_loss: 265.5061\n",
      "Epoch 6/25\n",
      "1445/1445 [==============================] - 8s 6ms/step - loss: 382.3187 - val_loss: 254.2946\n",
      "Epoch 7/25\n",
      "1445/1445 [==============================] - 8s 5ms/step - loss: 372.6950 - val_loss: 247.4646\n",
      "Epoch 8/25\n",
      "1445/1445 [==============================] - 9s 6ms/step - loss: 360.7511 - val_loss: 247.8352\n",
      "Epoch 9/25\n",
      "1445/1445 [==============================] - 8s 6ms/step - loss: 358.1623 - val_loss: 252.6767\n",
      "Epoch 10/25\n",
      "1445/1445 [==============================] - 8s 5ms/step - loss: 352.2530 - val_loss: 266.6543\n",
      "Epoch 11/25\n",
      "1445/1445 [==============================] - 8s 6ms/step - loss: 348.8755 - val_loss: 257.8716\n",
      "Epoch 12/25\n",
      "1445/1445 [==============================] - 8s 6ms/step - loss: 345.3163 - val_loss: 270.1168\n",
      "Epoch 13/25\n",
      "1445/1445 [==============================] - 8s 6ms/step - loss: 343.7558 - val_loss: 242.9023\n",
      "Epoch 14/25\n",
      "1445/1445 [==============================] - 8s 5ms/step - loss: 340.8752 - val_loss: 276.7180\n",
      "Epoch 15/25\n",
      "1445/1445 [==============================] - 8s 6ms/step - loss: 338.8606 - val_loss: 231.5244\n",
      "Epoch 16/25\n",
      "1445/1445 [==============================] - 9s 6ms/step - loss: 335.6361 - val_loss: 272.2271\n",
      "Epoch 17/25\n",
      "1445/1445 [==============================] - 8s 6ms/step - loss: 333.1728 - val_loss: 235.5139\n",
      "Epoch 18/25\n",
      "1445/1445 [==============================] - 9s 6ms/step - loss: 330.7675 - val_loss: 231.7339\n",
      "Epoch 19/25\n",
      "1445/1445 [==============================] - 8s 6ms/step - loss: 326.4443 - val_loss: 249.7515\n",
      "Epoch 20/25\n",
      "1445/1445 [==============================] - 8s 6ms/step - loss: 327.2075 - val_loss: 232.6495\n",
      "Epoch 21/25\n",
      "1445/1445 [==============================] - 8s 6ms/step - loss: 324.6132 - val_loss: 297.2122\n",
      "Epoch 22/25\n",
      "1445/1445 [==============================] - 8s 6ms/step - loss: 324.2107 - val_loss: 306.5595\n",
      "Epoch 23/25\n",
      "1445/1445 [==============================] - 8s 5ms/step - loss: 322.3166 - val_loss: 329.7990\n",
      "Epoch 24/25\n",
      "1445/1445 [==============================] - 9s 6ms/step - loss: 320.2249 - val_loss: 350.5622\n",
      "Epoch 25/25\n",
      "1445/1445 [==============================] - 7s 5ms/step - loss: 320.1158 - val_loss: 347.4930\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "(46219, 30, 14) (46219, 1) (259, 30, 14)\n",
      "Epoch 1/25\n",
      "1445/1445 [==============================] - 11s 7ms/step - loss: 3550.0112 - val_loss: 1967.2651\n",
      "Epoch 2/25\n",
      "1445/1445 [==============================] - 9s 6ms/step - loss: 1936.9968 - val_loss: 1734.0243\n",
      "Epoch 3/25\n",
      "1445/1445 [==============================] - 10s 7ms/step - loss: 701.1963 - val_loss: 397.3933\n",
      "Epoch 4/25\n",
      "1445/1445 [==============================] - 8s 6ms/step - loss: 419.5350 - val_loss: 692.0019\n",
      "Epoch 5/25\n",
      "1445/1445 [==============================] - 9s 6ms/step - loss: 378.9609 - val_loss: 748.5066\n",
      "Epoch 6/25\n",
      "1445/1445 [==============================] - 8s 6ms/step - loss: 361.2913 - val_loss: 903.8423\n",
      "Epoch 7/25\n",
      "1445/1445 [==============================] - 10s 7ms/step - loss: 351.2443 - val_loss: 906.7086\n",
      "Epoch 8/25\n",
      "1445/1445 [==============================] - 9s 6ms/step - loss: 348.0218 - val_loss: 585.0706\n",
      "Epoch 9/25\n",
      "1445/1445 [==============================] - 8s 6ms/step - loss: 337.6709 - val_loss: 711.1422\n",
      "Epoch 10/25\n",
      "1445/1445 [==============================] - 9s 6ms/step - loss: 339.0613 - val_loss: 277.7974\n",
      "Epoch 11/25\n",
      "1445/1445 [==============================] - 9s 6ms/step - loss: 333.4210 - val_loss: 237.5694\n",
      "Epoch 12/25\n",
      "1445/1445 [==============================] - 10s 7ms/step - loss: 330.5692 - val_loss: 257.4120\n",
      "Epoch 13/25\n",
      "1445/1445 [==============================] - 10s 7ms/step - loss: 329.7182 - val_loss: 229.7345\n",
      "Epoch 14/25\n",
      "1445/1445 [==============================] - 9s 6ms/step - loss: 324.5079 - val_loss: 255.5341\n",
      "Epoch 15/25\n",
      "1445/1445 [==============================] - 10s 7ms/step - loss: 323.1428 - val_loss: 225.6275\n",
      "Epoch 16/25\n",
      "1445/1445 [==============================] - 9s 6ms/step - loss: 318.3681 - val_loss: 263.6031\n",
      "Epoch 17/25\n",
      "1445/1445 [==============================] - 10s 7ms/step - loss: 320.3696 - val_loss: 232.7926\n",
      "Epoch 18/25\n",
      "1445/1445 [==============================] - 9s 6ms/step - loss: 318.5424 - val_loss: 231.1154\n",
      "Epoch 19/25\n",
      "1445/1445 [==============================] - 9s 6ms/step - loss: 315.8416 - val_loss: 245.1160\n",
      "Epoch 20/25\n",
      "1445/1445 [==============================] - 9s 6ms/step - loss: 312.8185 - val_loss: 241.8529\n",
      "Epoch 21/25\n",
      "1445/1445 [==============================] - 9s 6ms/step - loss: 310.7155 - val_loss: 246.1191\n",
      "Epoch 22/25\n",
      "1445/1445 [==============================] - 8s 6ms/step - loss: 308.3769 - val_loss: 260.1157\n",
      "Epoch 23/25\n",
      "1445/1445 [==============================] - 10s 7ms/step - loss: 305.9834 - val_loss: 248.2531\n",
      "Epoch 24/25\n",
      "1445/1445 [==============================] - 9s 6ms/step - loss: 307.1331 - val_loss: 274.9535\n",
      "Epoch 25/25\n",
      "1445/1445 [==============================] - 10s 7ms/step - loss: 303.6177 - val_loss: 238.5489\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "iteration  20\n",
      "(46219, 30, 14) (46219, 1) (259, 30, 14)\n",
      "Epoch 1/25\n",
      "181/181 [==============================] - 9s 42ms/step - loss: 5483.3770 - val_loss: 3492.0981\n",
      "Epoch 2/25\n",
      "181/181 [==============================] - 7s 39ms/step - loss: 3299.7686 - val_loss: 2412.3420\n",
      "Epoch 3/25\n",
      "181/181 [==============================] - 7s 41ms/step - loss: 2380.7241 - val_loss: 2032.6880\n",
      "Epoch 4/25\n",
      "181/181 [==============================] - 7s 39ms/step - loss: 2025.9805 - val_loss: 1958.0942\n",
      "Epoch 5/25\n",
      "181/181 [==============================] - 7s 40ms/step - loss: 1917.2461 - val_loss: 1972.5330\n",
      "Epoch 6/25\n",
      "181/181 [==============================] - 7s 41ms/step - loss: 1889.1185 - val_loss: 1994.1393\n",
      "Epoch 7/25\n",
      "181/181 [==============================] - 7s 39ms/step - loss: 1884.6862 - val_loss: 2006.0260\n",
      "Epoch 8/25\n",
      "181/181 [==============================] - 7s 37ms/step - loss: 1884.5601 - val_loss: 1983.3312\n",
      "Epoch 9/25\n",
      "181/181 [==============================] - 7s 38ms/step - loss: 1396.5833 - val_loss: 1281.8754\n",
      "Epoch 10/25\n",
      "181/181 [==============================] - 7s 39ms/step - loss: 684.7067 - val_loss: 934.9919\n",
      "Epoch 11/25\n",
      "181/181 [==============================] - 7s 38ms/step - loss: 458.9022 - val_loss: 881.4850\n",
      "Epoch 12/25\n",
      "181/181 [==============================] - 8s 43ms/step - loss: 371.5062 - val_loss: 898.9875\n",
      "Epoch 13/25\n",
      "181/181 [==============================] - 7s 39ms/step - loss: 334.2079 - val_loss: 841.0292\n",
      "Epoch 14/25\n",
      "181/181 [==============================] - 7s 41ms/step - loss: 329.8548 - val_loss: 838.0745\n",
      "Epoch 15/25\n",
      "181/181 [==============================] - 7s 38ms/step - loss: 302.5276 - val_loss: 850.9562\n",
      "Epoch 16/25\n",
      "181/181 [==============================] - 7s 38ms/step - loss: 301.8132 - val_loss: 883.7027\n",
      "Epoch 17/25\n",
      "181/181 [==============================] - 7s 40ms/step - loss: 293.8407 - val_loss: 922.4339\n",
      "Epoch 18/25\n",
      "181/181 [==============================] - 7s 37ms/step - loss: 289.8118 - val_loss: 876.7216\n",
      "Epoch 19/25\n",
      "181/181 [==============================] - 6s 35ms/step - loss: 285.6563 - val_loss: 871.1092\n",
      "Epoch 20/25\n",
      "181/181 [==============================] - 7s 41ms/step - loss: 290.3975 - val_loss: 870.4747\n",
      "Epoch 21/25\n",
      "181/181 [==============================] - 7s 39ms/step - loss: 281.3852 - val_loss: 880.9445\n",
      "Epoch 22/25\n",
      "181/181 [==============================] - 7s 40ms/step - loss: 285.6624 - val_loss: 859.7216\n",
      "Epoch 23/25\n",
      "181/181 [==============================] - 7s 38ms/step - loss: 277.3469 - val_loss: 919.4486\n",
      "Epoch 24/25\n",
      "181/181 [==============================] - 7s 40ms/step - loss: 277.3226 - val_loss: 891.3759\n",
      "Epoch 25/25\n",
      "181/181 [==============================] - 7s 39ms/step - loss: 287.6434 - val_loss: 871.3268\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "CPU times: total: 1h 1min 38s\n",
      "Wall time: 1h 15min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = pd.DataFrame(columns=['RMSE', 'std_RMSE', \n",
    "                                'S_score','std_S_score',\n",
    "                                'MSE', 'std_MSE',\n",
    "                                'nodes', 'dropout',\n",
    "                                'activation', 'batch_size'])\n",
    "\n",
    "\n",
    "for i in range(ITERATIONS):\n",
    "    if ITERATIONS < 10:\n",
    "        print('iteration ', i+1)\n",
    "    elif ((i+1) % 10 == 0):\n",
    "        print('iteration ', i+1)    \n",
    "    tf.random.set_seed(SEED)\n",
    "    mse = []\n",
    "    R2_val = []\n",
    "    RMSE = []\n",
    "    score_val = []\n",
    "    \n",
    "    \n",
    "    # parameter's sample\n",
    "    weights_file = \"model_weight/weights_file_gru.h5\"\n",
    "    alpha = 0.3\n",
    "    sequence_length = 30\n",
    "    epochs = 25\n",
    "    nodes_per_layer = random.sample(nodes_list, 1)[0]\n",
    "    dropout = random.sample(dropouts, 1)[0]\n",
    "    activation = random.sample(activation_functions, 1)[0]\n",
    "    batch_size = random.sample(batch_size_list, 1)[0]\n",
    "    remaining_sensors = remaining_sensors\n",
    "    drop_sensors = [element for element in sensor_names if element not in remaining_sensors]\n",
    "\n",
    "    # create model\n",
    "    input_shape = (sequence_length, len(remaining_sensors))\n",
    "    model = model_gru_1layer(input_shape, nodes_per_layer[0], dropout,\n",
    "                             activation, weights_file)\n",
    "    \n",
    "    # Data prepration\n",
    "    X_train_interim, X_test_interim = prep_data(train, test, drop_sensors, remaining_sensors, alpha)\n",
    "\n",
    "    # create sequences train, test\n",
    "    train_array = gen_data_wrapper(X_train_interim, sequence_length,remaining_sensors)\n",
    "    label_array = gen_label_wrapper(X_train_interim, sequence_length, ['RUL'])\n",
    "\n",
    "    test_gen = (list(gen_test_data(X_test_interim[X_test_interim['Unit']==unit_nr], sequence_length,remaining_sensors, -99.))\n",
    "               for unit_nr in X_test_interim['Unit'].unique())\n",
    "    \n",
    "    test_array = np.concatenate(list(test_gen)).astype(np.float32)\n",
    "    test_rul = rul_piecewise_fct(y_test,rul_piecewise)\n",
    "    print(train_array.shape, label_array.shape, test_array.shape)\n",
    "    \n",
    "    # Model fitting\n",
    "    with tf.device('/device:GPU:0'):\n",
    "        history = model.fit(train_array, label_array,\n",
    "                                validation_data=(test_array, test_rul),\n",
    "                                epochs=epochs,\n",
    "                                batch_size=batch_size,\n",
    "                                # callbacks=[cb],\n",
    "                                verbose=1)\n",
    "        mse.append(history.history['val_loss'][-1])\n",
    "\n",
    "        y_hat_val_split = model.predict(test_array)\n",
    "        R2_val.append(r2_score(test_rul, y_hat_val_split))\n",
    "        RMSE.append(np.sqrt(mean_squared_error(test_rul, y_hat_val_split)))\n",
    "        score_val.append(compute_s_score(test_rul, y_hat_val_split))\n",
    "            \n",
    "        \n",
    "    #  append results\n",
    "    d = {'RMSE' :np.mean(RMSE), 'std_RMSE' :np.std(RMSE),\n",
    "         'S_score' :np.mean(score_val), 'std_S_score' :np.std(score_val),\n",
    "         'MSE':np.mean(mse), 'std_MSE':np.std(mse),\n",
    "         'nodes':str(nodes_per_layer), 'dropout':dropout, \n",
    "         'activation':activation, 'batch_size':batch_size}\n",
    "\n",
    "#     results = results.append(pd.DataFrame(d, index=[0]), ignore_index=True)\n",
    "    results = pd.concat([results, pd.DataFrame(d, index=[0])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE</th>\n",
       "      <th>std_RMSE</th>\n",
       "      <th>S_score</th>\n",
       "      <th>std_S_score</th>\n",
       "      <th>MSE</th>\n",
       "      <th>std_MSE</th>\n",
       "      <th>nodes</th>\n",
       "      <th>dropout</th>\n",
       "      <th>activation</th>\n",
       "      <th>batch_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14.061648</td>\n",
       "      <td>0.0</td>\n",
       "      <td>928.483398</td>\n",
       "      <td>0.0</td>\n",
       "      <td>197.729965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[256]</td>\n",
       "      <td>0.1</td>\n",
       "      <td>tanh</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>14.831621</td>\n",
       "      <td>0.0</td>\n",
       "      <td>944.086039</td>\n",
       "      <td>0.0</td>\n",
       "      <td>219.976990</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[256]</td>\n",
       "      <td>0.1</td>\n",
       "      <td>tanh</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.895869</td>\n",
       "      <td>0.0</td>\n",
       "      <td>974.758527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>221.886917</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[128]</td>\n",
       "      <td>0.3</td>\n",
       "      <td>tanh</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.676073</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1004.472028</td>\n",
       "      <td>0.0</td>\n",
       "      <td>215.387115</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[128]</td>\n",
       "      <td>0.2</td>\n",
       "      <td>tanh</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>15.147210</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1048.456973</td>\n",
       "      <td>0.0</td>\n",
       "      <td>229.437958</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[128]</td>\n",
       "      <td>0.2</td>\n",
       "      <td>tanh</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         RMSE  std_RMSE      S_score  std_S_score         MSE  std_MSE  nodes  \\\n",
       "6   14.061648       0.0   928.483398          0.0  197.729965      0.0  [256]   \n",
       "15  14.831621       0.0   944.086039          0.0  219.976990      0.0  [256]   \n",
       "1   14.895869       0.0   974.758527          0.0  221.886917      0.0  [128]   \n",
       "3   14.676073       0.0  1004.472028          0.0  215.387115      0.0  [128]   \n",
       "16  15.147210       0.0  1048.456973          0.0  229.437958      0.0  [128]   \n",
       "\n",
       "    dropout activation batch_size  \n",
       "6       0.1       tanh         32  \n",
       "15      0.1       tanh         32  \n",
       "1       0.3       tanh         32  \n",
       "3       0.2       tanh         64  \n",
       "16      0.2       tanh        256  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.sort_values(by=\"S_score\").head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(\"fd002_result/optim_result_1layer.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
